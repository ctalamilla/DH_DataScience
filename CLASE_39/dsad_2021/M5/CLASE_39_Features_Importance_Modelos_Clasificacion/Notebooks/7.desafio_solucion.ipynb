{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial setup\n",
    "%run \"../../../common/0_notebooks_base_setup.py\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<img src='../../../common/logo_DH.png' align='left' width=35%/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "**Introducción**\n",
    "\n",
    "La Organización Mundial de la Salud ha estimado que 12 millones de muertes ocurren en todo el mundo, cada año debido a enfermedades del corazón. La mitad de las muertes en los Estados Unidos y otros países desarrollados se deben a enfermedades cardiovasculares. El pronóstico temprano de las enfermedades cardiovasculares puede ayudar a tomar decisiones sobre los cambios en el estilo de vida en pacientes de alto riesgo y, a su vez, reducir las complicaciones. Esta investigación tiene la intención de identificar los factores más relevantes / de riesgo de enfermedad cardíaca, así como predecir el riesgo general mediante distintos modelos de clasificación\n",
    "\n",
    "**Fuente**\n",
    "\n",
    "El conjunto de datos está disponible públicamente en el sitio web de Kaggle (https://www.kaggle.com/amanajmera1/framingham-heart-study-dataset), y proviene de un estudio cardiovascular en curso en residentes de la ciudad de Framingham, Massachusetts. El objetivo de la clasificación es predecir si el paciente tiene riesgo de enfermedad coronaria (CHD) en los próximos 10 años. El conjunto de datos proporciona la información del paciente. Incluye más de 4000 registros y 15 atributos.\n",
    "\n",
    "**Variables**\n",
    "\n",
    "Cada atributo es un factor de riesgo potencial. Hay factores de riesgo demográficos, conductuales y médicos.\n",
    "\n",
    "Demográficos:\n",
    "\n",
    "• Sex: male or female(Nominal)\n",
    "\n",
    "• Age: Age of the patient;(Continuous - Although the recorded ages have been truncated to whole numbers, the concept of age is continuous)\n",
    "Behavioral\n",
    "\n",
    "• Current Smoker: whether or not the patient is a current smoker (Nominal)\n",
    "\n",
    "• Cigs Per Day: the number of cigarettes that the person smoked on average in one day.(can be considered continuous as one can have any number of cigarettes, even half a cigarette.)\n",
    "\n",
    "Médicos (histórico):\n",
    "\n",
    "• BP Meds: whether or not the patient was on blood pressure medication (Nominal)\n",
    "\n",
    "• Prevalent Stroke: whether or not the patient had previously had a stroke (Nominal)\n",
    "\n",
    "• Prevalent Hyp: whether or not the patient was hypertensive (Nominal)\n",
    "\n",
    "• Diabetes: whether or not the patient had diabetes (Nominal)\n",
    "\n",
    "Médicos (actual):\n",
    "\n",
    "• Tot Chol: total cholesterol level (Continuous)\n",
    "\n",
    "• Sys BP: systolic blood pressure (Continuous)\n",
    "\n",
    "• Dia BP: diastolic blood pressure (Continuous)\n",
    "\n",
    "• BMI: Body Mass Index (Continuous)\n",
    "\n",
    "• Heart Rate: heart rate (Continuous - In medical research, variables such as heart rate though in fact discrete, yet are considered continuous because of large number of possible values.)\n",
    "\n",
    "• Glucose: glucose level (Continuous)\n",
    "\n",
    "Variable a predecir (target):\n",
    "\n",
    "• 10 year risk of coronary heart disease CHD (binary: “1”, means “Yes”, “0” means “No”)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicios\n",
    "\n",
    "En esta clase vamos entrenar distintos modelos de clasificación usando:\n",
    "    \n",
    "* Regresión Logística    \n",
    "\n",
    "* KNN\n",
    "\n",
    "* Classification Tree\n",
    "\n",
    "* Random Forest\n",
    "\n",
    "\n",
    "Para cada uno de ello vamos a evaluar la preformance en testing del modelo resultado\n",
    "\n",
    "* Default\n",
    "\n",
    "* Grid Search Cross Validation KFold\n",
    "\n",
    "* Grid Search CV Stratified KFold\n",
    "\n",
    "* Bagging\n",
    "\n",
    "* Bagging Grid Search Cross Validation\n",
    "\n",
    "Las métricas que vamos a calcular para cada modelo son\n",
    "\n",
    "* score\n",
    "\n",
    "* confusion matrix\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, StratifiedKFold\n",
    "from sklearn.metrics import auc, plot_roc_curve\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 1\n",
    "\n",
    "1.1) Leamos los datos del archivo datasets_222487_478477_framingham.csv\n",
    "\n",
    "1.2) ¿Qué porcentaje de registros hay en cada una de las categorías target?\n",
    "\n",
    "1.3) ¿El dataset tiene datos faltantes?\n",
    "\n",
    "1.4) Usemos `dropna` para eliminar los registros con valores faltantes, y volvamos a calcular el porcentaje de registros hay en cada una de las categorías target \n",
    "\n",
    "https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.dropna.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_raw = pd.read_csv('../Data/datasets_222487_478477_framingham.csv')\n",
    "data_raw.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_raw.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos qué procentaje de registros hay en cada una de las categorías target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_raw.TenYearCHD.value_counts() / data_raw.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_raw.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_raw.dropna()\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.TenYearCHD.value_counts() / data.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que en este caso, eliminando los registros que tienen algun valor nulo no cambiamos la proporción de registros en cada una de las categorías target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 2 - Train Test Split + StandardScaler\n",
    "\n",
    "Construir los conjuntos de entranamiento y test y usando StandardScaler normalizar las features\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=data.drop([\"TenYearCHD\"],axis=1)\n",
    "y=data[\"TenYearCHD\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=717)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "X_train_sc = sc.fit_transform(X_train)\n",
    "X_test_sc = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## De la práctica de checkpoint:\n",
    "\n",
    "Vamos a usar esta función para entrenar todos los modelos que pide el enunciado, devolviendo como resultado las métricas de evaluación de cada modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model_instance, X_train, y_train, X_test, y_test, gridSearch_params, gridSearch_bagging_params):\n",
    "    \n",
    "    # entreno el modelo default\n",
    "    model_instance.fit(X_train, y_train)\n",
    "    \n",
    "    # calculo el score sobre los datos de test\n",
    "    score_default_test = model_instance.score(X_test, y_test)\n",
    "    \n",
    "    # calculo la matriz de confusión\n",
    "    predictions_default = model_instance.predict(X_test)\n",
    "    confusion_matrix_default = metrics.confusion_matrix(y_test, predictions_default)\n",
    "    \n",
    "    ###################################################\n",
    "    \n",
    "    # gridSearch KFold:    \n",
    "    cv_KFold = KFold(n_splits=3, shuffle=True, random_state=371)\n",
    "    grid_search_CV_KFold_model = GridSearchCV(model_instance, gridSearch_params, n_jobs=-1, cv = cv_KFold)    \n",
    "    grid_search_CV_KFold_model.fit(X_train, y_train)        \n",
    "    scores_KFold = cross_val_score(model_instance, X_train, y_train, cv=cv_KFold, n_jobs=-1)\n",
    "    mean_score_grid_search_CV_KFold_model = scores_KFold.mean()\n",
    "    std_score_grid_search_CV_KFold_model = scores_KFold.std()\n",
    "        \n",
    "    score_grid_search_CV_KFold_model = grid_search_CV_KFold_model.best_score_\n",
    "    params_grid_search_CV_KFold_model = grid_search_CV_KFold_model.best_params_\n",
    "    \n",
    "    score_grid_search_CV_KFold_model_test = grid_search_CV_KFold_model.score(X_test, y_test)\n",
    "    predictions_grid_search_CV_KFold_model = grid_search_CV_KFold_model.predict(X_test)    \n",
    "    confusion_matrix_grid_search_CV_KFold_model = metrics.confusion_matrix(y_test, predictions_grid_search_CV_KFold_model)\n",
    "\n",
    "    ###################################################\n",
    "    \n",
    "    # gridSearch Stratified KFold:    \n",
    "    cv_Stratified_KFold = StratifiedKFold(n_splits=3, shuffle=True, random_state=371)\n",
    "    grid_search_CV_Stratified_KFold_model = GridSearchCV(model_instance, gridSearch_params, n_jobs=-1, cv = cv_Stratified_KFold)    \n",
    "    grid_search_CV_Stratified_KFold_model.fit(X_train, y_train)        \n",
    "    scores_Stratified_KFold = cross_val_score(model_instance, X_train, y_train, cv=cv_Stratified_KFold, n_jobs=-1)\n",
    "    mean_score_grid_search_CV_Stratified_KFold_model = scores_Stratified_KFold.mean()\n",
    "    std_score_grid_search_CV_Stratified_KFold_model = scores_Stratified_KFold.std()    \n",
    "    \n",
    "    score_grid_search_CV_Stratified_KFold_model = grid_search_CV_Stratified_KFold_model.best_score_\n",
    "    params_grid_search_CV_Stratified_KFold_model = grid_search_CV_Stratified_KFold_model.best_params_\n",
    "    \n",
    "    score_grid_search_CV_Stratified_KFold_model_test = grid_search_CV_Stratified_KFold_model.score(X_test, y_test)\n",
    "    predictions_grid_search_CV_Stratified_KFold_model = grid_search_CV_Stratified_KFold_model.predict(X_test)\n",
    "    confusion_matrix_grid_search_CV_Stratified_KFold_model = metrics.confusion_matrix(y_test, predictions_grid_search_CV_Stratified_KFold_model)\n",
    "\n",
    "    ###################################################\n",
    "    \n",
    "    if gridSearch_bagging_params:\n",
    "\n",
    "        # bagging\n",
    "\n",
    "        bagging_model_default = BaggingClassifier(base_estimator = model_instance)\n",
    "        bagging_model_default.fit(X_train, y_train)\n",
    "        score_bagging_model_default_test =  bagging_model_default.score(X_test, y_test)\n",
    "        \n",
    "        predictions_bagging_model_default = bagging_model_default.predict(X_test)\n",
    "        confusion_matrix_bagging_model_default = metrics.confusion_matrix(y_test, predictions_bagging_model_default)    \n",
    "\n",
    "        ###################################################\n",
    "\n",
    "        # bagging Stratified KFold cross validation usando de base el mejor modelo de gridsearch estratificado\n",
    "        base_estimator_stratified_grid_search = grid_search_CV_Stratified_KFold_model.best_estimator_\n",
    "        cv_Stratified_KFold =StratifiedKFold(n_splits=3, shuffle=True, random_state=371)\n",
    "        grid_search_bagging_model = GridSearchCV(BaggingClassifier(base_estimator = base_estimator_stratified_grid_search),\n",
    "                               gridSearch_bagging_params, n_jobs=-1, cv = cv_Stratified_KFold)\n",
    "\n",
    "        grid_search_bagging_model.fit(X_train, y_train)\n",
    "        \n",
    "        score_grid_search_bagging_model_test = grid_search_bagging_model.score(X_test, y_test)\n",
    "        predictions_grid_search_bagging_model = grid_search_bagging_model.predict(X_test)\n",
    "        confusion_matrix_grid_search_bagging_model = metrics.confusion_matrix(y_test, predictions_grid_search_bagging_model)\n",
    "        scores_bagging_Stratified_KFold = cross_val_score(BaggingClassifier(base_estimator = base_estimator_stratified_grid_search),\n",
    "                                                          X_train, y_train, cv=cv_Stratified_KFold, n_jobs=-1)\n",
    "        mean_score_bagging_grid_search_CV_Stratified_KFold_model = scores_bagging_Stratified_KFold.mean()\n",
    "        std_score_bagging_grid_search_CV_Stratified_KFold_model = scores_bagging_Stratified_KFold.std()    \n",
    "        \n",
    "        best_score_bagging_grid_search_CV_Stratified_KFold_model = grid_search_bagging_model.best_score_\n",
    "        best_params_bagging_grid_search_CV_Stratified_KFold_model = grid_search_bagging_model.best_params_\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        score_bagging_model_default_test = None\n",
    "        confusion_matrix_bagging_model_default = None\n",
    "        mean_score_bagging_grid_search_CV_Stratified_KFold_model = None\n",
    "        std_score_bagging_grid_search_CV_Stratified_KFold_model = None\n",
    "        confusion_matrix_grid_search_bagging_model = None\n",
    "        best_score_bagging_grid_search_CV_Stratified_KFold_model = None\n",
    "        score_grid_search_bagging_model_test = None\n",
    "        best_params_bagging_grid_search_CV_Stratified_KFold_model = None\n",
    "\n",
    "                                                                                                                                     \n",
    "    ###################################################\n",
    "    \n",
    "    \n",
    "    # armo un diccionario con todos los valores de performance que calculé para los modelos\n",
    "    result = {\n",
    "        'default': {\n",
    "            'score': score_default_test,\n",
    "            'confusion_matrix': confusion_matrix_default            \n",
    "        },\n",
    "        'cv_kfold': {\n",
    "            'mean_score_grid_search': mean_score_grid_search_CV_KFold_model,\n",
    "            'std_score_grid_search': std_score_grid_search_CV_KFold_model,\n",
    "            'best_score_grid_search': score_grid_search_CV_KFold_model,\n",
    "            'score': score_grid_search_CV_KFold_model_test,\n",
    "            'confusion_matrix': confusion_matrix_grid_search_CV_KFold_model           \n",
    "        },\n",
    "        'cv_stratified_kfold': {\n",
    "            'mean_score_grid_search': mean_score_grid_search_CV_Stratified_KFold_model,\n",
    "            'std_score_grid_search': std_score_grid_search_CV_Stratified_KFold_model,\n",
    "            'best_score_grid_search': score_grid_search_CV_Stratified_KFold_model,\n",
    "            'score': score_grid_search_CV_Stratified_KFold_model_test,\n",
    "            'confusion_matrix': confusion_matrix_grid_search_CV_Stratified_KFold_model           \n",
    "        },\n",
    "        'bagging': {\n",
    "            'score': score_bagging_model_default_test,\n",
    "            'confusion_matrix': confusion_matrix_bagging_model_default           \n",
    "        },\n",
    "        'bagging_cv_stratified_kfold': {\n",
    "            'mean_score_grid_search': mean_score_bagging_grid_search_CV_Stratified_KFold_model,\n",
    "            'std_score_grid_search': std_score_bagging_grid_search_CV_Stratified_KFold_model,\n",
    "            'best_score_grid_search': best_params_bagging_grid_search_CV_Stratified_KFold_model,\n",
    "            'score': score_grid_search_bagging_model_test,\n",
    "            'confusion_matrix': confusion_matrix_grid_search_bagging_model           \n",
    "        }\n",
    "        \n",
    "    }\n",
    "    \n",
    "    return result\n",
    "        \n",
    "#           'trained_model_instance': model_instance, \n",
    "#              'score_default': score_default_test,\n",
    "#              'confusion_matrix_default': confusion_matrix_default,\n",
    "#              'mean_score_grid_search_CV_KFold_model': mean_score_grid_search_CV_KFold_model, \n",
    "#              'std_score_grid_search_CV_KFold_model': std_score_grid_search_CV_KFold_model, \n",
    "#              'best_score_grid_search_CV_KFold_model': score_grid_search_CV_KFold_model,\n",
    "#              'best_params_grid_search_CV_KFold_model': params_grid_search_CV_KFold_model,              \n",
    "#              'score_grid_search_CV_KFold_model_test': score_grid_search_CV_KFold_model_test,\n",
    "#              'confusion_matrix_grid_search_CV_KFold_model': confusion_matrix_grid_search_CV_KFold_model,\n",
    "        \n",
    "#              'mean_score_grid_search_CV_Stratified_KFold_model': mean_score_grid_search_CV_Stratified_KFold_model, \n",
    "#              'std_score_grid_search_CV_Stratified_KFold_model': std_score_grid_search_CV_Stratified_KFold_model, \n",
    "#              'best_score_grid_search_CV_Stratified_KFold_model': score_grid_search_CV_Stratified_KFold_model,\n",
    "#              'best_params_grid_search_CV_Stratified_KFold_model': params_grid_search_CV_Stratified_KFold_model,              \n",
    "#              'score_grid_search_CV_Stratified_KFold_model_test': score_grid_search_CV_Stratified_KFold_model_test,\n",
    "#              'confusion_matrix_grid_search_CV_Stratified_KFold_model': confusion_matrix_grid_search_CV_Stratified_KFold_model,\n",
    "        \n",
    "#              'score_bagging_default': score_bagging_model_default_test,\n",
    "#              'confusion_matrix_bagging_default': confusion_matrix_bagging_model_default,\n",
    "        \n",
    "#              'mean_score_bagging_grid_search_CV_Stratified_KFold_model': mean_score_bagging_grid_search_CV_Stratified_KFold_model, \n",
    "#              'std_score_bagging_grid_search_CV__StratifiedKFold_model': std_score_bagging_grid_search_CV_Stratified_KFold_model, \n",
    "#              'best_score_bagging_grid_search_CV_Stratified_KFold_model': best_score_bagging_grid_search_CV_Stratified_KFold_model,\n",
    "#              'best_params_bagging_grid_search_CV_Stratified_KFold_model': best_params_bagging_grid_search_CV_Stratified_KFold_model,              \n",
    "#              'score_bagging_grid_search_CV_Stratified_KFold_model_test': score_grid_search_bagging_model_test,\n",
    "#              'confusion_matrix_bagging_grid_search_CV_Stratified_KFold_model': confusion_matrix_grid_search_bagging_model,\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 3 - Regresión Logística\n",
    "\n",
    "Usemos la función definida en el checkpoint que evalua la performance de modelos en un modelo de regresión logística usando `LogisticRegression` con los parámetros por default\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\n",
    "\n",
    "Los parámetros de GridSearchCV que vamos a probar son \n",
    "\n",
    "``params = {'C': [0.001, 0.01, 0.1, 1.0, 10.0, 100.0], 'penalty': ['l1', 'l2']}``\n",
    "\n",
    "Los parámetros de bagging que vamos a probar son\n",
    "\n",
    "<code>\n",
    "bagging_params = {'n_estimators': [10, 100],\n",
    "\n",
    "                  'max_samples': [0.01, 1.0],\n",
    "                  \n",
    "                  'max_features': [0.3, 1.0],\n",
    "                  \n",
    "                  'bootstrap_features': [True, False]}\n",
    "</code>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_instance = LogisticRegression()\n",
    "x_train = X_train_sc\n",
    "x_test =  X_test_sc\n",
    "gridSearch_params = {'C': [0, 1e-20, 1e-10, 1e-5, 1e-4, 0.001, 0.01, 0.1, 1.0, 10.0, 100.0], 'penalty': ['l1', 'l2']}\n",
    "gridSearch_bagging_params = {'n_estimators': [10, 100],\n",
    "                  'max_samples': [0.01, 1.0],                  \n",
    "                  'max_features': [0.3, 1.0],                  \n",
    "                  'bootstrap_features': [True, False]}\n",
    "\n",
    "logistic_metrics = evaluate_model(model_instance, x_train, y_train, x_test, y_test, gridSearch_params, gridSearch_bagging_params)\n",
    "\n",
    "logistic_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Para todos los modelos vamos a ver que la capacidad de predicción de la clase minoritaria es bastante mala)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 4 - KNN\n",
    "\n",
    "Usemos la función definida en el checkpoint que evalua la performance de modelos en un modelo KNN usando `KNeighborsClassifier` con los parámetros por default (n_neighbors=5)\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html\n",
    "\n",
    "Los parámetros de GridSearchCV que vamos a probar son \n",
    "\n",
    "``params =  {'n_neighbors': range(1,50)}``\n",
    "\n",
    "Los parámetros de bagging que vamos a probar son\n",
    "\n",
    "<code>\n",
    "bagging_params = {'n_estimators': [10, 100],\n",
    "\n",
    "                  'max_samples': [0.05, 1.0],\n",
    "                  \n",
    "                  'max_features': [0.3, 1.0],\n",
    "                  \n",
    "                  'bootstrap_features': [True, False]}\n",
    "</code>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_instance = KNeighborsClassifier()\n",
    "x_train = X_train_sc\n",
    "x_test =  X_test_sc\n",
    "gridSearch_params = {'n_neighbors': range(1,50)}\n",
    "gridSearch_bagging_params = {'n_estimators': [10, 100],\n",
    "                  'max_samples': [0.05, 1.0],                  \n",
    "                  'max_features': [0.3, 1.0],                  \n",
    "                  'bootstrap_features': [True, False]}\n",
    "\n",
    "knn_metrics = evaluate_model(model_instance, x_train, y_train, x_test, y_test, gridSearch_params, gridSearch_bagging_params)\n",
    "\n",
    "knn_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 5 - Tree\n",
    "\n",
    "Usemos la función definida en el checkpoint que evalua la performance de modelos en un modelo de árbol de decisión usando `DecisionTreeClassifier` con los parámetros por default\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html\n",
    "\n",
    "Los parámetros de GridSearchCV que vamos a probar son \n",
    "\n",
    "``params =  {'criterion': ['gini', 'entropy'],\n",
    "          'splitter': ['best', 'random'],\n",
    "          'max_depth': [None, 5, 10],\n",
    "          'min_samples_split': [2, 5],\n",
    "          'min_samples_leaf': [1, 2, 3]}``\n",
    "\n",
    "Los parámetros de bagging que vamos a probar son\n",
    "\n",
    "<code>\n",
    "bagging_params = {'n_estimators': [10, 100],\n",
    "\n",
    "                  'max_samples': [0.01, 1.0],\n",
    "                  \n",
    "                  'max_features': [0.3, 1.0],\n",
    "                  \n",
    "                  'bootstrap_features': [True, False]}\n",
    "</code>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_instance = DecisionTreeClassifier()\n",
    "x_train = X_train_sc\n",
    "x_test =  X_test_sc\n",
    "gridSearch_params = {'criterion': ['gini', 'entropy'],\n",
    "          'splitter': ['best', 'random'],\n",
    "          'max_depth': [None, 5, 10],\n",
    "          'min_samples_split': [2, 5],\n",
    "          'min_samples_leaf': [1, 2, 3]}\n",
    "\n",
    "gridSearch_bagging_params = {'n_estimators': [10, 100],\n",
    "                  'max_samples': [0.01, 1.0],                  \n",
    "                  'max_features': [0.3, 1.0],                  \n",
    "                  'bootstrap_features': [True, False]}\n",
    "\n",
    "decision_tree_metrics = evaluate_model(model_instance, x_train, y_train, x_test, y_test, gridSearch_params, gridSearch_bagging_params)\n",
    "\n",
    "decision_tree_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 6 - Random Forest\n",
    "\n",
    "Usemos la función definida en el checkpoint que evalua la performance de modelos en un modelo random forest usando `RandomForestClassifier` con los parámetros por default\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html\n",
    "\n",
    "Los parámetros de GridSearchCV que vamos a probar son \n",
    "\n",
    "``params =   {'n_estimators':[3, 5, 10, 50],\n",
    "          'criterion': ['gini', 'entropy'],\n",
    "          'max_depth': [None, 3, 5],\n",
    "          'min_samples_split': [2,5],\n",
    "          'class_weight':[None, 'balanced']}``\n",
    "\n",
    "(No vamos a hacer bagging sobre este modelo porque ya es un ensamble.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_instance = RandomForestClassifier()\n",
    "x_train = X_train_sc\n",
    "x_test =  X_test_sc\n",
    "gridSearch_params = {'n_estimators':[3, 5, 10, 50],\n",
    "          'criterion': ['gini', 'entropy'],\n",
    "          'max_depth': [None, 3, 5],\n",
    "          'min_samples_split': [2,5],\n",
    "          'class_weight':[None, 'balanced']}\n",
    "\n",
    "gridSearch_bagging_params = None\n",
    "\n",
    "random_forest_metrics = evaluate_model(model_instance, x_train, y_train, x_test, y_test, gridSearch_params, gridSearch_bagging_params)\n",
    "\n",
    "random_forest_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 7 - Evaluación de modelos\n",
    "\n",
    "Vamos a comparar los resultados de los diferentes modelos. Para eso, grafiquemos como barras los scores de los modelos evaluados en el conjunto de testing. \n",
    "\n",
    "¿Cuál es el ganador?\n",
    "\n",
    "Repetir el gráfico mostrando el valor medio el desvío estandard de la validación cruzada. ¿Es el mismo ganador?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_model_metrics = [logistic_metrics, knn_metrics, decision_tree_metrics, random_forest_metrics]\n",
    "all_model_names =  ['logistic', 'knn', 'decision_tree', 'random_forest']\n",
    "\n",
    "data_to_plot = pd.DataFrame(columns = ['model', 'score'])\n",
    "data_to_plot\n",
    "\n",
    "for i in range(len(all_model_names)):\n",
    "    model_name_prefix = all_model_names[i]\n",
    "    model_metric = all_model_metrics[i]        \n",
    "    for model_metric_key in model_metric.keys():    \n",
    "        score = model_metric[model_metric_key]['score']        \n",
    "        data_to_plot = data_to_plot.append({'model': model_name_prefix + '_' + model_metric_key, 'score':score}, ignore_index=True)\n",
    "        \n",
    "data_to_plot.index = data_to_plot.model\n",
    "\n",
    "data_to_plot.sort_values(by = 'score', axis=0, ascending=True, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_to_plot.plot(kind='bar')\n",
    "plt.ylim(0.7, 0.9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_to_plot_cv = pd.DataFrame(columns = ['model', 'score', 'error'])\n",
    "\n",
    "for i in range(len(all_model_names)):\n",
    "    model_name_prefix = all_model_names[i]\n",
    "    model_metric = all_model_metrics[i]        \n",
    "    for model_metric_key in model_metric.keys():    \n",
    "        model = model_metric[model_metric_key]\n",
    "        if 'mean_score_grid_search' in model.keys() and 'std_score_grid_search' in model.keys():\n",
    "            score = model['mean_score_grid_search']        \n",
    "            std = model['std_score_grid_search']        \n",
    "            data_to_plot_cv = data_to_plot_cv.append({'model': model_name_prefix + '_' + model_metric_key, \n",
    "                                            'score':score,\n",
    "                                            'error': std,\n",
    "                                           }, ignore_index=True)\n",
    "        \n",
    "data_to_plot_cv.index = data_to_plot_cv.model\n",
    "\n",
    "data_to_plot_cv.sort_values(by = 'score', axis=0, ascending=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_to_plot_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "x_values = range(data_to_plot_cv.shape[0])\n",
    "y_values = data_to_plot_cv.score\n",
    "rects1 = ax.bar(x_values, y_values,\n",
    "                yerr=data_to_plot_cv.error,\n",
    "                tick_label=data_to_plot_cv.index)\n",
    "\n",
    "ax.set_ylabel('Scores')\n",
    "plt.xticks(rotation=90)\n",
    "plt.ylim(0.7, 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 8 - Importancia de features\n",
    "\n",
    "Veamos ahora la cuál es la importancia de cada variable predictora en el modelo random forest\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html#sklearn.ensemble.RandomForestClassifier.feature_importances_\n",
    "\n",
    "Representemos en un gráfico de barras la importancia de cada una, y su error definido como el desvío estandar de las importancias de cada variable sobre todos los árboles.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest = RandomForestClassifier()\n",
    "random_forest.fit(X_train_sc, y_train)\n",
    "feature_importance = random_forest.feature_importances_\n",
    "feature_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# error:\n",
    "std = np.std([tree.feature_importances_ for tree in random_forest.estimators_], axis=0)\n",
    "std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = data.columns\n",
    "\n",
    "data_to_plot = pd.DataFrame(columns = ['feature', 'importance', 'error'])\n",
    "\n",
    "for i in range(len(feature_importance)):\n",
    "    data_to_plot = data_to_plot.append({'feature': feature_names[i],\n",
    "                                        'importance': feature_importance[i],\n",
    "                                        'error': std[i]\n",
    "                                       }, ignore_index=True)    \n",
    "\n",
    "data_to_plot.sort_values(by = 'importance', axis=0, ascending=False, inplace=True)\n",
    "data_to_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.title(\"Importancia de los features en RandomForest\")\n",
    "x_values = range(data_to_plot.shape[0])\n",
    "y_values = data_to_plot.importance\n",
    "y_err = data_to_plot.error\n",
    "plt.bar(x_values, y_values, color=\"r\", align=\"center\", yerr=y_err )\n",
    "plt.xticks(x_values, data_to_plot.feature, rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Referencias \n",
    "\n",
    "Cross Validation\n",
    "https://scikit-learn.org/stable/modules/cross_validation.html\n",
    "\n",
    "StratifiedKFold\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedKFold.html#sklearn.model_selection.StratifiedKFold\n",
    "\n",
    "Grid Search\n",
    "https://scikit-learn.org/stable/modules/grid_search.html#grid-search\n",
    "\n",
    "ROC\n",
    "https://scikit-learn.org/stable/auto_examples/model_selection/plot_roc_crossval.html#sphx-glr-auto-examples-model-selection-plot-roc-crossval-py\n",
    "\n",
    "BaggingClassifier\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.BaggingClassifier.html\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
