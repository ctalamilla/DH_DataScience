{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial setup\n",
    "%run \"../../../common/0_notebooks_base_setup.py\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<img src='../../../common/logo_DH.png' align='left' width=35%/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section_intro\"></a> \n",
    "## Intro\n",
    "\n",
    "\n",
    "Muchas veces estamos interesados en la interpretabilidad de los modelo además de su performance.\n",
    "\n",
    "Podemos entender la importancia de la interpretabilidad de un modelo en su posterior adopción por parte de las empresas. \n",
    "\n",
    "LIME (Local Interpretable Model-agnostic Explanations) es una biblioteca de Python que intenta resolver el problema de interpretabilidad de los modelos generando explicaciones a nivel local.\n",
    "\n",
    "Para generar confianza en nuestro modelo, ejecutamos cross validation y realizamos tests sobre datos nunca antes presentados al modelo. \n",
    "Estas simulaciones nos dan una vista agregada del rendimiento del modelo sobre datos desconocidos.\n",
    "Pero en general, no podemos entender por qué algunas de nuestras predicciones son correctas mientras que otras no, ni podemos rastrear el camino de decisión de nuestro modelo. En otras palabras, no podemos entender si está aprendiendo o si son conclusiones espurias.\n",
    "\n",
    "LIME es una biblioteca de python que explica cómo decide un modelo de una manera humanamente comprensible.\n",
    "\n",
    "LIME explica la predicción de cualquier clasificador de manera interpretable al aprender un modelo interpretable local alrededor de la predicción.\n",
    "\n",
    "En esta guía vamos a mostrar un ejemplo de uso de LIME sobre un clasificador random forest y ver qué podemos entender de sus resultados.\n",
    "\n",
    "**Documentación**\n",
    "https://lime-ml.readthedocs.io/en/latest/lime.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section_imports\"></a> \n",
    "## Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from lime.lime_tabular import LimeTabularExplainer\n",
    "\n",
    "#%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section_dataset\"></a> \n",
    "## Dataset\n",
    "\n",
    "\n",
    "Para mostrar el funcionamiento de LIME vamos a usar el dataset Titanic que está disponible en https://www.kaggle.com/c/titanic-dataset/data\n",
    "\n",
    "La variable target es `survived`, y vamos a usar como variables predictoras `pclass, sex, sibsp, parch, fare`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../Data/titanic_train.csv')\n",
    "\n",
    "# data preparation\n",
    "data.fillna(0, inplace=True)\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "features = ['pclass_le', 'sex_le','sibsp_le', 'parch_le', 'fare']\n",
    "\n",
    "# label encoding textual data\n",
    "data['pclass_le'] = label_encoder.fit_transform(data['pclass'])\n",
    "data['sibsp_le'] = label_encoder.fit_transform(data['sibsp'])\n",
    "data['sex_le'] = label_encoder.fit_transform(data['sex'])\n",
    "data['parch_le'] = label_encoder.fit_transform(data['parch'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separamos los datos en train y test, manteniendo para test el 30% del dataset original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data[features], data['survived'], test_size=0.3, random_state = 123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos un clasificador random forest y lo entranamos con los datos X_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest_classifier = RandomForestClassifier(n_estimators=500, random_state = 123)\n",
    "random_forest_classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a crear una instancia de `LimeTabularExplainer` \n",
    "\n",
    "https://lime-ml.readthedocs.io/en/latest/lime.html?highlight=limetabularexplainer#lime.lime_tabular.LimeTabularExplainer \n",
    "\n",
    "para después generar explicaciones sobre una predicción usando este objeto.\n",
    "\n",
    "El constructor de `LimeTabularExplainer` recibe como parámetro `training_data` que es un numpy 2d array. Es importante pasarle los datos en un objeto de este tipo y no en un DataFrame de pandas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos de qué tipo es X_train:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformemos X_train en un numpy 2d array;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_explainer = np.array(X_train)\n",
    "type(X_train_explainer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los parámetros del constructor de `LimeTabularExplainer` que vamos a usar son:\n",
    "* training_data – numpy 2d array\n",
    "* mode – “classification” or “regression”, <font color=\"green\">vamos a usar classification</font>\n",
    "* training_labels – labels for training data,  <font color=\"green\">son los valores de la variable target en train</font>\n",
    "* feature_names – list of names (strings) corresponding to the columns in the training data\n",
    "* categorical_features – list of indices (ints) corresponding to the categorical columns. Everything else will be considered continuous. Values in these columns MUST be integers,  <font color=\"green\">son las columnas 0 a 3 inclusive en X_train</font> \n",
    "* discretize_continuous – if True, all non-categorical features will be discretized into quartiles,  <font color=\"green\">va a transformar la columna 4 de X_train usando deciles</font>\n",
    "* discretizer – only matters if discretize_continuous is True. Options are ‘quartile’, ‘decile’ or ‘entropy’,  <font color=\"green\">usamos deciles, pueden probar las otras variantes</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = LimeTabularExplainer(X_train_explainer, \n",
    "                                 mode = \"classification\",\n",
    "                                 training_labels = y_train,\n",
    "                                 feature_names = X_train.columns, \n",
    "                                 categorical_features  = [0, 1, 2, 3],\n",
    "                                 discretize_continuous=True, \n",
    "                                 discretizer = 'decile')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usando el objeto `explainer` y el método `explain_instance` vamos a generar explicaciones sobre una predicción concreta\n",
    "\n",
    "https://lime-ml.readthedocs.io/en/latest/lime.html?highlight=explain_instance#lime.lime_tabular.LimeTabularExplainer.explain_instance\n",
    "\n",
    "En este caso vamos a tomar la fila de índice 13 (puede ser cualquiera) del dataset de test, y usar `explainer` para explicar la predicción (el valor de la variable `survived`) que hace el clasificador random forest entrenado.\n",
    "\n",
    "`explain_instance` recibe como argumentos:\n",
    "\n",
    "* `data_row` que es de tipo 1d numpy array\n",
    "* `predict_fn` – prediction function. For classifiers, this should be a function that takes a numpy array and outputs prediction probabilities. For regressors, this takes a numpy array and returns the predictions. For ScikitClassifiers, this is classifier.predict_proba(). For ScikitRegressors, this is regressor.predict(), <font color=\"green\">usamos classifier.predict_proba()</font>\n",
    "* `num_features` – maximum number of features present in explanation <font color=\"green\">pedimos todas las variables predictoras, que son 5</font>\n",
    "\n",
    "Y devuelve una instancia de tipo `explanation`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 13\n",
    "\n",
    "# necesito que sea un np array:\n",
    "data_row = np.array(X_test[features].iloc[i])\n",
    "explanation = explainer.explain_instance(data_row, random_forest_classifier.predict_proba, num_features=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La clase `explanation` provee métodos para analizar y visualizar el resultado\n",
    "\n",
    "https://lime-ml.readthedocs.io/en/latest/lime.html?highlight=explanation#module-lime.explanation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`as_list` devuelve la lista de tuplas (feature, peso) correspondientes a la predicción\n",
    "\n",
    "https://lime-ml.readthedocs.io/en/latest/lime.html?highlight=explanation#lime.explanation.Explanation.as_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explanation.as_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`as_map` devuelve un diccionario que asocia una etiqueta target a una lista de tuplas (feature_id, peso) asociadas a la predicción\n",
    "\n",
    "https://lime-ml.readthedocs.io/en/latest/lime.html?highlight=explanation#lime.explanation.Explanation.as_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explanation.as_map()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(features[1], features[0], features[3], features[4], features[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`show_in_notebook` muestra en una celda de la notebook el mismo resultado que guardamos con `save_to_file`\n",
    "\n",
    "https://lime-ml.readthedocs.io/en/latest/lime.html?highlight=explanation#lime.explanation.Explanation.show_in_notebook\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explanation.show_in_notebook(show_table=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El gráfico tiene tres partes:\n",
    "\n",
    "* El panel de la izquierda muestra la probabilidad predicha por el modelo (random forest en este caso) para el registro de índice 13 de pertenecer a la clase 0 y de pertencer a la clase 1\n",
    "\n",
    "* El panel del medio muestra las features por orden de importancia. Como en este caso es una clasificación binaria, vemos dos colores. Las features que tienen color naranja son compatibles con la clase 1 y los que tienen color azul son compatibles con la clase 0. \n",
    "Sex_le = 1 significa que cuando el valor de esta feature satisface este criterio, admite la clase 0. \n",
    "El número de coma flotante en las barras horizontales representa la importancia relativa de estas features.\n",
    "\n",
    "* El panel de la derecha usa el mismo código de color que los otros dos. Contiene los valores que corresponden a la fila del DataFrame (la de índice 13) cuya predicción estamos explicando.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos que el panel de la derecha efectivamente representa los datos de la fila de índice 13 del DataFrame de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test[features].iloc[13]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`as_pyplot_figure` devuelve un gráfico de barras que representa explanation, análogo al panel central de `show_in_notebook`\n",
    "\n",
    "https://lime-ml.readthedocs.io/en/latest/lime.html?highlight=explanation#lime.explanation.Explanation.as_pyplot_figure\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explanation.as_pyplot_figure();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`save_to_file` guarda el resultado, idéntico al generado por `show_in_notebook`, en un archivo html \n",
    "\n",
    "https://lime-ml.readthedocs.io/en/latest/lime.html?highlight=explanation#lime.explanation.Explanation.save_to_file\n",
    "\n",
    "(Pueden revisar que esté generado en el mismo directorio donde tienen esta notebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explanation_path = \"./explanation.html\"\n",
    "explanation.save_to_file(explanation_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio:\n",
    "\n",
    "Intenten explicar las predicciones de otras instancias (filas del dataset) de test\n",
    "\n",
    "Analicen cómo cambian las probabilidades y los pesos de las variables para distintos datos de entrada."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section_referencias\"></a> \n",
    "## Referencias\n",
    "\n",
    "\n",
    "Documentación\n",
    "https://lime-ml.readthedocs.io/en/latest/lime.html\n",
    "\n",
    "Decrypting your Machine Learning model using LIME \n",
    "https://towardsdatascience.com/decrypting-your-machine-learning-model-using-lime-5adc035109b5\n",
    "    \n",
    "Paper\n",
    "https://arxiv.org/abs/1602.04938\n",
    "\n",
    "Github\n",
    "https://github.com/marcotcr/lime\n",
    "\n",
    "Blog del autor del paper\n",
    "https://homes.cs.washington.edu/~marcotcr/blog/lime/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
