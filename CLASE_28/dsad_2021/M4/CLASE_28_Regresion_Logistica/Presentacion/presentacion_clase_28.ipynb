{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/paulati/Nuevo vol/paula/dh/2021/dsad_2021_paula/common\n",
      "default checking\n",
      "Running command `conda list`... ok\n",
      "jupyterlab=2.2.6 already installed\n",
      "pandas=1.1.5 already installed\n",
      "bokeh=2.2.3 already installed\n",
      "seaborn=0.11.0 already installed\n",
      "matplotlib=3.3.2 already installed\n",
      "ipywidgets=7.5.1 already installed\n",
      "pytest=6.2.1 already installed\n",
      "chardet=4.0.0 already installed\n",
      "psutil=5.7.2 already installed\n",
      "scipy=1.5.2 already installed\n",
      "statsmodels=0.12.1 already installed\n",
      "scikit-learn=0.23.2 already installed\n",
      "xlrd=2.0.1 already installed\n",
      "Running command `conda install --yes nltk=3.5.0`... ok\n",
      "Collecting package metadata (current_repodata.json): ...working... done\n",
      "Solving environment: ...working... done\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n",
      "\n",
      "unidecode=1.1.1 already installed\n",
      "pydotplus=2.0.2 already installed\n",
      "pandas-datareader=0.9.0 already installed\n",
      "flask=1.1.2 already installed\n"
     ]
    }
   ],
   "source": [
    "# initial setup\n",
    "%run \"../../../common/0_notebooks_base_setup.py\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<link rel=\"stylesheet\" href=\"../../../common/dhds.css\">\n",
    "<div class=\"Table\">\n",
    "    <div class=\"Row\">\n",
    "        <div class=\"Cell grey left\"> <img src=\"https://raw.githubusercontent.com/Digital-House-DATA/ds_blend_2021_img/master/M4/CLASE_28_Regresion_Logistica/Presentacion/img/M4_CLASE_28_portada.jpg\" align=\"center\" width=\"90%\"/></div>\n",
    "        <div class=\"Cell right\">\n",
    "            <div class=\"div-logo\"><img src=\"https://raw.githubusercontent.com/Digital-House-DATA/ds_blend_2021_img/master/common/logo_DH.png\" align=\"center\" width=70% /></div>\n",
    "            <div class=\"div-curso\">DATA SCIENCE</div>\n",
    "            <div class=\"div-modulo\">MÓDULO 4</div>\n",
    "            <div class=\"div-contenido\">Regresión Logística</div>\n",
    "        </div>\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Agenda\n",
    "\n",
    "---\n",
    "\n",
    "- Describir el modelo de regresión logística\n",
    "\n",
    "- Presentar los fundamentos matemáticos de la regresión logística\n",
    "\n",
    "- Entrenar modelos de regresión logística utilizando la biblioteca Scikit-learn\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "<img src = \"https://raw.githubusercontent.com/Digital-House-DATA/ds_blend_2021_img/master/M4/CLASE_28_Regresion_Logistica/Presentacion/img/M4_CLASE_28_logisticregression.png\" align=\"center\" />\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div class=\"div-dhds-fondo-1\"> Introducción\n",
    "<img src=\"https://raw.githubusercontent.com/Digital-House-DATA/ds_blend_2021_img/master/M4/CLASE_28_Regresion_Logistica/Presentacion/img/M4_CLASE_28_separador.png\" align=\"center\" />\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Introducción\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "La regresión logística es un abordaje lineal para resolver **problemas de clasificación**.\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/Digital-House-DATA/ds_blend_2021_img/master/M4/CLASE_28_Regresion_Logistica/Presentacion/img/M4_CLASE_28_ejemplo1.png\" align=\"center\" />\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "¿Podríamos usar una regresión lineal?\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/Digital-House-DATA/ds_blend_2021_img/master/M4/CLASE_28_Regresion_Logistica/Presentacion/img/M4_CLASE_28_ejemplo1_lineal.png\" align=\"center\" />\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Podríamos, pero vamos a obtener valores fuera del rango [0,1], dificultando la interpretación como probabilidad."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "La regresión logística nos permite **modelar la probabilidad** de que la variable objetivo `y` pertenezca a una determinada categoría, dados los valores de las variables `X`.   \n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/Digital-House-DATA/ds_blend_2021_img/master/M4/CLASE_28_Regresion_Logistica/Presentacion/img/M4_CLASE_28_ejemplo1_logistica.png\" align=\"center\" />\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Debemos establecer una **frontera de decisión lineal**\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/Digital-House-DATA/ds_blend_2021_img/master/M4/CLASE_28_Regresion_Logistica/Presentacion/img/M4_CLASE_28_ejemplo1_logistica_umbral.png\" align=\"center\" />\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Introducción (cont.)\n",
    "\n",
    "---\n",
    "\n",
    "Veamos ahora un ejemplo con dos features\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/Digital-House-DATA/ds_blend_2021_img/master/M4/CLASE_28_Regresion_Logistica/Presentacion/img/M4_CLASE_28_ejemplo2.png\" align=\"left\" width =\"50%\"/>\n",
    "\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/Digital-House-DATA/ds_blend_2021_img/master/M4/CLASE_28_Regresion_Logistica/Presentacion/img/M4_CLASE_28_ejemplo2_3D.png\" align=\"right\" width =\"50%\" />\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "También podemos definir una **frontera de decisión lineal** que resuelva el problema\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/Digital-House-DATA/ds_blend_2021_img/master/M4/CLASE_28_Regresion_Logistica/Presentacion/img/M4_CLASE_28_ejemplo2_umbral.png\" align=\"center\"/>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Ejemplo Regresión Logística\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "Queremos predecir la **probabilidad** de que un cliente no pague su tarjeta de crédito (entre en Default):\n",
    "\n",
    "$$ y = \\cases{\n",
    "    0, & \\text{si  No}\\\\\n",
    "    1, & \\text{si  Sí}\n",
    "}$$\n",
    "\n",
    "Los **features** son:\n",
    "\n",
    "- Ingresos (income)\n",
    "\n",
    "- Deuda en su tarjeta de crédito (balance)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"https://raw.githubusercontent.com/Digital-House-DATA/ds_blend_2021_img/master/M4/CLASE_28_Regresion_Logistica/Presentacion/img/M4_CLASE_28_ejemplo3.png\" align=\"center\"/>\n",
    "\n",
    "Observando los datos, decidimos usar como variable predictora `balance` (¿por qué?). \n",
    "\n",
    "Es decir, queremos predecir **p(y = 1 | balance)**\n",
    "\n",
    "Definiendo como umbral 0.5 (podríamos elegir otro!), si la p(y=1|balance) > 0.5 => default = Sí\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div class=\"div-dhds-fondo-1\"> Regresión Logística\n",
    "<img src=\"https://raw.githubusercontent.com/Digital-House-DATA/ds_blend_2021_img/master/M4/CLASE_28_Regresion_Logistica/Presentacion/img/M4_CLASE_28_separador.png\" align=\"center\" />\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## ¿Por qué no podemos estimar la probablidad usando una regresión lineal simple?\n",
    "\n",
    "---\n",
    "\n",
    "Si estimáramos p(y=1 | X) con una regresión lineal, nuestro modelo asumiría la siguiente forma:\n",
    "\n",
    "<p style=\"font-size:20px;\">\n",
    "$$p(X) = \\beta_0 + \\beta_1 . X_1$$\n",
    "</p>\n",
    "donde para abreviar, definimos \n",
    "<p style=\"font-size:20px;\">\n",
    "$$p(X) = p(y = 1 | X)$$\n",
    "</p>\n",
    "\n",
    "Problemas:\n",
    "\n",
    "- Esto arrojaría **valores fuera del rango válido para una probabilidad [0,1]**. \n",
    "\n",
    "- Cuando el problema de clasificación es multiclase, el modelo **interpretaría a las diferentes clases como valores numéricos**.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<p style=\"font-size:20px;\">\n",
    "Tenemos que buscar una función que nos garantice que las estimaciones que hagamos estarán dentro del rango válido de una probabilidad.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## La función logística\n",
    "\n",
    "---\n",
    "\n",
    "<p style=\"font-size:24px;\">\n",
    "$$p(X) = \\frac{e^{\\beta_0 + \\beta_1 . X}}{1 + e^{\\beta_0 + \\beta_1 . X}}$$\n",
    "</p>\n",
    "\n",
    "Sin importar qué valores tome `X` siempre vamos a predecir valores dentro del rango [0,1].\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Lineal vs. Logística\n",
    "\n",
    "---\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/Digital-House-DATA/ds_blend_2021_img/master/M4/CLASE_28_Regresion_Logistica/Presentacion/img/M4_CLASE_28_ejemplo3_probability.png\" align=\"center\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## odds-ratio\n",
    "\n",
    "---\n",
    "\n",
    "El odd es la **probabilidad de que suceda un evento dividido por la probabilidad de que no suceda**. \n",
    "\n",
    "No hay una traducción clara al español, así que usamos el término odd. \n",
    "\n",
    "Los odd **oscilan entre 0 e infinito** y se pueden calcular para la ocurrencia del evento como para la no ocurrencia del evento. \n",
    "\n",
    "<p style=\"font-size:20px;\">\n",
    "$$\\frac{p(X)}{1- p(X)} = e^{\\beta_0 + \\beta_1 . X}$$\n",
    "</p>\n",
    "\n",
    "**Ejemplo**:\n",
    "\n",
    "El odd de sí-votar al partido A es 0.35 / 0.65 = 0.53\n",
    "\n",
    "El odd de no-votar al partido A es 0.65 / 0.35 = 1.86\n",
    "\n",
    "Entonces es 1.86 veces más probable que alguien no sea del partido A a que lo sea. \n",
    "\n",
    "**Los odds se interpretan como ratios, es decir, la cantidad de veces que algo pueda suceder sobre que no pueda suceder**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## log odds\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "El logaritmo de odds-ratio tiene una relación lineal con $X$.\n",
    "\n",
    "<p style=\"font-size:20px;\">\n",
    "$$ log(\\frac{p(X)}{1 - p(X)}) = \\beta_0 + \\beta_1 . X$$\n",
    "</p>\n",
    "\n",
    "En el modelo lineal, los $\\beta_p$ son el cambio promedio en $y$ ante un cambio unitario en $X_p$. \n",
    "\n",
    "En la regresión logística, incrementar una unidad en $X$, cambia el logaritmo del odds-ratio en $\\beta_1$. \n",
    "\n",
    "O, lo que es lo mismo, multiplica el odds por $\\beta_1$. \n",
    "\n",
    "La relación entre $p(X)$ y $X$ no es una línea recta, entonces cuánto cambia $p(X)$ ante un cambio unitario en $X$ depende de los valores de $X$. \n",
    "\n",
    "El signo de $\\beta_1$ expresa la dirección de cambio en $p(X)$, independientemente del valor de $X$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Probabilidad, odds-ratio, log odds\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/Digital-House-DATA/ds_blend_2021_img/master/M4/CLASE_28_Regresion_Logistica/Presentacion/img/M4_CLASE_28_odds.png\" align=\"center\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div class=\"div-dhds-fondo-1\"> Ejemplos\n",
    "<img src=\"https://raw.githubusercontent.com/Digital-House-DATA/ds_blend_2021_img/master/M4/CLASE_28_Regresion_Logistica/Presentacion/img/M4_CLASE_28_separador.png\" align=\"center\" />\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Ejemplo Regresión Logística. Ajuste variable predictora cuantitativa.\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "Siguiendo nuestro ejemplo de default en tarjetas de crédito obtenemos estos valores para el modelo ajustado:\n",
    "    \n",
    "<img src=\"https://raw.githubusercontent.com/Digital-House-DATA/ds_blend_2021_img/master/M4/CLASE_28_Regresion_Logistica/Presentacion/img/M4_CLASE_28_ejemplo3_fit1.png\" align=\"center\"/>\n",
    "\n",
    "Observamos que un incremento de $1 en el balance incrementa 0.0055 unidades el \"log odds-ratio\".\n",
    "\n",
    "Existe un estadístico z que es análogo al estadístico t en regresión lineal. \n",
    "\n",
    "$H_0$: $\\beta_1 = 0$ (la probabilidad de default no depende del balance)\n",
    "\n",
    "$H_1$: $\\beta_1 \\ne 0$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Ejemplo Regresión Logística - Predicción\n",
    "\n",
    "---\n",
    "\n",
    "Una vez que hemos estimados los coeficientes del modelo, podemos hacer predicciones y computar la probabilidad de default para algún valor dado de balance.\n",
    "\n",
    "Por ejemplo, para un balance \\$1000 tenemos que está por debajo del 1%\n",
    "\n",
    "<p style=\"font-size:20px;\">\n",
    "$$ \\hat{p}(X) = \\frac{e^{\\hat{\\beta_0} + \\hat{\\beta_1} . X}}{1 + e^{\\hat{\\beta_0} + \\hat{\\beta_1} . X}} = \\frac{e^{-10.6513 + 0.0055 . 1000}}{1 + e^{-10.6513 + 0.0055 . 1000}} = 0.00576 $$\n",
    "</p>\n",
    "\n",
    "En cambio, para un balance de \\$2000 es mucho más grande y está cerca del 58%\n",
    "\n",
    "<p style=\"font-size:20px;\">\n",
    "$$ \\hat{p}(X) = \\frac{e^{-10.6513 + 0.0055 . 2000}}{1 + e^{-10.6513 + 0.0055 . 2000}} = 0.586 $$\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Ejemplo Regresión Logística. Ajuste variable predictora cualitativa.\n",
    "\n",
    "---\n",
    "\n",
    "La regresión logística admite también variables cualitativas. \n",
    "\n",
    "Entrenamos un modelo utilizando la condición de ser estudiante sobre la probabilidad de default.\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/Digital-House-DATA/ds_blend_2021_img/master/M4/CLASE_28_Regresion_Logistica/Presentacion/img/M4_CLASE_28_ejemplo3_fit2.png\" align=\"center\" /> \n",
    "\n",
    "En este caso, el coeficiente es positivo, lo cual indica que **ser estudiante tiene una relación positiva con ser potencial moroso**. \n",
    "\n",
    "¿Qué pueden decir de la significancia del coeficiente?\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Ejemplo Regresión Logística - Predicción\n",
    "\n",
    "---\n",
    "\n",
    "Podemos estimar las probabilidades de entrar en default siendo estudiante y no siéndolo\n",
    "\n",
    "<p style=\"font-size:20px;\">\n",
    "$$ \\hat{p}(default = Sí | X = 1) = \\frac{e^{-3.5041 + 0.4049 . 1}}{1 + e^{-3.5041 + 0.4049 . 1}} = 0.0431 $$    \n",
    "</p>\n",
    "\n",
    "<p style=\"font-size:20px;\">\n",
    "$$ \\hat{p}(default = Sí | X = 0) = \\frac{e^{-3.5041 + 0.4049 . 0}}{1 + e^{-3.5041 + 0.4049 . 0}} = 0.0292 $$    \n",
    "</p>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div class=\"div-dhds-fondo-1\"> Regresión Logística Múltiple\n",
    "<img src=\"https://raw.githubusercontent.com/Digital-House-DATA/ds_blend_2021_img/master/M4/CLASE_28_Regresion_Logistica/Presentacion/img/M4_CLASE_28_separador.png\" align=\"center\" />\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Regresión Logística Múltiple\n",
    "\n",
    "---\n",
    "\n",
    "De forma análoga al caso de regresión lineal, pensemos en el problema de predecir una variable cualitativa binaria con una serie de p features.\n",
    "\n",
    "Nuestro modelo de regresión logística múltiple quedará definido:\n",
    "\n",
    "<p style=\"font-size:24px;\">\n",
    "$$p(X) = \\frac{e^{\\beta_0 + \\beta_1 . X_1 + \\beta_2 . X_2 + ... + \\beta_p . X_p}}{1 + e^{\\beta_0 + \\beta_1 . X_1 + \\beta_2 . X_2 + ... + \\beta_p . X_p}}$$\n",
    "</p>\n",
    "\n",
    "\n",
    "Y reescribiéndolo en términos de logs odds:\n",
    "\n",
    "<p style=\"font-size:20px;\">\n",
    "$$ log(\\frac{p(X)}{1 - p(X)}) = \\beta_0 + \\beta_1 . X_1 + \\beta_2 . X_2 + ... + \\beta_p . X_p$$\n",
    "</p>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Ejemplo Regresión Logística Múltiple\n",
    "\n",
    "---\n",
    "\n",
    "Veamos los resultados de aplicar este modelo para predecir la probabilidad de default según el ingreso, el balance y la condición de estudiante.\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/Digital-House-DATA/ds_blend_2021_img/master/M4/CLASE_28_Regresion_Logistica/Presentacion/img/M4_CLASE_28_ejemplo3_fit3.png\" align=\"center\" />\n",
    "\n",
    "¿Qué pueden decir de los resultados?\n",
    "\n",
    "¿Ven algo raro?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"https://raw.githubusercontent.com/Digital-House-DATA/ds_blend_2021_img/master/M4/CLASE_28_Regresion_Logistica/Presentacion/img/M4_CLASE_28_ejemplo4.png\" align=\"center\" />\n",
    "\n",
    "En el cuadro de la izquierda, en <a style=\"color:orange;\">naranja</a> se representan a los estudiantes y en <a style=\"color:blue;\">azul</a> a los no estudiantes. \n",
    "\n",
    "La línea punteada representa el % total de defaults, mientras que la línea sólida representa el % de defaults en función del balance de la tarjeta de crédito\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div class=\"div-dhds-fondo-1\"> Función de costo\n",
    "<img src=\"https://raw.githubusercontent.com/Digital-House-DATA/ds_blend_2021_img/master/M4/CLASE_28_Regresion_Logistica/Presentacion/img/M4_CLASE_28_separador.png\" align=\"center\" />\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Función de costo\n",
    "\n",
    "---\n",
    "\n",
    "Como en todos los algoritmos de Machine Learning, debe definirse una **función de costo que dependa de los parámetros del modelo**. De esta manera, el entrenamiento o \"aprendizaje\" consiste en **encontrar los parámetros que optimicen dicha función**.\n",
    "\n",
    "En el caso de la regresión logística se busca **maximizar la verosimilitud del modelo**, es decir que las estimaciones de las probabilidades de las observaciones que pertenezcan a la clase 1 sean cercanas a 1 y lo mismo para las que pertenezcan a la clase 0. \n",
    "\n",
    "Matemáticamente:\n",
    "\n",
    "<p style=\"font-size:24px;\">\n",
    "$$L = \\prod_{i: y_i = 1}P(y = 1 | x = X) . \\prod_{i: y_i = 0}(1 - P(y = 1 | x = X))$$\n",
    "</p>    \n",
    "\n",
    "Tomando el logaritmo:\n",
    "    \n",
    "<p style=\"font-size:24px;\">\n",
    "$$LL = \\sum_{i=1}^m{y_i . log(P(y_i = 1 | x_i = X)) + (1-y_i).log(1 - P(y_i = 1 | x_i = X))}$$\n",
    "</p>    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<p style=\"font-size:24px;\">\n",
    "$$LL = \\sum_{i=1}^m{y_i . log(P(y_i = 1 | x_i = X)) + (1-y_i).log(1 - P(y_i = 1 | x_i = X))}$$\n",
    "</p>    \n",
    "\n",
    "Cuando $y_i = 1$ se suman los:\n",
    "\n",
    "<p style=\"font-size:24px;\">\n",
    "$$log(P(y_i = 1 | x_i = X))$$\n",
    "</p>    \n",
    "\n",
    "que deberían resultar en valores cercanos a 1.\n",
    "\n",
    "Cuando $y_i = 0$ se suman los:\n",
    "\n",
    "<p style=\"font-size:24px;\">\n",
    "$$log(1 - P(y_i = 1 | x_i = X))$$\n",
    "</p>    \n",
    "\n",
    "que deberían resultar en valores cercanos a 0.\n",
    "\n",
    "Esto se conoce como **Maximum Likelihood Estimation o MLE**. \n",
    "\n",
    "Como la función de costo es algo que debe minimizarse, se trabaja con el opuesto y se promedia:\n",
    "\n",
    "<p style=\"font-size:24px;\">\n",
    "$$J = \\frac{-1}{m} . LL$$\n",
    "</p>    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "##  Regresión Logística con una variable predictora\n",
    "\n",
    "---\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/Digital-House-DATA/ds_blend_2021_img/master/M4/CLASE_28_Regresion_Logistica/Presentacion/img/M4_CLASE_28_logistic_animation.gif\" align=\"center\" width=\"70%\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "##  Regresión Logística con dos variables predictoras\n",
    "\n",
    "---\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/Digital-House-DATA/ds_blend_2021_img/master/M4/CLASE_28_Regresion_Logistica/Presentacion/img/M4_CLASE_28_logistic_animation_2.gif\" align=\"center\" width=\"60%\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div class=\"div-dhds-fondo-1\"> Regularización\n",
    "<img src=\"https://raw.githubusercontent.com/Digital-House-DATA/ds_blend_2021_img/master/M4/CLASE_28_Regresion_Logistica/Presentacion/img/M4_CLASE_28_separador.png\" align=\"center\" />\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Regularización\n",
    "\n",
    "---\n",
    "\n",
    "<table>\n",
    "<tr>    \n",
    "<td style=\"width:60%;font-size:16px;line-height:2;\">    \n",
    "Recordemos que:\n",
    "<ul>    \n",
    "<li>Podemos pensar en la regularización como agregar (o aumentar) el sesgo si nuestro modelo sufre de (alta) varianza (es decir, sobreajusta los datos de entrenamiento).</li> \n",
    "<li>Por otro lado, un sesgo excesivo dará como resultado un ajuste insuficiente (un indicador característico de un sesgo alto es que el modelo muestra un rendimiento \"malo\" tanto para el conjunto de datos de entrenamiento como de prueba).</li> \n",
    "<li>Sabemos que nuestro objetivo en un modelo no regularizado es minimizar la función de costo, es decir, queremos encontrar los pesos de las features que corresponden al costo mínimo global (la función de costo en la regresión logística es convexa).</li>     \n",
    "</ul>\n",
    "</td>\n",
    "<td>\n",
    "<img src=\"https://raw.githubusercontent.com/Digital-House-DATA/ds_blend_2021_img/master/M4/CLASE_28_Regresion_Logistica/Presentacion/img/M4_CLASE_28_unregularized.png\" align=\"center\"/>\n",
    "</td>    \n",
    "</tr>    \n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<table>\n",
    "<tr>    \n",
    "<td style=\"width:60%;font-size:16px;line-height:2;\">    \n",
    "\n",
    "\n",
    "Si regularizamos la función de costo (por ejemplo, a través de la regularización L2), agregamos un término adicional a nuestra función de costo (J) que aumenta a medida que aumenta el valor de los pesos de sus parámetros (w ó $\\beta$). \n",
    "\n",
    "    \n",
    "Tengamos en cuenta que a la regularización agregamos un nuevo hiperparámetro, $\\lambda$, para controlar la fuerza de la regularización.\n",
    "\n",
    "        \n",
    "<p style=\"font-size:20px;\">\n",
    "$L2: \\frac{\\lambda}{2} . \\lVert{w}\\rVert^2  = \\frac{\\lambda}{2} . \\sum_{j=1}^{p}w_j^2$\n",
    "</p>\n",
    "\n",
    "<p style=\"font-size:20px;\">\n",
    "$J(w) = J + \\frac{\\lambda}{2} . \\lVert{w}\\rVert^2 $\n",
    "</p>    \n",
    "\n",
    "</td>\n",
    "<td>\n",
    "        \n",
    "<img src=\"https://raw.githubusercontent.com/Digital-House-DATA/ds_blend_2021_img/master/M4/CLASE_28_Regresion_Logistica/Presentacion/img/M4_CLASE_28_regularized.png\" align=\"center\"/>\n",
    "    \n",
    "</td>    \n",
    "</tr>    \n",
    "</table>    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div class=\"div-dhds-fondo-1\"> Scikit-learn\n",
    "<img src=\"https://raw.githubusercontent.com/Digital-House-DATA/ds_blend_2021_img/master/M4/CLASE_28_Regresion_Logistica/Presentacion/img/M4_CLASE_28_separador.png\" align=\"center\" />\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Ejemplo \n",
    "\n",
    "---\n",
    "\n",
    "Vamos a ajustar un modelo de regresión logística para el dataset <a href=\"https://rdrr.io/cran/ISLR/man/Default.html\" taget=\"_blank\">Default</a>, un conjunto de datos simulados que contiene información sobre diez mil clientes. \n",
    "\n",
    "El objetivo aquí es predecir qué clientes incumplirán con la deuda de su tarjeta de crédito.\n",
    "\n",
    "Vamos a usar scikit-learn <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\" target=\"_blank\">LogisticRegression</a>.\n",
    "\n",
    "Esta clase implementa la regresión logística regularizada utilizando la biblioteca \"liblinear\", los métodos \"newton-cg\", \"sag\", \"saga\" y \"lbfgs\". **Tengamos en cuenta que la regularización se aplica por default**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>default</th>\n",
       "      <th>student</th>\n",
       "      <th>balance</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>729.526495</td>\n",
       "      <td>44361.625074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>817.180407</td>\n",
       "      <td>12106.134700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>1073.549164</td>\n",
       "      <td>31767.138947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>529.250605</td>\n",
       "      <td>35704.493935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>785.655883</td>\n",
       "      <td>38463.495879</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  default student      balance        income\n",
       "0      No      No   729.526495  44361.625074\n",
       "1      No     Yes   817.180407  12106.134700\n",
       "2      No      No  1073.549164  31767.138947\n",
       "3      No      No   529.250605  35704.493935\n",
       "4      No      No   785.655883  38463.495879"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('../Data/Default.csv', sep=\"\\t\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Vemos que las categorías están muy desbalanceadas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "No     9667\n",
       "Yes     333\n",
       "Name: default, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.default.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Convertimos a dummies las variables categóricas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>student_Yes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   student_Yes\n",
       "0            0\n",
       "1            1\n",
       "2            0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student_dummy = pd.get_dummies(data.student, drop_first = True, prefix = 'student')\n",
    "student_dummy.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>default</th>\n",
       "      <th>student</th>\n",
       "      <th>balance</th>\n",
       "      <th>income</th>\n",
       "      <th>student_Yes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>729.526495</td>\n",
       "      <td>44361.625074</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>817.180407</td>\n",
       "      <td>12106.134700</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>1073.549164</td>\n",
       "      <td>31767.138947</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  default student      balance        income  student_Yes\n",
       "0      No      No   729.526495  44361.625074            0\n",
       "1      No     Yes   817.180407  12106.134700            1\n",
       "2      No      No  1073.549164  31767.138947            0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.concat([data, student_dummy], axis = 1)\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "X = data[['student_Yes', 'balance', 'income']]\n",
    "y = data.default"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Creamos los conjuntos de entrenamiento y test, estableciendo el valor del parámetro `stratify` para que los datos se dividan de forma estratificada según las etiquetas de default. Esto construye conjuntos de entrenamiento y test que mantienen la misma proporción de registros en cada categoría que en el dataset original."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state = 12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Comprobemos que se mantienen las proporciones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0333"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.default.value_counts()['Yes'] / data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03333333333333333"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()['Yes'] / y_train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0332"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts()['Yes'] / y_test.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Instanciamos una regresión logística:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "logistic_regression = LogisticRegression(penalty='none') # sin regularización\n",
    "logistic_regression.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['No', 'No', 'No', ..., 'No', 'No', 'No'], dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_pred = logistic_regression.predict(X_test)\n",
    "y_test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.97675832e-01, 2.32416770e-03],\n",
       "       [9.98876259e-01, 1.12374110e-03],\n",
       "       [9.96638594e-01, 3.36140624e-03],\n",
       "       ...,\n",
       "       [9.67782530e-01, 3.22174700e-02],\n",
       "       [9.14285262e-01, 8.57147383e-02],\n",
       "       [9.99920761e-01, 7.92386434e-05]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_pred_proba = logistic_regression.predict_proba(X_test)\n",
    "y_test_pred_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9684"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Aunque el valor de accuracy resultó alto (97%), vemos en la matriz de confusión que la performance para la etiqueta 'Yes' es bastante mala.\n",
    "\n",
    "De los 83 registros con etiqueta 'Yes'\n",
    "\n",
    "- clasificó correctamente 17, o sea 20%.\n",
    "\n",
    "- clasificó erroneamente 66, o sea 80%.\n",
    "\n",
    "Para la etiqueta 'No' la performance es buena:\n",
    "\n",
    "De los 2417 registros con etiqueta 'No'\n",
    "\n",
    "- clasificó correctamente 2404, o sea 99.5%.\n",
    "\n",
    "- clasificó erroneamente 13, o sea 0.5%.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2404,   13],\n",
       "       [  66,   17]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "El valor de $\\beta_0$ en la regresión logística es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-3.01195506])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_regression.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Los $\\beta$ de la regresión logística son:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-4.01670288e+00,  4.10753666e-03, -1.31786584e-04]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_regression.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "El modelo queda representado por\n",
    "<p style=\"font-size:24px;\">\n",
    "$$ \\hat{p}(X) = \\frac{e^{\\hat{\\beta_0} + \\hat{\\beta_1} . student\\_Yes + \\hat{\\beta_2} . balance + \\hat{\\beta_3} . income}}{1 + e^{\\hat{\\beta_0} + \\hat{\\beta_1} . student\\_Yes + \\hat{\\beta_2} . balance + \\hat{\\beta_3} . income}} = \\frac{e^{-3.01 - 4.01 . student\\_Yes + 0.004 . balance - 0.0001 . income}}{1 + e^{-3.01 - 4.01 . student\\_Yes + 0.004 . balance - 0.0001 . income}}$$\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Observaciones:\n",
    "\n",
    "**No se requiere estandarización para la regresión logística**. El objetivo principal de estandarizar features es ayudar a la convergencia de la técnica utilizada para la optimización. \n",
    "\n",
    "Si usamos **regresión logística con regularización de Lasso o Ridge debemos estandarizar las features**\n",
    "\n",
    "En la práctica guiada verán un ejemplo de uso de statsmodels para ajustar una regresión logística.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div class=\"div-dhds-fondo-1\"> Hands-on\n",
    "<img src=\"https://raw.githubusercontent.com/Digital-House-DATA/ds_blend_2021_img/master/M4/CLASE_28_Regresion_Logistica/Presentacion/img/M4_CLASE_28_separador.png\" align=\"center\" />\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Hands-on\n",
    "\n",
    "---\n",
    "\n",
    "### Ejercicio 1\n",
    "\n",
    "Aplicar regularización de Lasso para predecir la variable default del dataset Default.csv\n",
    "\n",
    "\n",
    "### Ejercicio 2\n",
    "\n",
    "2.1 Asignar aleatoriamente la clase 'Unknown' al 20% de los registros que actualmente pertenecen a la clase 'No'.\n",
    "\n",
    "2.2 Ajustar un modelo de regresión logística multiclase usando scikit-learn\n",
    "\n",
    "2.3 Construir un dataset con las tres clases balanceadas y ajustar un modelo de regresión logística multiclase usando scikit-learn. Comparemos los resultados con el modelo anterior.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Solución\n",
    "\n",
    "---\n",
    "\n",
    "### Ejercicio 1\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, multilabel_confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('../Data/Default.csv', sep=\"\\t\")\n",
    "\n",
    "student_dummy = pd.get_dummies(data.student, drop_first = True, prefix = 'student')\n",
    "student_dummy.head(3)\n",
    "\n",
    "data = pd.concat([data, student_dummy], axis = 1)\n",
    "\n",
    "X = data[['student_Yes', 'balance', 'income']]\n",
    "y = data.default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state = 12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Como aplicamos regularización, estandarizamos las features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "logistic_regression = LogisticRegression(penalty='l1', solver= 'liblinear')\n",
    "logistic_regression.fit(X_train_scaled, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['No', 'No', 'No', ..., 'No', 'No', 'No'], dtype=object)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_pred = logistic_regression.predict(X_test_scaled)\n",
    "y_test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9744"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2404,   13],\n",
       "       [  51,   32]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "La matriz de confusión es mejor que la obtenida en el ejemplo sin regularización (hay menos casos mal clasificados).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.29599402,  2.72356118,  0.09481735]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_regression.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Tarea (adicional y opcional!):\n",
    "\n",
    "Usar cross validation estratificada para determinar el valor de C óptimo\n",
    "\n",
    "C: float, default=1.0\n",
    "Inverse of regularization strength; must be a positive float. Like in support vector machines, smaller values specify stronger regularization.\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegressionCV.html\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedKFold.html#sklearn.model_selection.StratifiedKFold\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Ejercicio 2\n",
    "\n",
    "---\n",
    "\n",
    "### 2.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('../Data/Default.csv', sep=\"\\t\")\n",
    "\n",
    "student_dummy = pd.get_dummies(data.student, drop_first = True, prefix = 'student')\n",
    "student_dummy.head(3)\n",
    "\n",
    "data = pd.concat([data, student_dummy], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Modificamos algunos datos para asignarle la etiqueta 'Unknown'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "No         7734\n",
       "Unknown    1933\n",
       "Yes         333\n",
       "Name: default, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = data.default == 'No'\n",
    "sample_count = round(np.sum(mask) * 0.2)\n",
    "universe = np.reshape(np.where(mask), -1)\n",
    "unknown_indexes = np.random.choice(universe, size = sample_count, replace = False)\n",
    "data.loc[unknown_indexes, 'default'] = 'Unknown'\n",
    "data.default.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 2.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "X = data[['student_Yes', 'balance', 'income']]\n",
    "y = data.default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state = 127)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "logistic_regression = LogisticRegression(penalty='none', multi_class = 'multinomial', class_weight = 'balanced')\n",
    "logistic_regression.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['No', 'Yes', 'No', ..., 'Yes', 'No', 'Yes'], dtype=object)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_pred = logistic_regression.predict(X_test)\n",
    "y_test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.456"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1000,  261,  673],\n",
       "       [ 272,   63,  148],\n",
       "       [   3,    3,   77]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_test_pred, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1934\n",
      "483\n",
      "83\n"
     ]
    }
   ],
   "source": [
    "print(sum(y_test == 'No'))\n",
    "print(sum(y_test == 'Unknown'))\n",
    "print(sum(y_test == 'Yes'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Observemos que:\n",
    "\n",
    "- Este clasificador es bastante malo.\n",
    "\n",
    "- El código utilizado para ajustar un modelo de regresión logística multiclase es casi idéntico al de clasificación binaria, asignando el valor del parámetro `multi_class` al constructor `LogisticRegression`:\n",
    "\n",
    "```python\n",
    "logistic_regression = LogisticRegression(penalty='none', multi_class = 'multinomial', class_weight = 'balanced')\n",
    "```\n",
    "El valor balanced del parámetro `class_weight` da mayor peso a las instancias de categorías menos frecuentes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 2.3\n",
    "\n",
    "Ahora vamos a construir un dataset balanceando las 3 categorías target del dataset original, y vamos a ajustar otra regresión logística"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "No         7734\n",
       "Unknown    1933\n",
       "Yes         333\n",
       "Name: default, dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.default.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Yes        333\n",
       "No         333\n",
       "Unknown    333\n",
       "Name: default, dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_unknown = data.loc[data.default == 'Unknown', ]\n",
    "data_no = data.loc[data.default == 'No', ]\n",
    "data_yes = data.loc[data.default == 'Yes', ]\n",
    "data_balanced = pd.concat([data_unknown.sample(n = 333, replace = False), data_no.sample(n = 333, replace = False), data_yes], axis = 0)\n",
    "data_balanced.default.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "X = data_balanced[['student_Yes', 'balance', 'income']]\n",
    "y = data_balanced.default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state = 127)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "logistic_regression = LogisticRegression(penalty='none', multi_class = 'multinomial')\n",
    "logistic_regression.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "y_test_pred = logistic_regression.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "#logistic_regression.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.52"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['No', 'Unknown', 'Yes'], dtype=object)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_regression.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[51,  6, 26],\n",
       "       [50,  6, 28],\n",
       "       [ 9,  1, 73]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_test_pred, )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Vemos que:\n",
    "\n",
    "* el clasificador sigue teniendo una performance bastante mala, aunque es mejor que el obtenido en la solución anterior\n",
    "\n",
    "* la clase peor clasificada en \"Unknown\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div class=\"div-dhds-fondo-1\"> Conclusiones\n",
    "<img src=\"https://raw.githubusercontent.com/Digital-House-DATA/ds_blend_2021_img/master/M4/CLASE_28_Regresion_Logistica/Presentacion/img/M4_CLASE_28_separador.png\" align=\"center\" />\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Conclusiones\n",
    "\n",
    "---\n",
    "\n",
    "- Modelo es útil para abordar problemas de clasificación con una variable target cualitativa o categórica, generalmente binaria.\n",
    "\n",
    "- La relación entre la variable dependiente y los predictores es lineal al realizar la transformación logística de los datos.\n",
    "\n",
    "- Pueden interpretarse los valores predichos por el modelo como \"probabilidades\" de cada uno de las categorías de la variable target.\n",
    "\n",
    "- Podemos realizar la interpretación de la influencia de las variables predictoras en términos de odds-ratio.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div class=\"div-dhds-fondo-1\"> Referencias\n",
    "<img src=\"https://raw.githubusercontent.com/Digital-House-DATA/ds_blend_2021_img/master/M4/CLASE_28_Regresion_Logistica/Presentacion/img/M4_CLASE_28_separador.png\" align=\"center\" />\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Referencias\n",
    "\n",
    "---\n",
    "\n",
    "<a href=\"https://towardsdatascience.com/animations-of-logistic-regression-with-python-31f8c9cb420\" target= \"_blank\">Animations of logistic regression with python</a>\n",
    "\n",
    "<a href=\"https://medium.com/swlh/from-animation-to-intuition-linear-regression-and-logistic-regression-f641a31e1caf\" target= \"_blank\">From animation to intuition linear regression and logistic regression</a>\n",
    "\n",
    "<a href=\"https://towardsdatascience.com/building-a-logistic-regression-in-python-step-by-step-becd4d56c9c8\" target= \"_blank\">Building a logistic regression in python step by step</a>\n",
    "\n",
    "<a href=\"https://dataaspirant.com/how-logistic-regression-model-works/\" target= \"_blank\">How logistic regression model works?</a>\n",
    "\n",
    "<a href=\"https://github.com/rasbt/python-machine-learning-book/blob/master/faq/regularized-logistic-regression-performance.md\" target= \"_blank\">Regularization in logistic regression</a>\n",
    "\n",
    "<a href=\"https://www.kaggle.com/satishgunjal/multiclass-logistic-regression-using-sklearn\" target= \"_blank\">Multiclass logistic regression using sklearn</a>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
