{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial setup\n",
    "%run \"../../../common/0_notebooks_base_setup.py\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<img src='../../../common/logo_DH.png' align='left' width=35%/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introducción\n",
    "\n",
    "En este checkpoint vamos a realizar un modelo de clasificación basado en árboles de decisión para predecir si una pelicula va a obtener un premio oscar o no. Veremos como graficar los árboles de decisión obtenidos y como varía la precisión luego de limitar la profundidad del mismo.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "En esta clase usaremos un dataset con info de películas (\"Movie_classification.csv\").  \n",
    "Este dataset esta conformado por los siguientes features:  \n",
    "\n",
    " *   **Marketing expense:**    (float64)    Gasto total en Marketing      \n",
    " *   **Production expense:**   (float64)    Gasto total de Producción\n",
    " *   **Multiplex coverage:**   (float64)    Cobertura promedio de Multiplex\n",
    " *   **Budget:**               (float64)    Presupuesto\n",
    " *   **Movie_length:**         (float64)    Duración de la película\n",
    " *   **Lead_ Actor_Rating:**   (float64)    Puntaje sobre el actor principal\n",
    " *   **Lead_Actress_rating:**  (float64)    Puntaje sobre la actriz principal\n",
    " *   **Director_rating:**      (float64)    Puntaje sobre el Director\n",
    " *   **Producer_rating:**      (float64)    Puntaje sobre el Productor\n",
    " *   **Critic_rating:**        (float64)    Puntaje que le puso la crítica\n",
    " *   **Trailer_views:**        (int64)      Cantidad de vistas del Trailer\n",
    " *   **3D_available:**         (object)     Si esta disponible en 3D (Yes/No)\n",
    " *   **Time_taken:**           (float64)    Duración de la película\n",
    " *   **Twitter_hastags:**      (float64)    Cantidad de menciones en twitter\n",
    " *   **Genre:**                (object)     Genero de la película\n",
    " *   **Avg_age_actors:**       (int64)      Edad promedio de los actores\n",
    " *   **Num_multiplex:**        (int64)      Cantidad de Multiplex\n",
    " *   **Collection:**           (int64)      Recaudación\n",
    " *   **Start_Tech_Oscar:**     (int64)      Si recibió un oscar o no.\n",
    " \n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "#import seaborn as sns\n",
    "#import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 1 - Importar datos\n",
    "\n",
    "1) Leamos los datos de \"Movie_classification.csv\" y lo guardamos en un dataframe de pandas.  \n",
    "2) Veamos cuántos registros hay en cada DataFrame y de qué tipos son los datos de cada columna.   \n",
    "3) Veamos los primeros registros de cada DataFrame para verificar que los datos fueron importados correctamente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 2 - Imputación de valores faltantes\n",
    "\n",
    "Veamos si existen valores faltantes y en tal caso imputemos los mismos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vemos la cantidad de valores que tiene cada columna\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 3 - Generación de Variables Dummies.\n",
    "\n",
    "Veamos si existen variables categóricas y en tal caso generar variables dummies para dichas columnas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 4 - Features, Target\n",
    "\n",
    "Construyamos una matriz de features (X) y el vector target (Y) para predecir `Start_Tech_Oscar` en el dataset de datos completos\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 5 - Train Test Split\n",
    "\n",
    "Constuyamos los conjuntos de train y test, asignando el 70% de los registros a train y el 30% a test\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 6 - Entrenamos el árbol de clasificación\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html  \n",
    "\n",
    "Entrenemos el árbol de clasificación y realizar las predicciones tanto para el dataset de entrenamiento como el de pruebas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 7 - Verificamos la performance del modelo\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html  \n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html  \n",
    "\n",
    "Importemos las librerías de `accuracy_score`  y `confusion_matrix` para analizar la performance de nuestro modelo tanto para el dataset de entrenamiento como el de pruebas \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recordamos que la matriz de confusión tiene la siguiente forma:\n",
    "\n",
    "<img style=\"float: center;\" src=\"img/matriz_confusion.png\">\n",
    "\n",
    "<img style=\"float: center;\" src=\"img/matriz_confusion_2.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los árboles de decisión implementados en skitlearn ofrecen un atributo llamado `feature_importances_`. Es la contribunción a la reducción de las impurezas a lo largo de todo el árbol.  \n",
    "Observemos los resultados del atributo `feature_importances_`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 8 - Graficamos el modelo de ML.\n",
    "\n",
    "Es necesario tener instaladas las librerias de `graphviz` y `pydotplus`\n",
    "\n",
    "```\n",
    "> conda install graphviz\n",
    "> pip install pydotplus\n",
    "```\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.tree.export_graphviz.html  \n",
    "https://chrisalbon.com/machine_learning/trees_and_forests/visualize_a_decision_tree/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 9 - Analizamos como varía la performance al reducir la altura del árbol (tree prunning).\n",
    "\n",
    "Realizamos tree prunning definiendo los siguientes hiper-parámetros:\n",
    " - min_samples_leaf = 20\n",
    " - max_depth = 4  \n",
    " \n",
    "Luego graficamos el árbol entrenado y verificamos la performance en el dataset de pruebas.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 10 - Optimizamos nuestro árbol de decisión ajustando los hiperparámetros mediante el uso de gridsearch.\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html  \n",
    "\n",
    "Optimizamos el modelo, aplicando gridseach con los siguientes hiperparametros:\n",
    "\n",
    "```python \n",
    "params_grid = { \"criterion\" : [\"gini\", \"entropy\"],\n",
    "                \"min_samples_leaf\": [5,10,15,20,None], \n",
    "                \"max_depth\" : [1,2,3,4,5,6,8,9,10,11,12,13,14,15,16,17,None],\n",
    "                \"min_samples_split\": [2, 3, 4,None]}\n",
    "``` \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
