{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial setup\n",
    "%run \"../../../common/0_notebooks_base_setup.py\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='../../../common/logo_DH.png' align='left' width=35%/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Series de Tiempo - Práctica Guiada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section_toc\"></a> \n",
    "## Tabla de Contenidos\n",
    "\n",
    "[1- Intro](#section_intro)\n",
    "\n",
    "[2- Descomposición de una serie de tiempo](#section_descomposicion)\n",
    "\n",
    "$\\hspace{.5cm}$[2.1- Tendencia](#section_tendencia)\n",
    "\n",
    "$\\hspace{.5cm}$[2.2- Estacionalidad](#section_estacionalidad)\n",
    "\n",
    "[3- Primeros modelos para prónosticos](#section_modelos_basicos)\n",
    "\n",
    "$\\hspace{.5cm}$[3.1- Análisis exploratorio y preprocesamiento de los datos](#section_eda_preprocesamiento)\n",
    "\n",
    "$\\hspace{.5cm}$[3.2- Media Constante](#section_media_constante)\n",
    "\n",
    "$\\hspace{.5cm}$[3.3- Random Walk](#section_random_walk)\n",
    "\n",
    "$\\hspace{.5cm}$[3.4- Tendencia Lineal](#section_tendencia_lineal)\n",
    "\n",
    "$\\hspace{.5cm}$[3.5- Tendencia Cuadrática](#section_tendencia_cuadratica)\n",
    "\n",
    "$\\hspace{.5cm}$[3.6- Tendencia Transformación Logarítmica](#section_tendencia_transformacion_log)\n",
    "\n",
    "$\\hspace{.5cm}$[3.7- Tendencia Transformación Logarítmica + Estacionalidad](#section_tendencia_transformacion_log_estacionalidad)\n",
    "\n",
    "$\\hspace{.5cm}$[3.8- Single Exponential Smoothing](#section_exponential_smoothing)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section_intro\"></a> \n",
    "###  1- Intro\n",
    "[volver a TOC](#section_toc)\n",
    "\n",
    "Esta clase sigue principalmente la exposición de *Elements of Forecasting (2001)* de Francis X. Diebold. \n",
    "\n",
    "#### ¿Qué es una serie de tiempo?\n",
    "\n",
    "Podemos definir una **serie de tiempo** como un conjunto de observaciones tomadas en **intervalos regulares** que se encuentran **ordenadas** por el momento en que se produjeron.\n",
    "\n",
    "El análisis de series de tiempo se suele utilizar para proyectar o pronosticar la evolución de una variable a lo largo del tiempo, a partir de información previa sobre esa misma variable. Es decir, tenemos que proyectar una variable determinada (eje y) en función del tiempo (eje x). \n",
    "\n",
    "Un ejemplo de serie de tiempo puede ser la evolución del precio de un determinado activo financiero a lo largo del tiempo como en la siguiente imagen:\n",
    "\n",
    "![image.png](img/Picture1.png)\n",
    "\n",
    "Otros ejemplos pueden ser:\n",
    "\n",
    "- Variables macroeconómicas, como el PBI, inflación, reservas del BCRA, etc.\n",
    "- Ventas de comercios\n",
    "- Consumo energético\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"caja1\" style=\"float:left;width: 100%;\">\n",
    "  <div style=\"float:left;width: 15%;\"><img src=\"../../../common/icons/para_seguir_pensando.png\" style=\"align:left\"/> </div>\n",
    "  <div style=\"float:left;width: 85%;\"><label>¿Cuáles podrían ser otros ejemplos de series de tiempo? <br/> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section_descomposicion\"></a> \n",
    "### 2- Descomposición de una serie de tiempo\n",
    "[volver a TOC](#section_toc)\n",
    "\n",
    "Existen distintos tipos de modelos para tratar las series de tiempo. \n",
    "Una opción es modelar una serie de tiempo como compuesta por **cuatro componentes**:\n",
    "- **Tendencia**: componente “permanente”, el efecto persiste en el largo plazo. Se puede interpretar como lo que motiva el cambio a largo plazo de la media.\n",
    "- **Estacionalidad**: esta componente aporta movimientos periódicos a la serie.\n",
    "- **Ciclos**: se entiende por cualquier tipo de dinámica no capturada por la tendencia o la estacionalidad. Estamos ante la presencia de ciclos cuando observamos algún tipo de dinámica mediante la cual el presente está vinculado al pasado. No tiene por qué ser un ciclo rígido.\n",
    "- **Componente aleatoria**: son shocks que no presentan un efecto duradero, ya que las suponemos i.i.d. con media 0 y varianza constante.\n",
    "\n",
    "De manera aditiva, podemos decir entonces que: \n",
    "\n",
    "$$ y_t = T_t + S_t + C_t + \\varepsilon_t. $$\n",
    "\n",
    "… donde T es la tendencia, S es el efecto estacional C es el ciclo y $ \\varepsilon $ es el error aleatorio."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section_tendencia\"></a> \n",
    "#### 2.1- Tendencia\n",
    "[volver a TOC](#section_toc)\n",
    "\n",
    "La **tendencia** corresponde a la **evolución de largo plazo** de la variable que estamos analizando. Puede ser generada por la lenta evolución y cambios en las preferencias, la tecnología, las instituciones o en la demografía.\n",
    "\n",
    "\n",
    "###### Ejemplo 1: Tasa de participación de las mujeres en la fuerza laboral (USA)\n",
    "<img src=\"img/Picture2.png\" width=\"450\">\n",
    "\n",
    "\n",
    "Podemos modelar la tendencia de diferentes maneras, dependiendo de la dinámica de la tendencia. \n",
    "\n",
    "##### Tendencia lineal:\n",
    "\n",
    "$$ T_t = \\beta_0 + \\beta_1 TIME_t + \\varepsilon_t. $$\n",
    "\n",
    "Donde la variable *TIME* es una variable que construimos artificialmente, llamada “dummy de tiempo”.\n",
    "\n",
    "Veamos unos ejemplos de tendencia lineal al variar los parámetros:\n",
    "\n",
    "<img src=\"img/Picture3.png\" width=\"450\">\n",
    "\n",
    "Veamos ahora cómo ajusta la tendencia lineal a la serie de la participación de las mujeres en la fuerza laboral de USA:\n",
    "<img src=\"img/Picture4.png\" width=\"450\">\n",
    "Vemos que la tendencia lineal ajusta bien a la tendencia de nuestra serie. Vemos que en el resíduo no parecen quedar dinámicas relacionadas a la tendencia.\n",
    "\n",
    "<br/> \n",
    " \n",
    "###### Ejemplo 2: Volumen del New York Exchange\n",
    "<img src=\"img/Picture5.png\" width=\"450\">\n",
    "\n",
    "\n",
    "Si la tendencia que estamos buscando modelar presenta una dinámica no lineal, podemos incluir un **término cuadrático** al modelo. Lo obtenemos simplemente elevando al cuadrado a la dummy de tiempo:\n",
    "\n",
    "$$ T_t = \\beta_0 + \\beta_1 TIME_t + \\beta_2 TIME^{2}_t +\\varepsilon_t. $$\n",
    "\n",
    "Veamos qué tal ajusta nuestra tendencia cuadrática a la serie del NY Exchange:\n",
    "\n",
    "<img src=\"img/Picture6.png\" width=\"450\">\n",
    "Vemos que la tendencia cuadrática en este caso no ajusta bien a la tendencia de nuestra serie. Podemos observarlo en el residuo de nuestro modelo.\n",
    "\n",
    "Probemos modelar a la serie del NY Exchange de otra manera. Si la tendencia está caracterizada por una tasa de crecimiento constante, podemos usar un **modelo exponencial**:\n",
    "\n",
    "$$ T_t = \\beta_0 e^{\\beta_1 TIME_t}\\varepsilon_t. $$\n",
    "\n",
    "Si en lugar de modelar directamente la tendencia, modelamos su **logaritmo natural**, volvemos a tener un modelo lineal:\n",
    "\n",
    "$$ \\ln{T_t} = \\ln{\\beta_0} + \\beta_1 TIME_t + \\ln{\\varepsilon_t}. $$\n",
    "\n",
    "<img src=\"img/Picture7.png\" width=\"450\">\n",
    "Vemos que el modelo logarítmico sí ajusta correctamente a nuestra serie.\n",
    "\n",
    "Es relevante también tener en cuenta que realizar la transformación logarítmica también es útil cuando queremos estabilizar la dispersión de nuestra serie. \n",
    "\n",
    "Tenemos que tener en cuenta que debemos **revertir la transformación (back-transform)** para obtener forecasts en la escala original.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section_estacionalidad\"></a> \n",
    "#### 2.2- Estacionalidad\n",
    "[volver a TOC](#section_toc)\n",
    "\n",
    "Un **patrón estacional** se repite con regularidad. La estacionalidad surge de vínculos entre el calendario y las tecnologías, las preferencias o las instituciones.\n",
    "\n",
    "Por ejemplo podemos ver un patrón estacional en la venta de bebidas alcohólicas en Estados Unidos:\n",
    "\n",
    "<img src=\"img/Picture8.png\" width=\"450\">\n",
    "\n",
    "Podemos modelar la estacionalidad utilizando variables dummy. En el siguiente ejemplo modelamos una estacionalidad trimestral:\n",
    "\n",
    "<img src=\"img/Picture9.png\" width=\"300\">\n",
    "\n",
    "$$ S_t = \\sum_{i=1}^{s} \\gamma_iD_it  + \\varepsilon_t. $$\n",
    "\n",
    "Podemos agregar otro tipo de dummies, por ejemplo por días de vacaciones/feriados o ajustes por cantidad de días de comercio, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"caja1\" style=\"float:left;width: 100%;\">\n",
    "  <div style=\"float:left;width: 15%;\"><img src=\"../../../common/icons/para_seguir_pensando.png\" style=\"align:left\"/> </div>\n",
    "  <div style=\"float:left;width: 85%;\"><label>¿Se les ocurren otros fenómenos que podrían generar patrones estacionales? ¿Cómo los modelarían?<br/> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section_modelos_basicos\"></a> \n",
    "### 3- Modelos básicos para pronósticos\n",
    "[volver a TOC](#section_toc)\n",
    "\n",
    "Pasemos al código para poner estos conceptos en práctica. \n",
    "\n",
    "En esta clase vamos a usar series de tiempo para predecir las ventas de medicamentos para diabetes en Australia.\n",
    "\n",
    "\n",
    "***Nota: en esta práctica guiada, vas a encontrar algunas celdas donde vas a tener que completar con tu propio código. Son pequeños ejercicios simples, para usar código que ya deberías conocer de clases anteriores o que ya se presentó en esta práctica. Completarlo te va a servir para fijar mejor los conceptos y corroborar tu comprensión del tema.***\n",
    "\n",
    "Primero importamos las librerías necesarias para trabajar con datos y visualizar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import statsmodels.tsa.api as smt\n",
    "\n",
    "from scipy import stats\n",
    "from statistics import mode\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section_eda_preprocesamiento\"></a> \n",
    "#### 3.1- Análisis exploratorio y preprocesamiento de los datos:\n",
    "[volver a TOC](#section_toc)\n",
    "\n",
    "Creamos nuestro DataFrame y realizamos un ploteo inicial:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../Data/a10.csv', parse_dates=['date'], index_col='date')\n",
    "\n",
    "# Función que plotea la serie:\n",
    "def plot_df(df, x, y, title=\"\", xlabel='Fecha', ylabel='Valor', dpi=100):\n",
    "    plt.figure(figsize=(16,5), dpi=dpi)\n",
    "    plt.plot(x, y, color='tab:red')\n",
    "    plt.gca().set(title=title, xlabel=xlabel, ylabel=ylabel)\n",
    "    plt.show()\n",
    "\n",
    "plot_df(df, x=df.index, y=df.value,\\\n",
    "        title='Ventas mensuales de medicamentos para diabetes en Australia, 1992 a 2008')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exploramos las primeras 5 observaciones de nuestro df:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# POR FAVOR COMPLETÁ CON TU CÓDIGO:\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ploteamos la estacionalidad:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparamos los datos:\n",
    "df['year'] = [d.year for d in df.index]\n",
    "df['month'] = [d.strftime('%b') for d in df.index]\n",
    "years = df['year'].unique()\n",
    "\n",
    "# Preparamos los colores:\n",
    "np.random.seed(100)\n",
    "mycolors = np.random.choice(list(mpl.colors.XKCD_COLORS.keys()), len(years), replace=False)\n",
    "\n",
    "# Ploteamos\n",
    "plt.figure(figsize=(16,12), dpi= 80)\n",
    "for i, y in enumerate(years):\n",
    "    if i > 0:        \n",
    "        plt.plot('month', 'value', data=df.loc[df.year==y, :], color=mycolors[i], label=y)\n",
    "        plt.text(df.loc[df.year==y, :].shape[0]-.9, df.loc[df.year==y, 'value'][-1:].values[0], y, fontsize=12, color=mycolors[i])\n",
    "\n",
    "\n",
    "plt.gca().set(xlim=(-0.3, 11), ylim=(2, 30), ylabel='$Ventas$', xlabel='$Mes$')\n",
    "plt.yticks(fontsize=12, alpha=.7)\n",
    "plt.title(\"Gráfico Estacional de ventas de medicamentos\", fontsize=20);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos los plots:\n",
    "fig, axes = plt.subplots(1, 2, figsize=(20,7), dpi= 80)\n",
    "sns.boxplot(x='year', y='value', data=df, ax=axes[0])\n",
    "sns.boxplot(x='month', y='value', data=df.loc[~df.year.isin([1991, 2008]), :])\n",
    "\n",
    "# Seteamos los títulos:\n",
    "axes[0].set_title('Box Plot Anual\\n(Tendencia)', fontsize=18); \n",
    "axes[1].set_title('Box Plot Mensual\\n(Estacionalidad)', fontsize=18);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos el shape de nuestro df:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# POR FAVOR COMPLETÁ CON TU CÓDIGO:\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a crear una **dummy de tiempo**, es decir indicador numérico para el período de tiempo,  para poder modelar la tendencia lineal.\n",
    "\n",
    "También vamos a crear una variable que sea la dummy de tiempo elevada al cuadrado para modelar la tendencia cuadrática:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"timeIndex\"] = pd.Series(np.arange(len(df['value'])), index=df.index)\n",
    "df[\"timeIndex_sq\"] = df[\"timeIndex\"]**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos variables dummy para los meses:\n",
    "dummies_mes = pd.get_dummies(df['month'], drop_first=True)\n",
    "dummies_mes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hacemos el join entre el DataFrame con la serie de tiempo y las dummies:\n",
    "\n",
    "# POR FAVOR COMPLETÁ CON TU CÓDIGO:\n",
    "df = df.join(dummies_mes)\n",
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a hacer un split entre train y test, teniendo en cuenta que, al tratarse de una serie de tiempo, tenemos que poner *shuffle=False*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df_train, df_test = train_test_split(df, test_size=12, random_state=42, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"caja1\" style=\"float:left;width: 100%;\">\n",
    "  <div style=\"float:left;width: 15%;\"><img src=\"../../../common/icons/para_seguir_pensando.png\" style=\"align:left\"/> </div>\n",
    "  <div style=\"float:left;width: 85%;\"><label>¿Qué problema metodológico generaría hacer el split con shuffle=True? <br/> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verificamos la continuidad entre los sets de entrenamiento y de testeo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vemos los últimos datos del set de entrenamiento:\n",
    "\n",
    "df_train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vemos los primeros datos del set de testeo:\n",
    "\n",
    "# POR FAVOR COMPLETÁ CON TU CÓDIGO:\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que hay continuidad entre el set de entrenamiento y el de testeo. Podemos entrenar los modelos con datos hasta septiembre de 2006 y testear con datos desde octubre en adelante, sin riesgo de data leakage. \n",
    "\n",
    "Ahora sí, pasemos a definir nuestros primeros modelos básicos de series de tiempo:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section_media_constante\"></a> \n",
    "#### 3.2- Media Constante:\n",
    "[volver a TOC](#section_toc)\n",
    "\n",
    "La **media constante** es el modelo más básico e ingenuo de todos. Consiste simplemente en tomar la media del set de entrenamiento y utilizar ese valor para realizar predicciones. Puede usarse como un baseline para comparar otros modelos, pero difícilmente sea nuestro modelo final."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculamos el promedio:\n",
    "model_mean_pred = df_train['value'].mean()\n",
    "\n",
    "# La predicción es fija y es la misma para el set de testeo y de entrenamiento:\n",
    "df_train[\"Mean\"] = model_mean_pred\n",
    "df_test[\"Mean\"] = model_mean_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"caja1\" style=\"float:left;width: 100%;\">\n",
    "  <div style=\"float:left;width: 15%;\"><img src=\"../../../common/icons/para_seguir_pensando.png\" style=\"align:left\"/> </div>\n",
    "  <div style=\"float:left;width: 85%;\"><label>¿Tendría sentido calcular la media para el set de testeo y estimar la bondad del modelo con ese valor?¿Por qué? <br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ploteamos los valores del set de entrenamiento y el modelo:\n",
    "df_train.plot(kind=\"line\", y = [\"value\", \"Mean\"]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ploteamos los valores del set de testeo y el modelo\n",
    "\n",
    "# POR FAVOR COMPLETÁ CON TU CÓDIGO:\n",
    "df_test.plot(kind=\"line\", y = [\"value\", \"Mean\"]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ¿Cuán bien ajusta esta estimación?\n",
    "\n",
    "Primero definimos una función que calcula el **RMSE**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RMSE(predicted, actual):\n",
    "    mse = (predicted - actual) ** 2\n",
    "    rmse = np.sqrt(mse.sum() / mse.count())\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_mean_RMSE = RMSE(df_test.Mean, df_test.value)\n",
    "model_mean_RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardamos el resultado en un DataFrame:\n",
    "df_Results = pd.DataFrame(columns = [\"Model\", \"RMSE\"])\n",
    "df_Results.loc[0, \"Model\"] = \"Mean\"\n",
    "df_Results.loc[0, \"RMSE\"] = model_mean_RMSE\n",
    "df_Results.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section_random_walk\"></a> \n",
    "#### 3.3- Random Walk:\n",
    "[volver a TOC](#section_toc)\n",
    "\n",
    "Decimos que un proceso $ {Y_t} $ es **random walk** (sigue una trayectoria al azar si):\n",
    "\n",
    "$$ \\ {Y_t} = Y_ {t-1} + \\varepsilon,  $$\n",
    "\n",
    "siendo epsilon **ruido blanco**. Si al modelo anterior le añadimos una constante $d$, obtenemos un **random walk con deriva (with drift)**:\n",
    "\n",
    "$$ \\ {Y_t} = Y_ {t-1} + d + \\varepsilon $$\n",
    "\n",
    "Cuando nos enfrentamos a una serie de tiempo que muestra una evolución irregular, la mejor estrategia no es tratar de predecir directamente el nivel de la serie en cada período (es decir, el valor Yt), sino el cambio que ocurre de un período al siguiente (es decir, la diferencia Yt - Yt-1). **Se observa la primera diferencia (o lag) de la serie para encontrar un patrón predecible**.\n",
    "\n",
    "A los efectos del pronóstico del próximo período, puede ser tan bueno predecir el nivel como la variación, ya que el cambio predicho puede agregarse al nivel actual para generar un nivel pronosticado. El caso más simple de dicho modelo es uno que siempre predice que el siguiente cambio será cero, como si la serie tuviera la misma probabilidad de subir o bajar en el próximo período, independientemente de lo que haya sucedido en el pasado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generamos el desplazamiento de nuestro nuestro target en el set de entrenamiento (lag=1):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[\"valueShift1\"] = df_train.value.shift()\n",
    "\n",
    "# La primera observación nos va a quedar en nan, la reemplazamos por el valor siguente:\n",
    "df_train[\"valueShift1\"].fillna(method='bfill', inplace=True)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generamos el desplazamiento de nuestro nuestro target en el set de testeo (lag=1):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test[\"valueShift1\"] = df_test.value.shift()\n",
    "\n",
    "# Podemos reemplazar el primer nan con el último valor del set de entrenamiento:\n",
    "df_test.iloc[0,17] = df_train.iloc[-1,0]\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a hacer un scatterplot entre las observaciones y su lag de un período:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.plot(kind= \"scatter\", y = \"value\", x = \"valueShift1\", s = 50);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ploteamos la diferencia entre nuestro target y el lag de un período:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[\"valueDiff\"] = df_train.value - df_train.valueShift1\n",
    "df_train.valueDiff.plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como la perturbación aleatoria tiene media igual a cero, la predicción del Random Walk va a ser el valor del lag de un período:\n",
    "\n",
    "$$ Y_t = Y_{t-1} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[\"RandomWalk\"] = df_train.valueShift1\n",
    "df_train.plot(kind=\"line\", y = [\"value\", \"RandomWalk\"]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La predicción sobre el set de testeo es simplemente la última observación registrada en el set de entrenamiento. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test[\"RandomWalk\"] = pd.Series(df_train[\"value\"][-1], index=df_test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# POR FAVOR COMPLETÁ CON TU CÓDIGO:\n",
    "df_test.plot(kind=\"line\", y = [\"value\", \"RandomWalk\"]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculamos el RMSE y almacenamos los resultados\n",
    "df_Results.loc[1, \"Model\"] = \"Random Walk\"\n",
    "df_Results.loc[1, \"RMSE\"] = RMSE(df_test.RandomWalk, df_test.value)\n",
    "df_Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que tomar la última observación del set de entranamiento mejoró significaticamente nuestras predicciones en el set de testeo respecto a tomar la media de todo el dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section_tendencia_lineal\"></a> \n",
    "#### 3.4- Tendencia Lineal:\n",
    "[volver a TOC](#section_toc)\n",
    "\n",
    "Continuaremos trabajando con la tendencia lineal entre value y time, fiteando nuestro modelo de regresión lineal entre \"Value\" y \"timeIndex\". En esta práctica vamos a usar la API formula de statsmodels, pero podríamos usar cualquier otra librería para realizar la regresión. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_linear = smf.ols('value ~ timeIndex', data = df_train).fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El primer argumento corresponde a la forma funcional de nuestra estimación. [Más detalles](http://www.statsmodels.org/dev/examples/notebooks/generated/formulas.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_linear.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observamos los resultados de la estimación del modelo. Vemos que la tendencia lineal es una variable significativa con un p-valor prácticamente igual a cero y que el R2 es igual a 0,853.\n",
    "\n",
    "\n",
    "Veamos las predicciones del modelo sobre el set de entrenamiento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[\"LinearTrend\"] = model_linear.predict(df_train.timeIndex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ploteamos los resultados de la predicción:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.plot(kind = \"line\", y = [\"value\",\"LinearTrend\"]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos las predicciones del modelo sobre el set de testeo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# POR FAVOR COMPLETÁ CON TU CÓDIGO:\n",
    "df_test[\"LinearTrend\"] = model_linear.predict(df_test.timeIndex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ploteamos los resultados de la predicción:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# POR FAVOR COMPLETÁ CON TU CÓDIGO:\n",
    "df_test.plot(kind = \"line\", y = [\"value\",\"LinearTrend\"]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculamos el error y añadimos estos datos a nuestro DF de resultados para comparar con el modelo anterior:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Results.loc[2, \"Model\"] = \"LinearTrend\"\n",
    "df_Results.loc[2, \"RMSE\"] = RMSE(df_test.LinearTrend, df_test.value)\n",
    "df_Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que en este caso la tendencia lineal no logra reducir el RMSE en el set de testeo. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section_tendencia_cuadratica\"></a> \n",
    "#### 3.5- Tendencia Cuadrática:\n",
    "[volver a TOC](#section_toc)\n",
    "\n",
    "Continuaremos trabajando con la tendencia cuadrática entre value y time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ahora fiteamos nuestro modelo de regresión lineal entre value y timeIndex + timeIndex_sq\n",
    "\n",
    "model_quadratic = smf.ols('value ~ timeIndex + timeIndex_sq', data = df_train).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Observamos el summary del modelo:\n",
    "\n",
    "# POR FAVOR COMPLETÁ CON TU CÓDIGO:\n",
    "model_quadratic.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que la componente cuadrática es significativa, ya que también tiene un p-valor cercano a cero y el R2 mejora a 0,886. En este caso, en realidad es más correcto comparar R2 ajustados ya que estamos comparando modelos con diferentes cantidad de features. Vemos entonces que el R2-ajustado mejora de 0,852 en el modelo lineal a 0,884. Podemos ver además que tanto el AIC como el BIC se redujeron, corroborando una mejor bondad de ajuste. \n",
    "\n",
    "Veamos las predicciones del modelo sobre el set de entrenamiento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[\"QuadraticTrend\"] = model_quadratic.predict(df_train[[\"timeIndex\",\\\n",
    "                                                      \"timeIndex_sq\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ploteamos los resultados de la predicción:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.plot(kind = \"line\", y = [\"value\",\"QuadraticTrend\"]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos las predicciones del modelo sobre el set de testeo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test[\"QuadraticTrend\"] = model_quadratic.predict(df_test[[\"timeIndex\",\\\n",
    "                                                      \"timeIndex_sq\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ploteamos los resultados de la predicción:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# POR FAVOR COMPLETÁ CON TU CÓDIGO:\n",
    "df_test.plot(kind = \"line\", y = [\"value\", \"QuadraticTrend\"]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agregamos las predicciones al DataFrame de testeo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Añadimos estos datos a nuestro DF de resultados para comparar con el modelo anterior\n",
    "df_Results.loc[3, \"Model\"] = \"QuadraticTrend\"\n",
    "df_Results.loc[3, \"RMSE\"] = RMSE(df_test.QuadraticTrend, df_test.value)\n",
    "df_Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora sí, vemos que trabajar con un trend cuadrático mejora el RMSE, llevándolo a 3,62."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section_tendencia_transformacion_log\"></a> \n",
    "#### 3.6- Tendencia con transformación logarítmica:\n",
    "[volver a TOC](#section_toc)\n",
    "\n",
    "Analizando los datos, vemos que la varianza de la serie aumenta con el paso del tiempo. \n",
    "\n",
    "Veamos si una transformación logarítimica con ayuda a estabilizar la varianza:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['log_value'] = np.log(df_train['value'])\n",
    "df_test['log_value'] = np.log(df_test['value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df(df_train, x=df_train.index, y=df_train['log_value'],\\\n",
    "    title='Log de ventas mensuales de medicamentos para diabetes en Australia, 1992 a 2008')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora fiteamos nuestro modelo de regresión lineal entre log_value y timeIndex:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_log = smf.ols('log_value ~ timeIndex ', data = df_train).fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos el summary del modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# POR FAVOR COMPLETÁ CON TU CÓDIGO:\n",
    "model_log.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que trabajar con la transformación logarítmica mejora la bondad de ajuste del modelo ya que el R2 ajustado es de 0,917.  Podemos ver además que tanto el AIC como el BIC volvieron a reducirse, indicando una mejor bondad de ajuste. \n",
    "\n",
    "Veamos las predicciones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['model_log'] = model_log.predict(df_train[[\"timeIndex\"]])\n",
    "df_test['model_log'] = model_log.predict(df_test[[\"timeIndex\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Almacenamos las predicciones del modelo en el set de entrenamiento y testeo luego de haber realizado back-transformation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['back_model_log'] = np.exp(df_train['model_log'])\n",
    "df_test['back_model_log'] = np.exp(df_test['model_log'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ploteamos los resultados de la predicción en el set de entrenamiento **sin** back-transformation:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.plot(kind = \"line\", y = ['log_value', 'model_log']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ploteamos los resultados de la predicción en el set de entrenamiento **con** back-transformation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.plot(kind = \"line\", y = ['value', 'back_model_log']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ploteamos los resultados de la predicción en el set de testeo **sin** back-transformation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# POR FAVOR COMPLETÁ CON TU CÓDIGO:\n",
    "df_test.plot(kind = \"line\", y = ['log_value', 'model_log']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ploteamos los resultados de la predicción en el set de testeo **con** back-transformation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# POR FAVOR COMPLETÁ CON TU CÓDIGO:\n",
    "df_test.plot(kind = \"line\", y = ['value', 'back_model_log']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Añadimos estos datos a nuestro DF de resultados para comparar con el modelo anterior:\n",
    "df_Results.loc[4, \"Model\"] = \"Transf Log\"\n",
    "df_Results.loc[4, \"RMSE\"] = RMSE(df_test['back_model_log'], df_test['value'])\n",
    "df_Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos una mejoría en el RMSE con el modelo logarítmico. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section_tendencia_transformacion_log_estacionalidad\"></a> \n",
    "#### 3.7- Tendencia con transformación logarítmica + estacionalidad mensual:\n",
    "[volver a TOC](#section_toc)\n",
    "\n",
    "Ahora fiteamos nuestro modelo de regresión lineal entre log_value y timeIndex más las dummies de mes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_log_est = smf.ols('log_value ~ timeIndex + Aug + Dec + Feb + Jan + Jul + Jun + Mar + May + Nov + Oct + Sep',\\\n",
    "                          data = df_train).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_log_est.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"caja1\" style=\"float:left;width: 100%;\">\n",
    "  <div style=\"float:left;width: 15%;\"><img src=\"../../../common/icons/para_seguir_pensando.png\" style=\"align:left\"/> </div>\n",
    "  <div style=\"float:left;width: 85%;\"><label>¿Todos los meses son significativos?<br/> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que al agregar las dummies mensuales, la bondad del modelo mejora sustancialmente. El R2 ajustado pasa de 0,917 a 0.987. Por otro lado, vemos que los coeficientes de todos los meses son significativos, con excepción del mes de marzo, cuyo p-valor es de 0,332. Podríamos volver a entrenar el modelo sin el mes de marzo para ver si mejora. En este caso también, los criterios AIC y BIC se redujeron, confirmando la mejoría en la bondad de ajuste indicada por el R2 ajustado.\n",
    "\n",
    "\n",
    "Calculamos las predicciones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['model_log_est'] = model_log_est.predict(df_train[[\"timeIndex\", \\\n",
    "                                              \"Aug\", \"Dec\", \"Feb\", \"Jan\",\\\n",
    "                                               \"Jul\", \"Jun\", \"Mar\", \"May\",\\\n",
    "                                                \"Nov\", \"Oct\", \"Sep\"]])\n",
    "\n",
    "\n",
    "df_test['model_log_est'] = model_log_est.predict(df_test[[\"timeIndex\", \\\n",
    "                                              \"Aug\", \"Dec\", \"Feb\", \"Jan\",\\\n",
    "                                               \"Jul\", \"Jun\", \"Mar\", \"May\",\\\n",
    "                                                \"Nov\", \"Oct\", \"Sep\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Almacenamos las predicciones del modelo en el set de entrenamiento y testeo luego de haber realizado back-transformation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['back_model_log_est'] = np.exp(df_train['model_log_est'])\n",
    "df_test['back_model_log_est'] = np.exp(df_test['model_log_est'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ploteamos los resultados de la predicción en el set de entrenamiento **sin** back-transformation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.plot(kind = \"line\", y = ['log_value', 'model_log_est']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ploteamos los resultados de la predicción en el set de entrenamiento **con** back-transformation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.plot(kind = \"line\", y = ['value', 'back_model_log_est']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ploteamos los resultados de la predicción en el set de testeo **sin** back-transformation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# POR FAVOR COMPLETÁ CON TU CÓDIGO:\n",
    "df_test.plot(kind = \"line\", y = ['log_value', 'model_log_est']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ploteamos los resultados de la predicción en el set de testeo **con** back-transformation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# POR FAVOR COMPLETÁ CON TU CÓDIGO:\n",
    "df_test.plot(kind = \"line\", y = ['value', 'back_model_log_est']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Results.loc[5, \"Model\"] = \"Transf Log + est\"\n",
    "df_Results.loc[5, \"RMSE\"] = RMSE(df_test['back_model_log_est'], df_test['value'])\n",
    "df_Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que al modelar la estacionalidad mensual agregando las variables dummy, nuestro modelos mejora sustancialmente, reduciéndose el RMSE de 3,25 a 2,05."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section_exponential_smoothing\"></a> \n",
    "#### 3.8- Single Exponential Smoothing:\n",
    "[volver a TOC](#section_toc)\n",
    "\n",
    "El **suavizamiento exponencial simple** otorga más importancia a la información reciente y menos a la pasada. En su forma más simple podemos expresarlo como:\n",
    "\n",
    "$$ \\widehat{y_t} =\\alpha . y_{t-1}  + (1 - \\alpha ) . \\widehat{y}_{t -1} $$\n",
    "\n",
    "Aquí el modelo es un promedio ponderado entre el valor actual y el valor anterior del modelo.\n",
    "$\\alpha$  se conoce como smoothing factor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.holtwinters import SimpleExpSmoothing\n",
    "\n",
    "model_exp_smoothing = SimpleExpSmoothing(df_train.value).fit(smoothing_level=0.3,\\\n",
    "                                                            optimized=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.plot(kind = \"line\", y = \"value\")\n",
    "model_exp_smoothing.fittedvalues.plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Time Series Cross Validation \n",
    "\n",
    "Antes de comenzar a construir un modelo, veamos primero cómo optimizar los hiperparámetros del modelo automáticamente.\n",
    "\n",
    "¿Cómo podemos hacer para realizar validación cruzada con series de tiempo? Las series de tiempo tienen una estructura temporal y no se pueden mezclar los valores aleatoriamente en una partición mientras se conserva esta estructura. Con la aleatorización, se perderán todas las dependencias temporales entre las observaciones. Es por esto que tendremos que usar un enfoque más complicado para optimizar los parámetros del modelo. Utilizaremos es \"cross validation on a rolling basis\".\n",
    "\n",
    "La idea es bastante simple: entrenamos nuestro modelo en un pequeño segmento de la serie de tiempo desde el principio hasta algunas t, hacemos predicciones para los siguientes t + n pasos y calculamos un error. Luego, expandimos nuestra muestra de entrenamiento a valor t + n, hacemos predicciones desde t + n hasta t + 2 ∗ n, y continuamos moviendo nuestro segmento de prueba de la serie de tiempo hasta que alcanzamos la última observación disponible. Como resultado, tenemos folds como n cabrá entre la muestra de entrenamiento inicial y la última observación\n",
    "\n",
    "<img src=\"img/ts_validation.png\" alt=\"drawing\" width=\"600\"/>\n",
    "\n",
    "Aplicamos un split entre train y test para series de tiempo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit \n",
    "\n",
    "tscv = TimeSeriesSplit(n_splits=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con fines ilustrativos, vamos a hacer un print de los elementos del set de entrenamiento y validación para cada fold:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for train_index, val_index in tscv.split(df_train):\n",
    "    print(\"TRAIN:\", train_index, \"VAL:\", val_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos una función que aplica time series cross validation para el modelo single exponential smoothing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def timeseriesCVscore_exp_smoot(alpha, series):\n",
    "    \"\"\"\n",
    "        Returns error on CV  \n",
    "        \n",
    "        params - vector of parameters for optimization\n",
    "        series - dataset with timeseries\n",
    "        slen - season length for Holt-Winters model\n",
    "    \"\"\"\n",
    "    # creamos un array de errores:\n",
    "    errors = []\n",
    "    \n",
    "    values = series.values\n",
    "    \n",
    "    # instanciamos el objeto que realiza el tscv:\n",
    "    tscv = TimeSeriesSplit(n_splits=5) \n",
    "    \n",
    "    # Aplicamos cross validation:\n",
    "\n",
    "    for train, test in tscv.split(values):\n",
    "    \n",
    "        model = SimpleExpSmoothing(values[train]).fit(smoothing_level=alpha,\\\n",
    "                                                             optimized=False)\n",
    "        \n",
    "        predictions = model.forecast(len(test))\n",
    "        actual = values[test]\n",
    "    \n",
    "        error = mean_squared_error(predictions, actual)\n",
    "        errors.append(error)\n",
    "        \n",
    "    return np.mean(np.array(errors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = [0.001, 0.01, 0.1, 0.2, 0.3, 0.35, 0.4, 0.5, 0.7]\n",
    "errors = []\n",
    "\n",
    "for alpha in alphas:\n",
    "    error = timeseriesCVscore_exp_smoot(alpha, df_train.value)\n",
    "    errors.append(error)\n",
    "\n",
    "print('Alpha óptimo:', alphas[np.argmin(errors)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenamos el modelo optimizado:\n",
    "\n",
    "model_exp_smoothing = SimpleExpSmoothing(df_train.value).fit(smoothing_level=alphas[np.argmin(errors)],\\\n",
    "                                                             optimized=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test[\"Simple_Smoothing\"] = model_exp_smoothing.forecast(12)\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_simp_smo_RMSE = RMSE(df_test[\"Simple_Smoothing\"], df_test.value)\n",
    "model_simp_smo_RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.plot(kind=\"line\", y = [\"value\", \"Simple_Smoothing\"]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculamos el RMSE y almacenamos los resultados\n",
    "df_Results.loc[6, \"Model\"] = \"Simple Smoothing\"\n",
    "df_Results.loc[6, \"RMSE\"] = RMSE(df_test[\"Simple_Smoothing\"], df_test.value)\n",
    "df_Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ploteamos las mejores estimaciones \n",
    "df_test.plot(kind = \"line\", y = [\"value\", \"RandomWalk\", \"back_model_log_est\",\\\n",
    "                                                 \"back_model_log\"]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"caja7\" style=\"float:left;width: 100%;\">\n",
    "  <div style=\"float:left;width: 15%;\"><img src=\"../../../common/icons/en_resumen.png\" style=\"align:left\"/> </div>\n",
    "  <br>\n",
    "  <br>  \n",
    "  <div style=\"float:left;width: 85%;\"><label><b>En conclusión...</b></label></div>\n",
    "</div>\n",
    "<br>\n",
    "\n",
    "Podemos descomponer una serie de tiempo en:\n",
    "\n",
    "- **Tendencia**: componente “permanente”, el efecto persiste en el largo plazo. Se puede interpretar como lo que motiva el cambio a largo plazo de la media.\n",
    "- **Estacionalidad**: esta componente aporta movimientos periódicos a la serie.\n",
    "- **Ciclos**: se entiende por cualquier tipo de dinámica no capturada por la tendencia o la estacionalidad. Estamos ante la presencia de ciclos cuando observamos algún tipo de dinámica mediante la cual el presente está vinculado al pasado. No tiene por qué ser un ciclo rígido.\n",
    "- **Componente aleatoria**: son shocks que no presentan un efecto duradero, ya que las suponemos i.i.d. con media 0 y varianza constante.\n",
    "\n",
    "De manera aditiva, podemos decir entonces que: \n",
    "\n",
    "$$ y_t = T_t + S_t + C_t + \\varepsilon_t. $$\n",
    "\n",
    "- Para modelar la tendencia y la estacionalidad podemos usar dummies de tiempo y estacionales. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[volver a TOC](#section_toc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
