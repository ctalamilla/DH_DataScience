{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial setup\n",
    "%run \"../../../common/0_notebooks_base_setup.py\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Setup**\n",
    "\n",
    "Si la instalación de lightgbm da error, ejecutar en Anaconda Prompt \n",
    "\n",
    "`conda install -c conda-forge xgboost=1.4.0`\n",
    "\n",
    "`conda install -c conda-forge lightgbm=3.2.1`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<img src='../../../common/logo_DH.png' align='left' width=35%/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7yO4fvwhyhvk"
   },
   "source": [
    "# Boosting en Scikit Learn\n",
    "\n",
    "## 1. Introducción\n",
    "En esta práctica vamos a comparar el rendimiento de los siguientes algoritmos:\n",
    "\n",
    "- AdaBoostClassifier()\n",
    "- GradientBoostingClassifier()\n",
    "\n",
    "\n",
    "Para ello vamos a comenzar con la lectura del dataset de aceptabilidad de autos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jScdVG1wyhvm"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "df = pd.read_csv('../Data/car.csv') \n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df.doors.unique())\n",
    "display(df.persons.unique())\n",
    "display(df.acceptability.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Q3YsInLayhvs"
   },
   "source": [
    "Esta vez vamos a codificar los atributos usando un esquema One Hot, es decir, los consideraremos como variables categóricas. También vamos a codificar el target usando el `LabelEncoder`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BnIuS5w9yhvu"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "lab_enc = LabelEncoder()\n",
    "lab_enc.fit(df['acceptability'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FsgZYvLOyhvy",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y = lab_enc.transform(df['acceptability'])\n",
    "X = pd.get_dummies(df.drop('acceptability', axis=1),drop_first=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vemos la forma final la matriz de features\n",
    "print(X.shape)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vemos la forma final del vector target\n",
    "print(y.shape)\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hacemos el split entre train y test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=41)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_NC7Ei-ryhv1"
   },
   "source": [
    "Para que los resultados sean consistentes hay que exponer los modelos exactamente al mismo esquema de validación cruzada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "j0pXpjNFyhv3"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "cv = StratifiedKFold(n_splits=5, random_state=41, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nxxMJeMYyhv5"
   },
   "source": [
    "## 2. Comparando la performance de los árboles de decisión y boosting\n",
    " \n",
    "Ahora vamos a inicializar el clasificador de árbol de decisión, evaluar su rendimiento y compararlo con la perfomance de los modelos de boosting. Para ello, vamos a usar los siguientes métodos:\n",
    "\n",
    "Para comparar los diferentes algoritmos armamos la función `evaluar_rendimiento`, que toma como input un estimador y un string con el nombre que le queramos poner, y ejecuta un `cross_val_score`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluar_rendimiento(modelo, nombre, X, y, cv):\n",
    "    s = cross_val_score(modelo, X, y, cv=cv, n_jobs=-1)\n",
    "    print(\"Rendimiento de {}:\\t{:0.3} ± {:0.3}\".format( \\\n",
    "        nombre, s.mean().round(3), s.std().round(3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluamos el rendimiento de un árbol de Clasificación simple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "V7Br9N3Jyhv6"
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dt = DecisionTreeClassifier(random_state=1)\n",
    "\n",
    "evaluar_rendimiento(dt,\"Árbol de decisión\", X_train, y_train, cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probemos ahora los modelos de *boosting* AdaBoost y GradientBoosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier\n",
    "\n",
    "ab = AdaBoostClassifier(base_estimator=dt, n_estimators=500,random_state=1)\n",
    "evaluar_rendimiento(ab, \"AdaBoostClassifier\",  X_train, y_train, cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb = GradientBoostingClassifier()\n",
    "evaluar_rendimiento(gb, \"GradientBoostingClassifier\", X_train, y_train, cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver que AdaBoost performa peor. Podríamos tratar de tunear los hiperparámetros para hacerlo funcionar mejor. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "params_ab = {\"n_estimators\": [500,1000],\n",
    "          \"learning_rate\":[0.01, 0.1],\n",
    "        \"base_estimator__max_depth\": [1, 2, 3]}\n",
    "\n",
    "grid_ab = GridSearchCV(AdaBoostClassifier(base_estimator=dt,random_state=1), \n",
    "                       param_grid=params_ab, cv=cv, verbose=1, n_jobs=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_ab.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_ab.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluar_rendimiento(grid_ab.best_estimator_,  \"AdaBoostClassifier + GS\", X_train, y_train, cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No hemos logrado mejorar la performance del modelo Adaboost luego de intentar optimizar sus parametros.  \n",
    "Veamos como nos va con Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_gb = {'n_estimators':[500, 1000] , \n",
    "             'learning_rate':[0.001, 0.001, 0.1],\n",
    "            'max_depth' : [1, 2, 3, 4]}\n",
    "\n",
    "grid_gb = GridSearchCV(gb, param_grid=params_gb, cv=cv, verbose=1, n_jobs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_gb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_gb.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluar_rendimiento(grid_gb.best_estimator_, \"GradientBoostingClassifier + GS\", X_train, y_train, cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso si vemos una mejora en la performance del Modelo de Gradient Boosting.  \n",
    "Veamos a continuacion el valor de AUC y el gráfico de ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "xgb_auc = roc_auc_score(y_test,grid_gb.predict_proba(X_test),multi_class=\"ovr\")\n",
    "print(\"El valor del AUC es: \", xgb_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scikitplot.metrics import plot_roc\n",
    "plot_roc(y_test,grid_gb.predict_proba(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente vamos a graficar la importancia relativa de los feature para la predicción:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = grid_gb.best_estimator_\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = model.feature_importances_\n",
    "importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recordamos que argsort nos devuelve un vector con indices del vector original \n",
    "# tal que este quede reordenado de mayor a menor. \n",
    "# https://numpy.org/doc/stable/reference/generated/numpy.argsort.html\n",
    "\n",
    "# creamos una variable que tenga los indices indicando los valores de mayor a menor\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# con dicha variable realizamos fancy indexing de manera de ordenar los labels del eje x.\n",
    "names = X.columns[indices]\n",
    "\n",
    "# Creamos el plot\n",
    "plt.figure()\n",
    "\n",
    "# Creamos plot title\n",
    "plt.title(\"Feature Importance\")\n",
    "\n",
    "# Agregamos las barras\n",
    "plt.bar(range(X.shape[1]), importances[indices])\n",
    "\n",
    "# Agregamos los feature names \n",
    "plt.xticks(range(X.shape[1]), names, rotation=90)\n",
    "\n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "1.PRACTICA_GUIADA_RandomForest_ExtraTrees..ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
