{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial setup\n",
    "%run \"../../../common/0_notebooks_base_setup.py\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='../../../common/logo_DH.png' align='left' width=35%/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Desafío: Clasificación de artículos de diario\n",
    "\n",
    "Trabajaremos con un dataset de noticias de los diarios Clarin y Pagina12. El objetivo de la práctica será implementar un modelo que permita predecir de qué diario proviene una noticia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix\n",
    "import unidecode\n",
    "from nltk.corpus import stopwords "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Importamos los datos\n",
    "\n",
    "* Importen los datos con pandas y generen un dataframe agregando una columna 'clase' que indique si son noticias de Clarin o de Pagina12.\n",
    "\n",
    "Las noticias de Clarin se encuentran en '../Data/clarin.csv' y las de Pagina12 en '../Data/pagina12.csv'.\n",
    "\n",
    "* Concatenen ambos data sets en un solo dataframe.\n",
    "\n",
    "* ¿Cuántas noticias tenemos de cada diario?\n",
    "\n",
    "* ¿Qué columnas tiene el dataframe? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Limpieza\n",
    "\n",
    "#### 2.1 Faltantes\n",
    "\n",
    "A partir del dataset observamos que los campos que probablemente contengan el vocabulario relevante son \"cuerpo\", \"título\" y \"resumen\".\n",
    "\n",
    "* Saquen del análisis los registros que no tienen cuerpo o título disponible\n",
    "\n",
    "* Completen los resúmenes faltantes con una campo en blanco\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 Suplementos relevantes\n",
    "\n",
    "Para mejorar la clasificación es conveniente retirar las secciones donde los dos diarios utilizan un vocabulario similar y muy específico del dominio como, por ejemplo, las relacionadas a deportes.\n",
    "\n",
    "* Miren las secciones dentro de la columna 'suplemento': Ojo que hay secciones de deportes con diferente nombre por ejemplo '/deportes/futbol/'\n",
    "\n",
    "* Remuevan las noticias de deportes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3 Corpus\n",
    "\n",
    "El data set tiene informacion relevante en las columnas 'título', 'resumen' y 'cuerpo', de modo que podemos generar una nueva columna que sea la concatenación de estas tres. \n",
    "\n",
    "* Generen dicha columna, que será nuestro corpus de documentos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Modelo\n",
    "\n",
    "### 3.1 \n",
    "\n",
    "* Vectoricen el corpus de textos resultante con CountVectorizer, removiendo stopwords. Usen el argumento strip_accents='unicode' para remover tildes del texto.\n",
    "\n",
    "Atención: las stopwords importadas de nltk contienen tildes. Elimínenlas antes de vectorizar el corpus.\n",
    "\n",
    "* ¿Cuál es la dimensión de la matriz de features?\n",
    "\n",
    "* Apliquen un modelo Naive Bayes con un split simple entre train y test. \n",
    "\n",
    "* ¿Cuál es el accuracy obtenido?  \n",
    "\n",
    "* Dibujen la matriz de confusión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Optimización del modelo\n",
    "\n",
    "* Hagan una gridsearch cross validation variando el hiperparámetro alpha en el rango (0;0.1)\n",
    "\n",
    "* Vean la accuracy y la matriz de confusión obtenida con el mejor modelo, en el test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Análisis de los resultados \n",
    "\n",
    "El modelo entrenado tiene el atributo \"feature_log_prob\" que contiene el logaritmo de los coeficientes $\\theta_{yi}$, que representan la probabilidad de que el término i-ésimo pertenezca a la clase $y$.\n",
    "\n",
    "¿Cuáles son las features (palabras) que mejor separan a las dos clases?\n",
    "\n",
    "* Calculen el cociente entre los logaritmos de los coeficientes estimados para la clase \"clarin\" y para \"pagina12\". ¿Cuáles términos mustran mayor diferencia entre ambos valores?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
