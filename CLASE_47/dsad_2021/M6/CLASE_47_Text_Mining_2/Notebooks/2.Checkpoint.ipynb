{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial setup\n",
    "%run \"../../../common/0_notebooks_base_setup.py\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='../../../common/logo_DH.png' align='left' width=35%/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checkpoint: Clasificacion de texto\n",
    "\n",
    "Trabajaremos con un dataset de noticias (en ingles) sobre diferentes temas: world, sports, business, sci/tech.\n",
    "\n",
    "La idea es vectorizar el corpus de noticias e implementar un clasificador para identificar a qué tema pertenecen las noticias.\n",
    "\n",
    "Trabajaremos con una versión reducida de un corpus que pueden descargar completo (~30Mb) del siguiente sitio:\n",
    "\n",
    "https://github.com/mhjabreel/CharCnn_Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ejercicio 1\n",
    "\n",
    "Generamos el corpus:\n",
    "\n",
    "Importen los datos con pandas. Los datos se encuentran en '../Data/ag_news_reduced.csv'. \n",
    "\n",
    "El dataset contiene tres columnas: la primera tiene un entero que indica a qué clase pertenece la noticia. La segunda es el título y la tercera es una descripción de la noticia.\n",
    "\n",
    "Como no tenemos las noticias enteras sino solo un resumen, conviene que generemos el corpus concatenando el título y la descripción en un sólo texto. \n",
    "\n",
    "Generen una columna en el dataframe que sea la concatenación del título y la descripción. No olviden agregar un espacio en blanco para no pegar la última palabra del título con la primera de la descrición.\n",
    "\n",
    "¿Cuántos artículos hay de cada clase?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ejercicio 2\n",
    "\n",
    "¿Cuáles son las palabras más frecuentes dentro de cada clase?\n",
    "\n",
    "Ayuda: Pueden vectorizar el corpus (dividido por temas) usando CountVectorizer() y luego sumar las filas de la matriz para obtener el número total de veces que aparece cada término.\n",
    "\n",
    "Ayuda2: No olviden remover stopwords al vectorizar!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ejercicio 3\n",
    "\n",
    "Vectorizar el corpus usando Countvectorizer y entrenar un clasificador de tipo Multinomial Naive Bayes (MultinomialNB). Para empezar, hagan un simple train_test_split de los datos y vean la performance (accuracy) en el set de validacion.\n",
    "\n",
    "Luego vean si pueden mejorar esa performance optimizando el parámetro alpha del modelo haciendo una Gridsearch cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ejercicio 4\n",
    "\n",
    "Repetir lo anterior removiendo stopwords al vectorizar.\n",
    "\n",
    "¿Cambia la performance?  ¿Cuánto se redujo la dimensionalidad?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ejercicio 5\n",
    "\n",
    "Utilizar los parámetros min_df y max_df para remover términos que aparecen en muy pocos documentos o que aparecen en demasiados (stopwords específicas del corpus).\n",
    "\n",
    "Reentrenar el modelo y ver si cambia la performance.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ejercicio 6\n",
    "\n",
    "Repetir el análisis incluyendo bigramas en la vectorizacion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
