{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# initial setup\n",
    "%run \"../../../common/0_notebooks_base_setup.py\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<link rel=\"stylesheet\" href=\"../../../common/dhds.css\">\n",
    "<div class=\"Table\">\n",
    "    <div class=\"Row\">\n",
    "        <div class=\"Cell grey left\"> <img src=\"https://raw.githubusercontent.com/Digital-House-DATA/ds_blend_2021_img/master/M5/CLASE_36_Ensemble/M5_CLASE_36_portada.png\" align=\"center\" width=\"90%\"/></div>\n",
    "        <div class=\"Cell right\">\n",
    "            <div class=\"div-logo\"><img src=\"https://raw.githubusercontent.com/Digital-House-DATA/ds_blend_2021_img/master/common/logo_DH.png\" align=\"center\" width=70% /></div>\n",
    "            <div class=\"div-curso\">DATA SCIENCE</div>\n",
    "            <div class=\"div-modulo\">MÓDULO 5</div>\n",
    "            <div class=\"div-contenido\">Modelos de Ensamble</div>\n",
    "        </div>\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Agenda\n",
    "\n",
    "---\n",
    "\n",
    "- Modelos de ensamble\n",
    "\n",
    "- Modelos de ensamble para regresión\n",
    "\n",
    "- Modelos de ensamble para clasificación\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div class=\"div-dhds-fondo-1\"> Introducción\n",
    "<img src=\"https://raw.githubusercontent.com/Digital-House-DATA/ds_blend_2021_img/master/M5/CLASE_36_Ensemble/M5_CLASE_36_separador.png\" align=\"center\" />\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src =\"https://raw.githubusercontent.com/Digital-House-DATA/ds_blend_2021_img/master/M5/CLASE_36_Ensemble/M5_CLASE_36_intro.png\" align = \"center\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Idea\n",
    "\n",
    "Entrenar muchos modelos y hacerlos votar. La clasificación resultante es la que reciba más votos.\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/Digital-House-DATA/ds_blend_2021_img/master/M5/CLASE_36_Ensemble/M5_CLASE_36_ensamble_2.png\" align=\"center\" />\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Si todos los modelos son muy parecidos, no van a agregar mucha información nueva en la votación. \n",
    "\n",
    "Necesitamos modelos diferentes entre sí, poco correlacionados. \n",
    "\n",
    "Los modelos pueden ser diferentes entre sí por una variedad de razones:\n",
    "\n",
    "* Puede haber diferencia en la **población de datos**\n",
    "\n",
    "* Puede haber una **técnica de modelado** utilizada diferente\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div class=\"div-dhds-fondo-1\"> Ensambles\n",
    "<img src=\"https://raw.githubusercontent.com/Digital-House-DATA/ds_blend_2021_img/master/M5/CLASE_36_Ensemble/M5_CLASE_36_separador.png\" align=\"center\" />\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## ¿Qué es un modelo de ensamble?\n",
    "\n",
    "---\n",
    "\n",
    "**Los modelos de ensamble en aprendizaje automático combinan las decisiones de varios modelos para mejorar el rendimiento general**.\n",
    "\n",
    "Las principales causas de error en los modelos de aprendizaje se deben al **ruido**, al **sesgo** y a la **varianza**.\n",
    "\n",
    "**Los modelos de ensamble ayudan a minimizar estos factores**. \n",
    "\n",
    "Estos modelos están diseñados para mejorar la estabilidad y precisión de los algoritmos de aprendizaje automático.\n",
    "\n",
    "Los modelos de ensamble emplean un grupo de modelos donde la combinación de sus resultados es casi siempre mejor en términos de precisión de predicción en comparación con el uso de un solo modelo.\n",
    "\n",
    "**Los ensambles son una estrategia \"divide and conquer\" que se utiliza para mejorar la performance.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Técnicas de Ensamble\n",
    "\n",
    "---\n",
    "\n",
    "Los métodos de **Ensamble** son técnicas de **aprendizaje supervisado** donde se **combinan varios modelos base**.\n",
    "\n",
    "\n",
    "Combinando varios modelos base se busca **ampliar el espacio de hipótesis** posibles para representar los datos, con el fin de **mejorar la precisión predictiva** del modelo combinado resultante.\n",
    "\n",
    "Los ensambles suelen ser mucho más precisos que los modelos base que los componen.\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/Digital-House-DATA/ds_blend_2021_img/master/M5/CLASE_36_Ensemble/M5_CLASE_36_ensamble_1.jpg\" align=\"center\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Generalmente se distinguen dos familias de métodos de ensamble:\n",
    "\n",
    "* Los métodos de **averaging (basados en promedios)**, que consisten en construir varios estimadores de forma independiente y luego hacer un **promedio** de sus predicciones. El modelo resultante de la combinación, suele ser mejor que cualquier estimador base separado.\n",
    "\n",
    "    * Ejemplos de esta familia son los métodos de **Bagging**, y su implementación particular **Random Forest**.\n",
    "\n",
    "* La otra familia de métodos de ensamble son los métodos de **boosting**, donde los estimadores base se construyen **secuencialmente** y uno trata de reducir el sesgo del estimador combinado, centrándose en aquellos casos en los que se observa una peor performance. La idea es combinar varios modelos débiles para producir un ensamble potente.\n",
    "\n",
    "    * Ejemplos de esta familia son **AdaBoost** y **Gradient Tree Boosting**.\n",
    "    \n",
    "**(Veremos bagging y boosting en detalle en las próximas clases.)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## El espacio de Hipótesis\n",
    "\n",
    "---\n",
    "\n",
    "En cualquier tarea de **aprendizaje supervisado**, nuestro objetivo es hacer predicciones de la verdadera función de clasificación $f$ aprendiendo el clasificador $h$. \n",
    "\n",
    "En otras palabras, buscamos en un cierto **espacio de hipótesis H** la función más apropiada para describir la relación entre nuestras features y el objetivo.\n",
    "\n",
    "Puede haber varias **razones por las cuales un clasificador base no pueda lograr mayor exactitud al tratar de aproximar la función de clasificación real**.\n",
    "\n",
    "Estos son tres de los posibles problemas:\n",
    "\n",
    "* Estadísticos\n",
    "\n",
    "* Computacionales\n",
    "\n",
    "* De representación\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### El problema estadístico\n",
    "\n",
    "---\n",
    "\n",
    "<table><tr>\n",
    "    <td style=\" font-size:18px;\">\n",
    "\n",
    "<p>\n",
    "Si la cantidad de datos de entrenamiento disponibles es <b>pequeña</b>, el clasificador base tendrá dificultades para converger a  $f$.\n",
    "</p>\n",
    "<p>        \n",
    "Un clasificador de ensamble puede mitigar este problema <b>\"promediando\"</b> las predicciones de los clasificadores base para mejorar la convergencia.\n",
    "</p>\n",
    "<p>        \n",
    "Esto puede representarse gráficamente como una búsqueda en un espacio en el que múltiples aproximaciones parciales son promediadas para obtener una mejor aproximación al objetivo.\n",
    "</p>\n",
    "<p>        \n",
    "La función real $f$ es mejor aproximada como un promedio de los clasificadores base $h_i$.\n",
    "</p>    \n",
    "        </td>\n",
    "        <td style=\"width:40%;\">\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/Digital-House-DATA/ds_blend_2021_img/master/M5/CLASE_36_Ensemble/M5_CLASE_36_problema_estadistico.png\" align = \"center\" />\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### El problema computacional\n",
    "\n",
    "---\n",
    "\n",
    "<table><tr>\n",
    "    <td style=\" font-size:18px;\">\n",
    "\n",
    "<p>Incluso con suficientes datos de entrenamiento, puede ser computacionalmente difícil encontrar el mejor clasificador $h$.</p>\n",
    "\n",
    "<p>Por ejemplo, si nuestro clasificador base es un árbol de decisión, una búsqueda exhaustiva del espacio de hipótesis de todos los posibles clasificadores es un problema extremadamente complejo (NP-completo). Por ésta razón usamos un <b>algoritmo voraz</b>.</p>\n",
    "\n",
    "<p>Un conjunto compuesto por varios clasificadores base con <b>diferentes puntos de partida</b> puede proporcionar una mejor aproximación de $f$ que cualquier clasificador base individualmente. La verdadera función $f$ es usualmente mejor aproximada usando varios puntos de partida para explorar el espacio de hipótesis H.</p>\n",
    "</td>\n",
    "<td style=\"width:40%;\">\n",
    "<img src=\"https://raw.githubusercontent.com/Digital-House-DATA/ds_blend_2021_img/master/M5/CLASE_36_Ensemble/M5_CLASE_36_problema_computacional.png\" align = \"center\" />\n",
    "</td></tr>\n",
    "</table>    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### El problema de representación\n",
    "\n",
    "---\n",
    "\n",
    "<table><tr>\n",
    "    <td style=\" font-size:18px;\">\n",
    "\n",
    "\n",
    "<p>A veces $f$ no se puede expresar en términos de la hipótesis.</p>\n",
    "\n",
    "<p>Por ejemplo, si usamos un árbol de decisión como clasificador base, este trabaja formando <b>particiones rectilíneas</b> del espacio de features.</p>\n",
    "\n",
    "<p>Pero si $f$ es una línea diagonal, entonces no puede ser representada por un número finito de segmentos rectilíneos.</p>\n",
    "\n",
    "<p>Por lo tanto, el límite de decisión verdadero, no puede ser expresado por un árbol de decisión.</p>\n",
    "\n",
    "<p>Sin embargo, todavía puede ser posible aproximar $f$, e incluso expandir el espacio de funciones representables, usando métodos de ensamble.</p>\n",
    "\n",
    "</td>\n",
    "<td style=\"width:40%;\">\n",
    "    \n",
    "<img src=\"https://raw.githubusercontent.com/Digital-House-DATA/ds_blend_2021_img/master/M5/CLASE_36_Ensemble/M5_CLASE_36_problema_representacion.png\" align = \"center\" />\n",
    "\n",
    "</td></tr>\n",
    "</table>    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Condición necesaria y suficiente\n",
    "\n",
    "---\n",
    "\n",
    "La condición necesaria y suficiente que se debe cumplir para que un clasificador de ensamble mejore los resultados de cualquiera de sus clasificadores base es que estos sean precisos y diversos.\n",
    "\n",
    "* **Capacidad predictiva**: los clasificadores base deben hacer mejores predicciones que la totalmente aleatoria. (Su AUC debe ser mayor a 0.5)\n",
    "\n",
    "* **Diversidad**: los clasificadores base deben cometer distintos errores ante los mismos casos. (Sin diversidad no se puede mejorar la precisión del ensamble al combinar los clasificadores base)\n",
    "\n",
    "Imaginemos que tenemos un ensamble de tres clasificadores base $\\{ h_1, h_2, h_3 \\}$ y consideramos un caso nuevo x:\n",
    "\n",
    "* Si los tres clasificadores son similares, cuando $h_1(x)$ sea erróneo probablemente $h_2(x)$ y $h_3(x)$ también lo serán y no ganaremos nada al combinarlos. \n",
    "\n",
    "* Pero si son bastante diversos, los errores que cometan estarán poco correlacionados, y cuando $h_1(x)$ sea erróneo posiblemente $h_2(x)$ y $h_3(x)$ sean correctos y el voto mayoritario será correcto. Esto es cierto, siempre y cuando, el error rate individual de cada uno sea menor al 50%\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Ejemplo\n",
    "\n",
    "---\n",
    "\n",
    "Vamos a usar el dataset Hitters (que ya usamos en CART) para entrenar un modelo de ensamble para predecir el valor del `log(Salary)`\n",
    "\n",
    "El ensamble va a estar compuesto por\n",
    "\n",
    "* Un modelo de regresión lineal múltiple\n",
    "\n",
    "* Un modelo de regresión de Lasso\n",
    "\n",
    "* Un árbol de regresión\n",
    "\n",
    "Vamos a calcular la predicción para cada instancia como el promedio de las predicciones de cada uno de estos tres modelos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression, Lasso\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Leemos los datos y, para simplificar, nos quedamos sólo con los registros completos y las features numéricas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "data_raw = pd.read_csv(\"../Data/Hitters.csv\")\n",
    "print(data_raw.shape)\n",
    "data_complete = data_raw.dropna()\n",
    "print(data_complete.shape)\n",
    "\n",
    "data_columns = ['AtBat', 'Hits', 'HmRun', 'Runs', 'RBI', \n",
    "                'Walks', 'Years', 'CAtBat', 'CHits', 'CHmRun', \n",
    "                'CRuns', 'CRBI', 'CWalks', 'PutOuts', 'Assists', \n",
    "                'Errors', 'Salary']\n",
    "\n",
    "data = data_complete.loc[:, data_columns]\n",
    "print(data.shape)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Creamos los conjuntos de train y test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "X = data.drop(\"Salary\", axis = 1)\n",
    "print(X.shape)\n",
    "\n",
    "y = np.log(data.Salary)\n",
    "print(y.shape)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,random_state = 127)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Estandarizamos las features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scl = scaler.fit_transform(X_train)\n",
    "\n",
    "X_test_scl = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Entrenamos el modelo de regresión lineal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "model_1 = LinearRegression()\n",
    "fit_1 = model_1.fit(X_train_scl, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Evaluamos la performance en test mediante en error cuadrático medio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "predict_1 = fit_1.predict(X_test_scl)\n",
    "performance_1 = mean_squared_error(y_test, predict_1)\n",
    "performance_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Entrenamos el modelo de Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "model_2 = Lasso(alpha = 0.05)\n",
    "fit_2 = model_2.fit(X_train_scl, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Evaluamos la performance en test mediante en error cuadrático medio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "predict_2 = fit_2.predict(X_test_scl)\n",
    "performance_2 = mean_squared_error(y_test, predict_2)\n",
    "performance_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Entrenamos el árbol de regresión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "model_3 = tree.DecisionTreeRegressor(random_state = 271)\n",
    "fit_3 = model_3.fit(X_train_scl, y_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Evaluamos la performance en test mediante en error cuadrático medio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "predict_3 = fit_3.predict(X_test_scl)\n",
    "performance_3 = mean_squared_error(y_test, predict_3)\n",
    "performance_3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Construimos el ensamble de los tres modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def predict_ensamble(X, model_1, model_2, model_3):\n",
    "    y_pred_1 = model_1.predict(X)\n",
    "    y_pred_2 = model_2.predict(X)\n",
    "    y_pred_3 = model_3.predict(X)\n",
    "    result = (y_pred_1 + y_pred_2 + y_pred_3) / 3\n",
    "    return result\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Evaluamos la performance en test mediante en error cuadrático medio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "y_pred_ensemble = predict_ensamble(X_test_scl, fit_1, fit_2, fit_3)\n",
    "performance_ensemble =  mean_squared_error(y_test, y_pred_ensemble)\n",
    "performance_ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Observemos que el error cuadrático medio del modelo de ensamble es el menor obtenido."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div class=\"div-dhds-fondo-1\"> Conclusiones\n",
    "<img src=\"https://raw.githubusercontent.com/Digital-House-DATA/ds_blend_2021_img/master/M5/CLASE_36_Ensemble/M5_CLASE_36_separador.png\" align=\"center\" />\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Conclusiones\n",
    "\n",
    "---\n",
    "\n",
    "* Los modelos de Ensamble generalmente presentan menos overfitting y mejor performance.\n",
    "\n",
    "* Los métodos de Ensamble mejoran el rendimiento de los modelos base individuales gracias a su mayor capacidad para aproximar la función de predicción real en un problema de aprendizaje supervisado.\n",
    "\n",
    "* Los métodos de Ensamble se desempeñan mejor en escenarios más complejos, pero pueden resultar en modelos muy complicados y difíciles de interpretar.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div class=\"div-dhds-fondo-1\"> Hands-on\n",
    "<img src=\"https://raw.githubusercontent.com/Digital-House-DATA/ds_blend_2021_img/master/M5/CLASE_36_Ensemble/M5_CLASE_36_separador.png\" align=\"center\" />\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Ejercicio\n",
    "\n",
    "Vamos a usar el dataset Hitters para entrenar un modelo de ensamble para clasificar el valor de `Salary` en alto o bajo.\n",
    "\n",
    "El ensamble va a estar compuesto por\n",
    "\n",
    "* Un modelo de clasificación Naive Bayes (Gaussian)\n",
    "\n",
    "* Un modelo de regresión logística con regularización\n",
    "\n",
    "* Un árbol de clasificación\n",
    "\n",
    "Vamos a calcular la predicción para cada instancia como el promedio de las probabilidades resultado de cada uno de estos tres modelos.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "1. Leer los datos y, para simplificar, conservar sólo los registros completos y las features numéricas.\n",
    "\n",
    "2. Crear una variable categórica, a partir de `Salary`, de valores alto / bajo representados como 1 / 0, usando como umbral un valor de Salary igual a 600\n",
    "\n",
    "3. Crear los conjuntos de train y test\n",
    "\n",
    "4. Estandarizar las features\n",
    "\n",
    "5. Entrenar cada uno de los modelos base del ensamble y evaluar con AUC la performance de cada uno de los modelos base\n",
    "\n",
    "6. Escribir una función que devuelva la predicción del ensamble, y comparar la performance obtenida en test con las obtenidas con los modelos base\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "sns.histplot(data.Salary);\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "threshold = 600\n",
    "mask = data.Salary < threshold\n",
    "print(sum(mask))\n",
    "mask = data.Salary >= threshold\n",
    "print(sum(mask))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Solución\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import binarize\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "data_raw = pd.read_csv(\"../Data/Hitters.csv\")\n",
    "print(data_raw.shape)\n",
    "data_complete = data_raw.dropna()\n",
    "print(data_complete.shape)\n",
    "\n",
    "data_columns = ['AtBat', 'Hits', 'HmRun', 'Runs', 'RBI', \n",
    "                'Walks', 'Years', 'CAtBat', 'CHits', 'CHmRun', \n",
    "                'CRuns', 'CRBI', 'CWalks', 'PutOuts', 'Assists', \n",
    "                'Errors', 'Salary']\n",
    "\n",
    "data = data_complete.loc[:, data_columns]\n",
    "print(data.shape)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "salary_cat = binarize(pd.DataFrame(data.Salary), threshold = 600)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "X = data.drop(\"Salary\", axis = 1)\n",
    "print(X.shape)\n",
    "\n",
    "y = salary_cat\n",
    "print(y.shape)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,random_state = 127)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "4. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scl = scaler.fit_transform(X_train)\n",
    "\n",
    "X_test_scl = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Entrenamos el modelo de Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1 = GaussianNB()\n",
    "y_train_nb = y_train.reshape(y_train.shape[0], )\n",
    "fit_1 = model_1.fit(X_train_scl, y_train_nb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Evaluamos la performance en test usando AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "predict_1 = fit_1.predict_proba(X_test_scl)\n",
    "predict_1_class_1 = predict_1[:, 1]\n",
    "performance_1 = roc_auc_score(y_test, predict_1_class_1)\n",
    "performance_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Entrenamos el modelo de regresión logística con regularización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "model_2 = LogisticRegression(solver = \"saga\", penalty=\"elasticnet\", l1_ratio = 0.5, C = 0.1)\n",
    "y_train_lr = y_train.reshape(y_train.shape[0], )\n",
    "fit_2 = model_2.fit(X_train_scl, y_train_lr);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Evaluamos la performance en test usando AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "predict_2 = fit_2.predict_proba(X_test_scl)\n",
    "predict_2_class_1 = predict_2[:, 1]\n",
    "performance_2 = roc_auc_score(y_test, predict_2_class_1)\n",
    "performance_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Entrenamos el árbol de clasificación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "model_3 = tree.DecisionTreeClassifier(criterion='entropy')\n",
    "fit_3 = model_3.fit(X_train_scl, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Evaluamos la performance en test usando AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "predict_3 = fit_3.predict_proba(X_test_scl)\n",
    "predict_3_class_1 = predict_3[:, 1]\n",
    "performance_3 = roc_auc_score(y_test, predict_3_class_1)\n",
    "performance_3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def predict_proba_ensamble(X, model_1, model_2, model_3):\n",
    "    y_pred_1 = model_1.predict_proba(X)[:, 1]\n",
    "    y_pred_2 = model_2.predict_proba(X)[:, 1]\n",
    "    y_pred_3 = model_3.predict_proba(X)[:, 1]\n",
    "    result = (y_pred_1 + y_pred_2 + y_pred_3) / 3\n",
    "    return result\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Observación: \n",
    "    \n",
    "Para calcular AUC necesitamos las probabilidades de pertenecer a una de las clases, por eso usamos predict_proba. \n",
    "\n",
    "Si empleáramos accuracy como medida de performance, podríamos usar predict en lugar de predict_proba para obtener los valores predichos, y la moda en lugar del promedio para calcular la predicción del ensamble."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Evaluamos la performance en test usando AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "y_pred_ensemble = predict_proba_ensamble(X_test_scl, model_1, model_2, model_3)\n",
    "performance_ensemble =  roc_auc_score(y_test, y_pred_ensemble)\n",
    "performance_ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Observemos que el valor de AUC del modelo de ensamble es el mejor obtenido."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div class=\"div-dhds-fondo-1\"> Referencias\n",
    "<img src=\"https://raw.githubusercontent.com/Digital-House-DATA/ds_blend_2021_img/master/M5/CLASE_36_Ensemble/M5_CLASE_36_separador.png\" align=\"center\" />\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<a href=\"https://www.youtube.com/watch?v=Un9zObFjBH0\" target=\"_blank\">Ensemble learners</a>\n",
    "\n",
    "<a href=\"https://towardsdatascience.com/simple-guide-for-ensemble-learning-methods-d87cc68705a2\" target=\"_blank\">Simple guide for ensemble learning methods</a>\n",
    "\n",
    "<a href=\"https://juhiramzai.medium.com/holy-grail-for-bias-variance-tradeoff-overfitting-underfitting-7fad64ab5d76\" target=\"_blank\">Holy Grail for Bias-Variance tradeoff, Overfitting & Underfitting</a>\n",
    "\n",
    "<a href=\"https://www.kaggle.com/mathchi/hitters-baseball-data\" target=\"_blank\">Dataset Hitters</a>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
