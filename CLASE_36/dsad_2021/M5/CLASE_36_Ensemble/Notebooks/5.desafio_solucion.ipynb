{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "floppy-armstrong",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial setup\n",
    "%run \"../../../common/0_notebooks_base_setup.py\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "involved-rings",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<img src='../../../common/logo_DH.png' align='left' width=35%/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "joined-music",
   "metadata": {},
   "source": [
    "# Modelos de Ensamble"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sunrise-pressure",
   "metadata": {},
   "source": [
    "## Introducción\n",
    "\n",
    "Usando el dataset Movie_classification, que vimos en la clase de CART, vamos a \n",
    "\n",
    "* Entrenar tres modelos base de clasificación, y construir a partir de ellos un ensamble para predecir el valor de la variable Start_Tech_Oscar usando predict_proba y AUC como métrica\n",
    "\n",
    "* Comparar la performance de los modelos base con la del modelo de ensamble, y con el resultado del checkpoint.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "executive-decision",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "En esta clase usaremos un dataset con info de películas (\"Movie_classification.csv\").  \n",
    "Este dataset esta conformado por los siguientes features:  \n",
    "\n",
    " *   **Marketing expense:**    (float64)    Gasto total en Marketing      \n",
    " *   **Production expense:**   (float64)    Gasto total de Producción\n",
    " *   **Multiplex coverage:**   (float64)    Cobertura promedio de Multiplex\n",
    " *   **Budget:**               (float64)    Presupuesto\n",
    " *   **Movie_length:**         (float64)    Duración de la película\n",
    " *   **Lead_ Actor_Rating:**   (float64)    Puntaje sobre el actor principal\n",
    " *   **Lead_Actress_rating:**  (float64)    Puntaje sobre la actriz principal\n",
    " *   **Director_rating:**      (float64)    Puntaje sobre el Director\n",
    " *   **Producer_rating:**      (float64)    Puntaje sobre el Productor\n",
    " *   **Critic_rating:**        (float64)    Puntaje que le puso la crítica\n",
    " *   **Trailer_views:**        (int64)      Cantidad de vistas del Trailer\n",
    " *   **3D_available:**         (object)     Si esta disponible en 3D (Yes/No)\n",
    " *   **Time_taken:**           (float64)    Duración de la película\n",
    " *   **Twitter_hastags:**      (float64)    Cantidad de menciones en twitter\n",
    " *   **Genre:**                (object)     Genero de la película\n",
    " *   **Avg_age_actors:**       (int64)      Edad promedio de los actores\n",
    " *   **Num_multiplex:**        (int64)      Cantidad de Multiplex\n",
    " *   **Collection:**           (int64)      Recaudación\n",
    " *   **Start_Tech_Oscar:**     (int64)      Si recibió un oscar o no.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "inner-employee",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tamil-piano",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, confusion_matrix\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "armed-museum",
   "metadata": {},
   "source": [
    "## Ejercicio 1\n",
    "\n",
    "Leamos el dataset \"Movie_classification\", eliminemos los registros con valores faltantes y las features categóricas \"Genre\" y \"3D_available\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "otherwise-spare",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_raw = pd.read_csv(\"../Data/Movie_classification.csv\")\n",
    "print(data_raw.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "detailed-edition",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_no_missing = data_raw.dropna()\n",
    "print(data_no_missing.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "confirmed-lottery",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_no_missing.drop([\"Genre\", \"3D_available\"], axis = 1)\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exterior-vancouver",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "minus-museum",
   "metadata": {},
   "source": [
    "## Ejercicio 2\n",
    "\n",
    "Crear los conjuntos de train y test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "narrative-enterprise",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(\"Start_Tech_Oscar\", axis = 1)\n",
    "print(X.shape)\n",
    "\n",
    "y = data.Start_Tech_Oscar\n",
    "print(y.shape)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,random_state = 127)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interstate-quantity",
   "metadata": {},
   "source": [
    "## Ejercicio 3\n",
    "\n",
    "Estandarizar las features para los conjuntos de train y test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "willing-dominican",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scl = scaler.fit_transform(X_train)\n",
    "\n",
    "X_test_scl = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vital-draft",
   "metadata": {},
   "source": [
    "## Ejercicio 4\n",
    "\n",
    "Entrenar un modelo Naive Bayes para predecir el valor de \"Start_Tech_Oscar\".\n",
    "\n",
    "Evaluar su perfomance en test mediante AUC.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bridal-ethiopia",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1 = GaussianNB()\n",
    "fit_1 = model_1.fit(X_train_scl, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deluxe-spring",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_1 = fit_1.predict_proba(X_test_scl)\n",
    "predict_1_score = predict_1[:, 1]\n",
    "auc_1 = roc_auc_score(y_test, predict_1_score)\n",
    "print(auc_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unauthorized-power",
   "metadata": {},
   "source": [
    "## Ejercicio 5\n",
    "\n",
    "Entrenar un modelo KNN para predecir el valor de \"Start_Tech_Oscar\".\n",
    "\n",
    "Evaluar su perfomance en test mediante AUC.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "structured-technician",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2 = KNeighborsClassifier()\n",
    "fit_2 = model_2.fit(X_train_scl, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "generous-watson",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_2 = fit_2.predict_proba(X_test_scl)\n",
    "predict_2_score = predict_2[:, 1]\n",
    "\n",
    "auc_2 = roc_auc_score(y_test, predict_2_score)\n",
    "print(auc_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "structural-abuse",
   "metadata": {},
   "source": [
    "## Ejercicio 6\n",
    "\n",
    "Entrenar unárbol de clasificación para predecir el valor de \"Start_Tech_Oscar\".\n",
    "\n",
    "Evaluar su perfomance en test mediante la matriz de confusión.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "charitable-recognition",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_3 = tree.DecisionTreeClassifier(criterion='entropy')\n",
    "fit_3 = model_3.fit(X_train_scl, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "american-blake",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_3 = fit_3.predict_proba(X_test_scl)\n",
    "predict_3_score = predict_3[:, 1]\n",
    "\n",
    "auc_3 = roc_auc_score(y_test, predict_3_score)\n",
    "print(auc_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "personal-print",
   "metadata": {},
   "source": [
    "## Ejercicio 7\n",
    "\n",
    "\n",
    "Construir un modelo de ensamble usando como modelos base los tres modelos anteriores.\n",
    "\n",
    "Para esto, escribir la función `predict_proba_ensamble` que calcule la probabilidad de 1 como el promedio de las probabilidades respuesta de los predictores base\n",
    "\n",
    "Evaluar la performance del ensamble (usando como umbral 0.5) mediante\n",
    "\n",
    "* AUC\n",
    "\n",
    "* accuracy\n",
    "\n",
    "* confusion_matrix\n",
    "\n",
    "\n",
    "Comparar estos resultados con los obtenidos en el ejercicio 7 del checkpoint.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "assigned-packaging",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_proba_ensamble(X, model_1, model_2, model_3):\n",
    "    y_pred_1 = model_1.predict_proba(X)[:, 1]\n",
    "    y_pred_2 = model_2.predict_proba(X)[:, 1]\n",
    "    y_pred_3 = model_3.predict_proba(X)[:, 1]\n",
    "    result = (y_pred_1 + y_pred_2 + y_pred_3) / 3    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "introductory-tactics",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_ensemble = predict_proba_ensamble(X_test_scl, fit_1, fit_2, fit_3)\n",
    "auc_ensemble = roc_auc_score(y_test, predict_ensemble)\n",
    "print(auc_ensemble)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "numerical-berry",
   "metadata": {},
   "source": [
    "El valor de AUC del ensamble es mejor que el de cada uno de los modelos base."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "minute-trademark",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.5\n",
    "predict_ensemble_cat = [1 if (x >= threshold) else 0 for x in predict_ensemble]  \n",
    "\n",
    "accuracy_ensemble = accuracy_score(y_test, predict_ensemble_cat)\n",
    "print(accuracy_ensemble)\n",
    "\n",
    "confusion_matrix_ensemble = confusion_matrix(y_test, predict_ensemble_cat)\n",
    "print(confusion_matrix_ensemble)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aging-pricing",
   "metadata": {},
   "source": [
    "El valor de accuracy resultó similar en el ensamble construido usando el promedio de las probabilidades en lugar de la moda de las categorías"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "crazy-slide",
   "metadata": {},
   "source": [
    "## Opcional:\n",
    "\n",
    "¿Pueden mejorar el valor de accuracy del ensamble usando otro valor (distinto de 0.5) para el umbral? \n",
    "\n",
    "¿Qué pasa con la matriz de confusión cuando mejora el valor de accuracy?\n",
    "\n",
    "Pueden hacer la prueba en un ciclo for con distintos valores de threshold, o usar roc_curve (https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_curve.html) para intentar responder."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
