{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial setup\n",
    "%run \"../../../common/0_notebooks_base_setup.py\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<img src='../../../common/logo_DH.png' align='left' width=35%/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checkpoint - Desbalance de clases + Feature Selection\n",
    "\n",
    "En este checkpoint trabajaremos con el dataset de préstamos crediticios 'loans.csv'.\n",
    "\n",
    "En la primera parte combinaremos los elementos vistos en la práctica guiada de clases desbalanceadas para resamplear el data set de entrenamiento.\n",
    "\n",
    "Luego implementaremos un modelo de regresión logística combinado con reducción de la dimensionalidad por eliminación recursiva de features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression,LogisticRegressionCV\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler,OneHotEncoder\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import SMOTENC\n",
    "from sklearn.metrics import accuracy_score,plot_confusion_matrix,roc_auc_score, classification_report, confusion_matrix, precision_recall_curve, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loans = pd.read_csv('../Data/loans.csv',low_memory=False)\n",
    "loans.dropna(inplace=True)\n",
    "loans.reset_index(drop=True,inplace=True)\n",
    "loans['bad_loans'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loans.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Train test split \n",
    "\n",
    "Hagamos un train test split estratificado por la variable target (bad loans). \n",
    "\n",
    "¿Cuál es el desbalance de clases?\n",
    "\n",
    "¿Cuál es el ratio clase mayoritaria/minoritaria?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. SMOTE-NC \n",
    "\n",
    "Implementemos la herramienta [SMOTENC](https://imbalanced-learn.readthedocs.io/en/stable/generated/imblearn.over_sampling.SMOTENC.html) para resamplear la clase minoritaria en el dataset de entrenamiento. Para ello debemos identificar previamente las variables categóricas y pasarlas como argumento al instanciar el objeto SMOTENC.\n",
    "\n",
    "Usemos un **sampling_strategy=0.5**, de modo que la clase mayoritaria tenga el doble de observaciones que la minoritaria.\n",
    "\n",
    "¿Cuál es el balance de clases ahora?\n",
    "\n",
    "¿Cuál es el ratio mayoritaria/minoritaria?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Undersampling\n",
    "\n",
    "A partir del dataset aumentado en el paso anterior balanceemos las clases sampleando aleatoriamente observaciones de la clase mayoritaria. Para esto usemos **RandomUnderSampler** con **sampling_strategy='majority'** de modo que queden las clases balanceadas.\n",
    "\n",
    "¿Cómo quedó el balance de clases?\n",
    "\n",
    "¿Y el tamaño del dataset de entrenamiento?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Variables dummy\n",
    "\n",
    "Utilicemos la herramienta OneHotEncoder para llevar a dummies las variables categoricas del training set. Luego transformamos de manera conforme las categóricas del test set. \n",
    "\n",
    "¿Cuál sería un posible problema de usar get_dummies?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Regresión logística\n",
    "\n",
    "Implementemos una regresión logística usando LogisticRegressionCV. \n",
    "\n",
    "¿Qué medida de scoring conviene usar?\n",
    "\n",
    "Veamos las métricas principales de performance en el test set: \n",
    "\n",
    "* matriz de confusión\n",
    "* clasification report\n",
    "* área bajo la curva ROC\n",
    "* área bajo la curva Precision-Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Feature selection\n",
    "\n",
    "Utilicen la herramientsa RFECV combinada con una regresión logística para seleccionar el mejor subset de features. Usen una regresión logística con el hiperparámetro de regularización C ajustado en el punto anterior. \n",
    "\n",
    "Lo correcto sería optimizar este parámetro para cada subset de features, es decir hacer dos validaciones cruzadas anidadas (una para RFE y otra para la regresión logística), pero por \n",
    "economía de cómputo lo haremos con el valor de C fijo.\n",
    "\n",
    "¿Cuáles features fueron seleccionadas?\n",
    "\n",
    "¿Cuáles fueron descartadas?\n",
    "\n",
    "¿Cuál es la performance del modelo?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
