{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial setup\n",
    "%run \"../../../common/0_notebooks_base_setup.py\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<img src='../../../common/logo_DH.png' align='left' width=35%/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clasificacion: canjeo de coupones de descuento\n",
    "\n",
    "Trabajaremos con el dataset preprocesado en la notebook 'opcional_preprocesamiento_datos_clase'.\n",
    "El mismo cuenta con información de distintas campañas de marketing en donde se ofrecen coupnes de descuento sobre distintas marcas y productos. El dataset preprocesado cuenta con fetures con información sobre las campañas, sobre los consumidores (hábitos de consumo y características demográficas) y sobre los items alcanzados por las promociones.\n",
    "\n",
    "La variable target es el estado de canje de los cupones: \"redemption_status\". \n",
    "\n",
    "El dataset original está [acá](https://www.kaggle.com/vasudeva009/coupon-redemption-smote-feature-selection/data). Se aconseja mirar la notebook de preprocesamiento para entender mejor las variables del dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split,cross_val_score,StratifiedKFold\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import SMOTENC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectKBest, f_classif,RFECV,RFE\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score,plot_confusion_matrix,roc_auc_score, classification_report, confusion_matrix, precision_recall_curve, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('../Data/marketing/data_preprocessed.csv')\n",
    "display(data.head(3))\n",
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data.drop(['Unnamed: 0','id','customer_id','campaign_id','coupon_id'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical=['campaign_type','month','year','age_range','marital_status','rented','family_size','no_of_children',\\\n",
    "             'income_bracket','brand','brand_type','category']\n",
    "\n",
    "data[categorical]=data[categorical].astype('category')\n",
    "data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Primera parte\n",
    "* Ver el balance de clases en el dataset conun value counts de la columna redemption_status\n",
    "* Hacer un train-test-split estratificado\n",
    "* Convertir las variables categoricas a dummy. Conviene que nos quedemos con una versión no dummy del dataset de entrenamiento puesto que luego usaremos SMOTENC\n",
    "* Opcional (recomendado): Armar una función que tome como input un modelo entrenado y un dataset de testeo e imprima las métricas más importantes para evaluar clasificación (classification_report, matriz de confución, area bajo las curvas ROC y Precision-Recall)\n",
    "* Instanciar un modelo Random Forest entrenarlo y evaluarlo en el dataset de testeo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['redemption_status'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train test split\n",
    "\n",
    "X_train,X_test,y_train,y_test=train_test_split(data.drop('redemption_status',axis=1),data['redemption_status'],\\\n",
    "                                               stratify=data['redemption_status'],random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_dummy=pd.get_dummies(X_train);\n",
    "X_test_dummy=pd.get_dummies(X_test)\n",
    "print('Mismas categorías en Train y Test:',(X_train_dummy.columns==X_test_dummy.columns).all())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model,X,y_true):\n",
    "    '''\n",
    "    Calcula las métricas ppales para evaluar un clasificador\n",
    "    Toma como imput el modelo entrenado, el dataset de testeo y sus etiquetas\n",
    "    '''\n",
    "    y_pred=model.predict(X)\n",
    "    y_proba=model.predict_proba(X)\n",
    "\n",
    "    print(classification_report(y_true,y_pred))\n",
    "    print('Area bajo la curva ROC:',np.round(roc_auc_score(y_true,y_proba[:,1]),4))\n",
    "    precision, recall,threshold=precision_recall_curve(y_true,y_proba[:,1]);\n",
    "    print('Area bajo la curva Precision-Recall:',np.round(auc(recall,precision),4))\n",
    "    plot_confusion_matrix(model,X,y_true,cmap='Blues');\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=RandomForestClassifier()\n",
    "model.fit(X_train_dummy,y_train)\n",
    "evaluate_model(model,X_test_dummy,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resampling de las clases\n",
    "\n",
    "* Hacer un undersampling de la clase mayoritaria en el training set para balancear las clases. ¿De qué tamaño quedó el dataset de entrenamiento?\n",
    "* Volver a entrenar un random forest y evaluarlo en test\n",
    "* Repetir el procedimiento usando SMOTENC para sobresamplear la clase minoritaria\n",
    "* Instanciar un Random Forest usando class_weight='balanced_subsample', entrenarlo en el training set original (sin resampling) y evaluarlo en test set\n",
    "\n",
    "* Combinar las tres estrategias anteriores:\n",
    "- Undersampling\n",
    "- Oversampling\n",
    "- Class weight\n",
    "Usar una combinación de undersampling y oversampling que les parezca razonable. Idealmente habría que optimizar esta combinación mediante cross-validation, pero no hay que subestimar el tiempo de cómputo. Utilicen una combinación de sampling_stategy que de por resultado un dataset de tamaño reducido respecto del original. Usaremos ese dataset para hacer feature selection en la segunda parte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UnderSampling del dataset\n",
    "\n",
    "sampler=RandomUnderSampler()\n",
    "X_train_us,y_train_us=sampler.fit_resample(X_train_dummy,y_train)\n",
    "print('X_train_us:',X_train_us.shape)\n",
    "print('\\nBalance de clases en train:')\n",
    "print(y_train_us.value_counts())\n",
    "\n",
    "print('\\n\\nX_test:',X_test_dummy.shape)\n",
    "print('\\nBalance de clases en test:')\n",
    "print(y_test.value_counts())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=RandomForestClassifier()\n",
    "model.fit(X_train_us,y_train_us)\n",
    "print('DATASET SUBSAMPLEADO')\n",
    "evaluate_model(model,X_test_dummy,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('DATASET SOBRESAMPLEADO')\n",
    "categorical_mask=(X_train.dtypes=='category').values\n",
    "sm=SMOTENC(categorical_features=categorical_mask,sampling_strategy='minority')\n",
    "X_train_os,y_train_os=sm.fit_resample(X_train,y_train)\n",
    "X_train_os=pd.get_dummies(X_train_os)\n",
    "\n",
    "print('X_train_os:',X_train_os.shape)\n",
    "print('\\nBalance de clases en train:')\n",
    "print(y_train_os.value_counts())\n",
    "\n",
    "print('\\n\\nX_test:',X_test_dummy.shape)\n",
    "print('\\nBalance de clases en test:')\n",
    "print(y_test.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=RandomForestClassifier()\n",
    "model.fit(X_train_os,y_train_os)\n",
    "evaluate_model(model,X_test_dummy,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Balance de clases\n",
    "model=RandomForestClassifier(class_weight='balanced_subsample')\n",
    "model.fit(X_train_dummy,y_train)\n",
    "evaluate_model(model,X_test_dummy,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combinando Estrategias\n",
    "sampler=RandomUnderSampler(sampling_strategy=0.05)\n",
    "X,y=sampler.fit_resample(X_train,y_train)\n",
    "sm=SMOTENC(categorical_mask,sampling_strategy=0.2)\n",
    "X_train_rs,y_train_rs=sm.fit_resample( X,y)\n",
    "\n",
    "X_train_rs=pd.get_dummies(X_train_rs)\n",
    "if not (X_test_dummy.columns==X_train_rs.columns).all():\n",
    "    print('Train y Test tienen distintas Categorias:')\n",
    "    print('Usar OneHotEncoding')\n",
    "\n",
    "print(y_train_rs.shape)\n",
    "print(y_train_rs.mean())\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Balance de clases\n",
    "model=RandomForestClassifier(class_weight='balanced_subsample')\n",
    "model.fit(X_train_rs,y_train_rs)\n",
    "evaluate_model(model,X_test_dummy,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Segunda Parte: Selección de Features\n",
    "\n",
    "#### SelectKBest\n",
    "\n",
    "Primero seleccionemos featuers usando SelectKbest tomando como medida de score el criterio 'f_classif'\n",
    "\n",
    "* Hacer un pipeline que concatene el selector de features y un RandomForestClassifier con class_weight='balanced_subsample'\n",
    "* Hacer una gridsearchCV variando el parámetro k del selector de features. Usar scoring='f1'.\n",
    "* Graficar los resultados del procedimiento de cross-validation: scores de clasificacion vs nro de features\n",
    "* ¿Con cuántas features se quedarían? ¿Cuáles?\n",
    "* ¿Cuál es el score en el test set al seleccionar el subset de features elegido?\n",
    "* Graficar la importancia de las features para el modelo (atributo feature_importance_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleccion de features:\n",
    "skf=StratifiedKFold(n_splits=3,shuffle=True,random_state=0)\n",
    "steps=([('selector',SelectKBest(f_classif)),('classif',RandomForestClassifier(class_weight='balanced_subsample'))])\n",
    "pipe=Pipeline(steps)\n",
    "param_grid={'selector__k':np.arange(10,150,20)}\n",
    "grid=GridSearchCV(pipe,param_grid,scoring='f1',cv=skf,verbose=3,n_jobs=3)\n",
    "grid.fit(X_train_rs,y_train_rs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features=grid.cv_results_['param_selector__k'].data\n",
    "mn_cv_score=grid.cv_results_['mean_test_score']\n",
    "err=grid.cv_results_['std_test_score']\n",
    "plt.bar(n_features,mn_cv_score,color = \"r\",width=3,yerr=err,align = \"center\")\n",
    "plt.xlabel('Número de features')\n",
    "plt.ylabel('test score');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluamos en test\n",
    "skb=SelectKBest(f_classif,k=70)\n",
    "X_train_reduced=skb.fit_transform(X_train_rs,y_train_rs)\n",
    "X_test_reduced=X_test_dummy.loc[:,skb.get_support()]\n",
    "model=RandomForestClassifier(class_weight='balanced_subsample')\n",
    "model.fit(X_train_reduced,y_train_rs)\n",
    "evaluate_model(model,X_test_reduced,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=np.sort(model.feature_importances_)\n",
    "x=np.argsort(model.feature_importances_)\n",
    "x=x[::-1]\n",
    "feat_names=X_train_rs.columns[skb.get_support()]\n",
    "labels=feat_names[x]\n",
    "y=y[::-1]\n",
    "\n",
    "plt.figure(figsize=(15,8))\n",
    "plt.bar(range(len(y)),y,color = \"r\",width=3,align = \"center\")\n",
    "plt.xticks(range(len(y)), labels, rotation=90)\n",
    "\n",
    "plt.xlim([0,30])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Seleccion de Features por RFE\n",
    "* Implementar RFECV usando como modelo un randomforest con clases pesadas. Usar un step grande (50) para tener una primera aproximacion\n",
    "* Graficar los scores obtenidos para cada numero de features\n",
    "* Usar RFE para seleccionar el número de features más adecuado. En este caso implementar un paso más fino (step=10), entrenando en todo el dataset de entremiento (sin cross-validation)\n",
    "* Evaluar el modelo en el test set y mirar las feature_importance_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recursive feature elimination\n",
    "skf=StratifiedKFold(n_splits=3,shuffle=True,random_state=0)\n",
    "rfecv = RFECV(RandomForestClassifier(class_weight='balanced_subsample'), step = 50, cv=skf, scoring = 'f1', verbose=2)\n",
    "rfecv.fit(X_train_rs,y_train_rs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#n_features=grid.cv_results_['param_selector__k'].data\n",
    "mn_cv_score=rfecv.grid_scores_\n",
    "n_features=np.arange(7,357+50,50)\n",
    "n_features=np.insert(n_features,0,1)\n",
    "\n",
    "plt.bar(n_features,mn_cv_score,color = \"r\",width=3,align = \"center\")\n",
    "plt.xlabel('Número de features');\n",
    "plt.ylabel('test score');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfe=RFE(RandomForestClassifier(class_weight='balanced_subsample'),\\\n",
    "       n_features_to_select=70,step=10,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfe.fit(X_train_rs,y_train_rs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_reduced=X_train_rs.loc[:,rfe.support_]\n",
    "X_test_reduced=X_test_dummy.loc[:,rfe.support_]\n",
    "model=RandomForestClassifier(class_weight='balanced_subsample')\n",
    "model.fit(X_train_reduced,y_train_rs)\n",
    "evaluate_model(model,X_test_reduced,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=np.sort(model.feature_importances_)\n",
    "x=np.argsort(model.feature_importances_)\n",
    "x=x[::-1]\n",
    "feat_names=X_train_rs.columns[skb.get_support()]\n",
    "labels=feat_names[x]\n",
    "y=y[::-1]\n",
    "\n",
    "plt.figure(figsize=(15,8))\n",
    "plt.bar(range(len(y)),y,color = \"r\",width=3,align = \"center\")\n",
    "plt.xticks(range(len(y)),labels,rotation=90);\n",
    "plt.xlim([0,30])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
