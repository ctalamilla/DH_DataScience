{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial setup\n",
    "%run \"../../../common/0_notebooks_base_setup.py\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<img src='../../../common/logo_DH.png' align='left' width=35%/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clasificacion: canjeo de coupones de descuento\n",
    "\n",
    "Trabajaremos con el dataset preprocesado en la notebook 'opcional_preprocesamiento_datos_clase'.\n",
    "El mismo cuenta con información de distintas campañas de marketing en donde se ofrecen coupnes de descuento sobre distintas marcas y productos. El dataset preprocesado cuenta con fetures con información sobre las campañas, sobre los consumidores (hábitos de consumo y características demográficas) y sobre los items alcanzados por las promociones.\n",
    "\n",
    "La variable target es el estado de canje de los cupones: \"redemption_status\". \n",
    "\n",
    "El dataset original está [acá](https://www.kaggle.com/vasudeva009/coupon-redemption-smote-feature-selection/data). Se aconseja mirar la notebook de preprocesamiento para entender mejor las variables del dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split,cross_val_score,StratifiedKFold\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import SMOTENC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectKBest, f_classif,RFECV,RFE\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score,plot_confusion_matrix,roc_auc_score, classification_report, confusion_matrix, precision_recall_curve, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('../Data/marketing/data_preprocessed.csv')\n",
    "display(data.head(3))\n",
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data.drop(['Unnamed: 0','id','customer_id','campaign_id','coupon_id'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical=['campaign_type','month','year','age_range','marital_status','rented','family_size','no_of_children',\\\n",
    "             'income_bracket','brand','brand_type','category']\n",
    "\n",
    "data[categorical]=data[categorical].astype('category')\n",
    "data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Primera parte\n",
    "* Ver el balance de clases en el dataset conun value counts de la columna redemption_status\n",
    "* Hacer un train-test-split estratificado\n",
    "* Convertir las variables categoricas a dummy. Conviene que nos quedemos con una versión no dummy del dataset de entrenamiento puesto que luego usaremos SMOTENC\n",
    "* Opcional (recomendado): Armar una función que tome como input un modelo entrenado y un dataset de testeo e imprima las métricas más importantes para evaluar clasificación (classification_report, matriz de confución, area bajo las curvas ROC y Precision-Recall)\n",
    "* Instanciar un modelo Random Forest entrenarlo y evaluarlo en el dataset de testeo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resampling de las clases\n",
    "\n",
    "* Hacer un undersampling de la clase mayoritaria en el training set para balancear las clases. ¿De qué tamaño quedó el dataset de entrenamiento?\n",
    "* Volver a entrenar un random forest y evaluarlo en test\n",
    "* Repetir el procedimiento usando SMOTENC para sobresamplear la clase minoritaria\n",
    "* Instanciar un Random Forest usando class_weight='balanced_subsample', entrenarlo en el training set original (sin resampling) y evaluarlo en test set\n",
    "\n",
    "* Combinar las tres estrategias anteriores:\n",
    "- Undersampling\n",
    "- Oversampling\n",
    "- Class weight\n",
    "Usar una combinación de undersampling y oversampling que les parezca razonable. Idealmente habría que optimizar esta combinación mediante cross-validation, pero no hay que subestimar el tiempo de cómputo. Utilicen una combinación de sampling_stategy que de por resultado un dataset de tamaño reducido respecto del original. Usaremos ese dataset para hacer feature selection en la segunda parte"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Segunda Parte: Selección de Features\n",
    "\n",
    "#### SelectKBest\n",
    "\n",
    "Primero seleccionemos featuers usando SelectKbest tomando como medida de score el criterio 'f_classif'\n",
    "\n",
    "* Hacer un pipeline que concatene el selector de features y un RandomForestClassifier con class_weight='balanced_subsample'\n",
    "* Hacer una gridsearchCV variando el parámetro k del selector de features. Usar scoring='f1'.\n",
    "* Graficar los resultados del procedimiento de cross-validation: scores de clasificacion vs nro de features\n",
    "* ¿Con cuántas features se quedarían? ¿Cuáles?\n",
    "* ¿Cuál es el score en el test set al seleccionar el subset de features elegido?\n",
    "* Graficar la importancia de las features para el modelo (atributo feature_importance_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Seleccion de Features por RFE\n",
    "* Implementar RFECV usando como modelo un randomforest con clases pesadas. Usar un step grande (50) para tener una primera aproximacion\n",
    "* Graficar los scores obtenidos para cada numero de features\n",
    "* Usar RFE para seleccionar el número de features más adecuado. En este caso implementar un paso más fino (step=10), entrenando en todo el dataset de entremiento (sin cross-validation)\n",
    "* Evaluar el modelo en el test set y mirar las feature_importance_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
