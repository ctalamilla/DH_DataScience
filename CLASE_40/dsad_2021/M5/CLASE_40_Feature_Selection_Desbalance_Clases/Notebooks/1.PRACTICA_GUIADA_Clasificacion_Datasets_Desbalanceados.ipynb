{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial setup\n",
    "%run \"../../../common/0_notebooks_base_setup.py\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<img src='../../../common/logo_DH.png' align='left' width=35%/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "epAlo2Q3K8OF"
   },
   "source": [
    "# Práctica Guiada - Clasificación en datasets desbalanceados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section_toc\"></a> \n",
    "## Tabla de Contenidos\n",
    "\n",
    "[1- Introducción](#section_intro)\n",
    "\n",
    "[2- Análisis exploratorio del dataset](#section_EDA)\n",
    "\n",
    "[3- Modelo predictivo: regresión logística](#section_modelo)\n",
    "\n",
    "[4- Undersampling](#section_undersampling)\n",
    "\n",
    "[5- Oversampling](#section_oversampling)\n",
    "\n",
    "[6- Class weighting](#section_class_weighting)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "puQ9YKZCK8OH"
   },
   "source": [
    "### Introducción\n",
    "\n",
    "<a id=\"section_intro\"></a> \n",
    "[volver a TOC](#section_toc)\n",
    "\n",
    "\n",
    "El problema de los datasets desbalanceados ocurre cada vez que por algún motivo las clases que se desean identificar se observan con frecuencia muy diferente. Es una situación que se encuentra en una amplia variedad de problemas de Machine Learning como el diagnóstico de enfermedades o la búsqueda de transacciones fraudulentas en un sistema. \n",
    "\n",
    "Existen dos grandes enfoques para abordar datasets que se encuentran desbalanceados:\n",
    "\n",
    "1.  Hacer un resampling de la muestra, para entrenar al algoritmo con proporciones similares de las clases.\n",
    "2.  Incorporar el desbalance a la función de costos del algoritmo para que tenga incentivos a elegir los parámetros que mejor discriminan la clase minoritaria.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6S6sXmsSK8OJ"
   },
   "source": [
    "A continuación presentamos un dataset de la empresa americana Lending Club, que se dedica a proveer servicios financieros para distintos segmentos. \n",
    "\n",
    "Vamos a utilizar información abierta del portal de la empresa para intentar predecir cuáles de los créditos terminan en default. Para más información sobre el datset pueden ingresar <a href='https://www.lendingclub.com/info/download-data.action'> aquí </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Actualizar scikit-learn e Instalar imbalanced-learn\n",
    "\n",
    "**Si la primera celda se ejecutó sin errores, omitan esta parte.**\n",
    "\n",
    "Si no, sigan estas instrucciones para instalar las dependencias necesarias para ejecutar esta notebook.\n",
    "\n",
    "En esta práctica usaremos la librería imbalanced-learn. La instalamos con la siguiente linea:\n",
    "\n",
    "!conda install --yes -c conda-forge imbalanced-learn==0.7\n",
    " \n",
    "Pueden tener problemas con versiones de scikitlearn anteriores a 0.23. Entonces:\n",
    "\n",
    "!conda install scikit-learn==0.23\n",
    "\n",
    "o\n",
    "\n",
    "!conda update scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p2PHSRoPK8OK"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score,plot_confusion_matrix,roc_auc_score, classification_report, confusion_matrix, precision_recall_curve, auc\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ylvmz7hrK8OR"
   },
   "outputs": [],
   "source": [
    "loans = pd.read_csv('../Data/loans.csv',low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loans.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aYvvW3HlK8OW"
   },
   "source": [
    "\n",
    "<a id=\"section_EDA\"></a> \n",
    "## Análisis exploratorio\n",
    "[volver a TOC](#section_toc)\n",
    "\n",
    "#### Balance de la clase\n",
    "\n",
    "La clase que vamos a intentar predecir es \"bad loans\" que indica si el préstamo fue pagado a tiempo o no. Observamos que la clase está desbalanceada, la mayoría de los préstamos se pagan a tiempo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BlIfUosgK8OY"
   },
   "outputs": [],
   "source": [
    "loans['bad_loans'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dinDuG-NVXZR"
   },
   "source": [
    "#### Valores faltantes\n",
    "\n",
    "Inspeccionamos los valores faltantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CKTjtKNkK8O3"
   },
   "outputs": [],
   "source": [
    "loans.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eliminamos las entradas nulas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "F45nRKCWK8O_"
   },
   "outputs": [],
   "source": [
    "loans.dropna(inplace=True);\n",
    "loans.reset_index(drop=True,inplace=True)\n",
    "loans.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "89F7zV-_K8PT"
   },
   "source": [
    "<a id=\"section_modelo\"></a> \n",
    "## Modelo Predictivo: regresión logística\n",
    "\n",
    "[volver a TOC](#section_toc)\n",
    "\n",
    "Vamos a utilizar Regresión Logística para predecir la clase bad_loans. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loans.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables dummy\n",
    "\n",
    "Generamos las variables dummies para los datos categóricos. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zv5V3VJ8K8PV"
   },
   "outputs": [],
   "source": [
    "# Generamos las variables dummies para los datos categóricos.\n",
    "loans_dummy = pd.get_dummies(loans,drop_first=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loans_dummy.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loans.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loans.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train test split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qLH7JTwoK8PZ"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test\\\n",
    "                            = train_test_split(loans_dummy.drop(['bad_loans'], axis=1),\\\n",
    "                                    loans_dummy['bad_loans'],\\\n",
    "                                    stratify = loans_dummy['bad_loans'],\\\n",
    "                                    random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chequeamos la presencia relativa de cada clase y el tamaño de los datasets\n",
    "print('Entrenamiento:',X_train.shape)\n",
    "print('Testeo:',X_test.shape)\n",
    "print('\\nClases train:')\n",
    "print(y_train.value_counts(normalize=True))\n",
    "print('\\nClases test:')\n",
    "print(y_test.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regresión logística\n",
    "\n",
    "La siguiente función implementa una regresión logística optimizando el hiperparámetro de regularización por cross validation.\n",
    "\n",
    "Luego imprime las métricas principales de evaluación en problemas de clasificación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_regression_report(X_train,X_test,y_train,y_test):\n",
    "    \n",
    "    scaler=StandardScaler()  \n",
    "    \n",
    "    X_train_sc=scaler.fit_transform(X_train) # Estandarizamos los datos     \n",
    "    X_test_sc=scaler.transform(X_test)\n",
    "        \n",
    "    model=LogisticRegressionCV(scoring='f1')\n",
    "    \n",
    "    model.fit(X_train_sc,y_train)\n",
    "    y_pred=model.predict(X_test_sc)\n",
    "    y_proba=model.predict_proba(X_test_sc)\n",
    "    \n",
    "    print(classification_report(y_test,y_pred))\n",
    "    \n",
    "    print('Area bajo la curva ROC:',np.round(roc_auc_score(y_test,y_proba[:,1]),4))\n",
    "    \n",
    "    precision, recall,threshold=precision_recall_curve(y_test,y_proba[:,1]);\n",
    "\n",
    "    print('Area bajo la curva Precision-Recall:',np.round(auc(recall,precision),4))\n",
    "\n",
    "    plot_confusion_matrix(model,X_test_sc,y_test,cmap='Blues');\n",
    "\n",
    "    return\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_regression_report(X_train,X_test,y_train,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que el modelo tiene una accuracy de 0.81. Los valores de precision y recall nos muestran que el modelo es bueno prediciendo la clase mayoritaria pero es muy malo para la clase minoritaria. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "X4jIoxaqK8P0"
   },
   "source": [
    "\n",
    "\n",
    "Vamos a implementar tres posibles soluciones al problema del desbalance de clases:<b> Undersampling, Oversampling, Class weighting</b>\n",
    "\n",
    "Para resamplear los datos utilizaremos la librería <b>imblearn</b>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section_undersampling\"></a>\n",
    "\n",
    "## Undersampling\n",
    "\n",
    "[Volver a TOC](#section_toc)\n",
    "\n",
    "\n",
    "Una estrategia posible es entrenar un modelo en un subset de datos con clases balanceadas, descartando casos de la clase mayoritaria. Para esto utilizaremos la clase RandomUnderSampler que samplea observaciones de la clase mayoritaria al azar, con o sin reposición.\n",
    "\n",
    "El hiporparámetro **sampling_strategy** sirve para definir la estrategia de sampleo. La opción 'majority' seleccionará un número de muestras igual al de la clase minoritaria. También se puede pasar un valor numérico entre cero y uno que represnte el ratio entre la clase mayoritaria y la minoritaria.\n",
    "\n",
    "[Documentación](https://imbalanced-learn.readthedocs.io/en/stable/generated/imblearn.under_sampling.RandomUnderSampler.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "undersampler=RandomUnderSampler(sampling_strategy='majority');\n",
    "\n",
    "X_train_us,y_train_us=undersampler.fit_resample(X_train,y_train);\n",
    "\n",
    "print('Composición del training set:')\n",
    "print(y_train_us.value_counts())\n",
    "\n",
    "print('\\nComposición del test set:')\n",
    "print(y_test.value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_regression_report(X_train_us, X_test, y_train_us, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que el modelo hace un mejor trabajo en reconocer a la clase minoritaria. \n",
    "\n",
    "Cabe recordar que hemos descartado un gran número de observaciones (todas de la clase 0). Veamos cómo generaliza el modelo si las incluimos en el test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agrego los datos dropeados al test set\n",
    "dropped_indices=set(loans.index)-set(undersampler.sample_indices_);\n",
    "\n",
    "dropped_features=loans_dummy.drop(['bad_loans'],axis=1)[loans.index.isin(dropped_indices)];\n",
    "dropped_targets=loans['bad_loans'][loans.index.isin(dropped_indices)];\n",
    "\n",
    "X_test_ext=X_test.append(dropped_features)\n",
    "y_test_ext=y_test.append(dropped_targets)\n",
    "\n",
    "print('Composición del training set:')\n",
    "print(y_train_us.value_counts())\n",
    "\n",
    "print('\\nComposición del test set:')\n",
    "print(y_test_ext.value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_regression_report(X_train_us,X_test_ext,y_train_us,y_test_ext)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DuW5s9npK8P1"
   },
   "source": [
    "<a id=\"section_oversampling\"></a>\n",
    "\n",
    "## Oversampling\n",
    "\n",
    "[Volver a TOC](#section_toc)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ckQn2V47K8P3"
   },
   "source": [
    "Para aumentar la representación de la clase minoritaria vamos a hacer un oversampling. Una estrategia posible es usar la herramienta RandomOversampler, que funciona de manera análoga a RandomUndersampler. En este caso, el método consiste en samplear observaciones de la clase minoritaria con reposición.\n",
    "\n",
    "El hiperparámetro **sampling_strategy** puede tomar los valores:\n",
    "\n",
    "* 'minority': samplea hasta balancear las clases\n",
    "* número entre 0 y 1: ratio entre las clases mayoritaria y minoritaria\n",
    "\n",
    "[Documentación](https://imbalanced-learn.readthedocs.io/en/stable/generated/imblearn.over_sampling.RandomOverSampler.html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "oversampler=RandomOverSampler(sampling_strategy='minority');\n",
    "\n",
    "X_train_os,y_train_os=oversampler.fit_resample(X_train,y_train);\n",
    "\n",
    "print('Composición del training set:')\n",
    "print(y_train_os.value_counts())\n",
    "\n",
    "print('\\nComposición del test set:')\n",
    "print(y_test.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_regression_report(X_train_os,X_test,y_train_os,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ckQn2V47K8P3"
   },
   "source": [
    "### Over sampling con SMOTE\n",
    "\n",
    "El algoritmo SMOTE (Synthetic Minority Oversample) ofrece otra estrategia de oversampling, generando muestras simuladas de la clase minoritaria.\n",
    "\n",
    "Cuando las features son numéricas, el algoritmo funciona de este modo:\n",
    "\n",
    "1. Se elige un punto al azar de la clase minoritaria.\n",
    "2. Se elige al azar uno de los K vecinos más cercanos al punto elegido en 1.\n",
    "3. Se calcula el vector que une los puntos elegidos en 1 y 2 y se lo multiplica por un número aleatorio entre 0 y 1.\n",
    "4. El punto aleatorio definido en el paso 3 constituye una nueva observación de la clase minoritaria.\n",
    "\n",
    "De este modo, el algoritmo genera datos ficticios vecinos a las observaciones de la clase minoritaria.\n",
    "\n",
    "Cuando las features son tanto numéricas como categóricas conviene usar la versión del algoritmo [SMOTENC](https://imbalanced-learn.readthedocs.io/en/stable/generated/imblearn.over_sampling.SMOTENC.html). Esta versión\n",
    "asigna la categoría más frecuente entre los k-vecinos a la nueva instancia generada.\n",
    "\n",
    "Hay una sutileza al respecto de usar SMOTE con variables dummy. Supongamos que convertimos las variables categóricas a dummy y luego implementamos SMOTENC tomando cada dummy como categórica, con categorías 0 y 1. El algoritmo sampleará los k vecinos más cercanos a una observación de la clase minoritaria y pontrá en cada columna dummy el valor más frecuente entre esos vecinos. Ahora bien, si la mayoría de los k vecinos (más del 50%) no es de la misma categoría, entonces el valor más frecuente en todas las dummy será el cero. De este modo estaríamos asignando erróneamente la categoría al nuevo dato generado.\n",
    "\n",
    "Por este motivo conviene usar SMOTENC con las variables originales categóricas y luego pasar a dummy para entrenar los modelos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Volvemos a hacer el train test split (con la misma semilla que al principio) conservando las variables categóricas\n",
    "\n",
    "X_train_cat, X_test_cat, y_train, y_test\\\n",
    "                            = train_test_split(loans.drop(['bad_loans'], axis=1),\\\n",
    "                                    loans['bad_loans'],\\\n",
    "                                    stratify = loans['bad_loans'],\\\n",
    "                                    random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTENC\n",
    "\n",
    "categorical_cols=(X_train_cat.dtypes=='object').values\n",
    "numerical_cols= ~categorical_cols\n",
    "\n",
    "sm=SMOTENC(categorical_features=categorical_cols,k_neighbors=5,random_state=0)\n",
    "X_train_sm,y_train_sm=sm.fit_resample(X_train_cat,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Balance de clases:')\n",
    "print(y_train_sm.value_counts(normalize=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc=OneHotEncoder(drop='first',sparse=False)\n",
    "train_dummies=enc.fit_transform(X_train_sm.loc[:,categorical_cols])\n",
    "train_dummies=pd.DataFrame(train_dummies)\n",
    "train_dummies.columns=[x for cat_list in enc.categories_ for x in cat_list[1:]]\n",
    "\n",
    "X_train_final=X_train_sm.loc[:,numerical_cols].join(train_dummies)\n",
    "\n",
    "test_dummies=enc.transform(X_test_cat.loc[:,categorical_cols])\n",
    "test_dummies=pd.DataFrame(test_dummies)\n",
    "test_dummies.columns=[x for cat_list in enc.categories_ for x in cat_list[1:]]\n",
    "test_dummies.index=X_test.index\n",
    "\n",
    "X_test_final=X_test_cat.loc[:,numerical_cols].join(test_dummies)\n",
    "\n",
    "print(X_train_final.shape)\n",
    "print(X_test_final.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_regression_report(X_train_final,X_test_final,y_train_sm,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GBiqvT9QK8QQ"
   },
   "source": [
    "<a id=\"section_class_weighting\"></a>\n",
    "\n",
    "## Class weighting\n",
    "\n",
    "[Volver a TOC](#section_toc)\n",
    "\n",
    "Otra técnica que podemos utilizar para corregir el desbalance de los datos es incorporar en la función de costos del algoritmo un mayor peso para los errores de entrenamiento cometidos sobre los puntos de la clase minoritaria. \n",
    "\n",
    "La regresuón logística admite el argumento \"class_weight\" para ponderar la contribución a la función de costo de cada clase. Si usamos class_weight = 'balanced' los pesos asignados son la inversa de la frecuencia con que se observa cada clase.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "j8ZXAmXcK8QR"
   },
   "outputs": [],
   "source": [
    "model = LogisticRegressionCV(class_weight = 'balanced')\n",
    "\n",
    "scaler=StandardScaler()\n",
    "\n",
    "X_train_sc=scaler.fit_transform(X_train);\n",
    "X_test_sc=scaler.transform(X_test);\n",
    "\n",
    "model.fit(X_train_sc,y_train)\n",
    "y_pred = model.predict(X_test_sc)\n",
    "pred_probas = model.predict_proba(X_test_sc);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "j8ZXAmXcK8QR"
   },
   "outputs": [],
   "source": [
    "print(classification_report(y_test,y_pred))\n",
    "plot_confusion_matrix(model,X_test_sc,y_test,cmap='Blues');\n",
    "\n",
    "print('Area bajo la curva ROC:',roc_auc_score(y_test,pred_probas[:,1]))\n",
    "\n",
    "precision, recall,threshold=precision_recall_curve(y_test,pred_probas[:,1]);\n",
    "\n",
    "print('Area bajo la curva Precision-Recall:',auc(recall,precision))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para profundizar:\n",
    "\n",
    "https://machinelearningmastery.com/random-oversampling-and-undersampling-for-imbalanced-classification/"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "2.Practica_Guiada_Datasets_Desbalanceados.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
