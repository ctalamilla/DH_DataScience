{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial setup\n",
    "%run \"../../../common/0_notebooks_base_setup.py\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<img src='../../../common/logo_DH.png' align='left' width=35%/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LAB: Generando nuestra propia API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introducción e instrucciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El objetivo de esta práctica es simular nuestro propio servidor para poner a disposición nuestra API para un cliente interno. \n",
    "\n",
    "Vamos a utilizar un set de datos adaptados de una competencia de kaggle ya cerrada: https://www.kaggle.com/kevinmh/fifa-18-more-complete-player-dataset\n",
    "\n",
    "En el dataset vamos a encontrar todos los jugadores de fútbol argentino que están en el juego fifa-18, y contaremos con las siguientes variables: \n",
    "- **ID**: un número único que identifica al jugador en toda la base.\n",
    "- **full_name**: nombre completo del jugador.\n",
    "- **age**\n",
    "- **club**: del jugador\n",
    "- **height_cm**\n",
    "- **weight_kg**\n",
    "- **puntaje_global**: puntaje que identifica la habilidad general del jugador.\n",
    "- **potencia**: potencia física del jugador.\n",
    "- **ritmo**: velocidad de aceleración del jugador.\n",
    "- **disparos**: nivel de precisión y potencia de sus remates.\n",
    "- **pases**: nivel de precisión en sus pases.\n",
    "- **amagues**: nivel de habilidad para amagar a un rival.\n",
    "- **defensa**: capacidad defensiva general del jugador.\n",
    "- **físico**: estado físico del jugador (nos indicaría qué tan rápido se cansa)\n",
    "\n",
    "Su **misión** es simular en esta notebook un **SERVIDOR** donde está alojada su API y, desde otra notebook (Clase_PIckle_shelve_flask_CLIENT) hacer los pedidos simulando que son un **CLIENTE**.\n",
    "\n",
    "Su API va a hacer varias cosas: va a entrenar un modelo, va a realizar un gráfico de los coeficientes del modelo y, además, si le pasamos datos de un jugador nos va a devolver la predicción de su **puntaje_global**.\n",
    "\n",
    "La API tiene que tener **tres funciones/endpoints**:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **PRIMERA FUNCIÓN/ENDOPOINT:** entrenar el modelo\n",
    "> La primera de esas funciones/endpoint entrena el modelo y tiene que recibir:\n",
    "- (i) el dataframe con la base de jugadores argentinos \"fifa_18_jugadores_argentinos_dos.csv\" que se encuentra dentro de la carpeta Data (tienen que pasar la base como un json), \n",
    "- (ii) la lista de predictores, \n",
    "- (iii) la variable target, \n",
    "- (iii) una dirección donde guardar el modelo entrenado, \n",
    "- (iv) un nombre para darle al modelo y a los estimadores que necesiten usar, y \n",
    "- (v) una lista de alphas (van a usar  ElasticNet -eNetCv) y determinar el mejor alpha.\n",
    "\n",
    "> El **output** de esta primera función/endpoint tiene que ser un json que contenga: \n",
    "- (i) el mejor alpha elegido por el modelo\n",
    "- (ii) el resultado de train del modelo\n",
    "- (iii) el resultado de test del modelo\n",
    "- Además, tienen que usar la librería PICKLE para guardar el modelo entrenado y los estimadores que hayan utilizado.\n",
    "          "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **SEGUNDA FUNCIÓN/ENDOPOINT:** coeficientes del modelo\n",
    "> La segunda función/endpoint, va a grabar en la misma carpeta que el modelo una figura de los coeficientes del modelo entrenado. Los inputs tienen que incluir, por lo menos:\n",
    "- (i) dirección donde está guardado el modelo\n",
    "- (ii) nombre del modelo guardado\n",
    "\n",
    "> El **output** de esta segunda función/endpoint tiene que ser: \n",
    "- (i) un json con los valores de los coeficientes\n",
    "- (ii) un figura .jpg que se guarde en la carpeta donde está guardado el modelo. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **TERCERA FUNCIÓN/ENDOPOINT:** predicciones\n",
    "> La tercera función/endpoint, va a realizar predicciones cuando nosotros le pasemos los datos de un nuevo jugador. Los inputs tiene que incluir, por lo menos: \n",
    "- (i) dirección donde está guardado el modelo\n",
    "- (ii) nombre del modelo y estimadores\n",
    "- (iii) features del jugador del cual queremos hacer la predicción sobre su puntaje total\n",
    "\n",
    "> El **output** de esta tercera función/endpoint tiene que ser: \n",
    "- (i) un json con la predicción del puntaje total del jugador.\n",
    "\n",
    "<br>  \n",
    "#### ¡Manos a la obra!\n",
    "<br>  \n",
    "\n",
    "<img src=\"img/05_flask.jpg\" alt=\"Drawing\" style=\"width: 300px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"caja9\" style=\"float:left;width: 100%;\">\n",
    "  <div style=\"float:left;width: 15%;\"><img src=\"../../../common/icons/kit_de_salida.png\" style=\"align:left\"/> </div>\n",
    "  <br>\n",
    "  <div style=\"float:left;width: 85%;\"><label><b>Para tener en cuenta:</b> Tal como vimos en las notebooks de la práctica guiada y en los checkpoints, por un lado tienen que definir las funionces/endopoints de su API y, al final de la notebook, ejecutar la línea de código <b>app.run(host='0.0.0.0')</b>. Recuerden que esta línea hace que la notebook simule ser un servidor que está poniendo a disposición a nuestra API para que podamos acceder desde la otra notebook que es el cliente (usando la librería request). Y por último: mientras esté en ejecución esta línea de código, acuérdense de que no pueden ejecutar ninguna otra celda de esta notebook. </label></div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recuerden importar todas las librerías que su servidor va a necesitar para poner la API a disposición y para hacer entrenar el modelo y guardarlo a disco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import pickle\n",
    "from flask import  Flask, request, jsonify, render_template\n",
    "\n",
    "# Recuerden que en este entorno de \"servidor\" tenemos que tener importadas las librerías que necesitamos usar\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import ElasticNetCV as eNetCv\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Librerías y configuración para visualizaciones\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_context(\"talk\")\n",
    "sns.set_style('darkgrid')\n",
    "sns.set_context(rc={'xtick.labelsize': 13,'ytick.labelsize': 13, 'axes.labelsize': 16, 'axes.titlesize': 18})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **PRIMERA FUNCIÓN/ENDOPOINT:** entrenar el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iniciamos nuestra API\n",
    "app = Flask('Predictor de jugadores')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iniciamos nuestro primera función asociada a su endpoint. Usamos el método POST ya que vamos a enviar información\n",
    "# al servidor: nuestro modelo entrenado junto con sus estimadores.\n",
    "\n",
    "def entrenar_modelo():\n",
    "    \n",
    "    # la función \"request.get_json\" de Flask para capturar la información que le envíemos a la API\n",
    "\n",
    "    \n",
    "    # Hacemos todos los pasos para entrenar el modelo y evaluarlo\n",
    "    \n",
    "        \n",
    "    # Guardamos el modelo entrenado y estimadores en una carpeta que se llama \"modelos\" \n",
    "    # que esté a la misma altura que la notebook\n",
    "    \n",
    "        \n",
    "        \n",
    "    \n",
    "    # La función devuelva el alpha elegido por el modelo, el resultado de train y el de test.\n",
    "    return {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **SEGUNDA FUNCIÓN/ENDOPOINT:** coeficientes del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iniciamos nuestro segunda función asociada a su endpoint. Usamos el método POST ya que vamos a enviar información\n",
    "# al servidor: la figura con los coeficientes de nuestro modelo entrenado\n",
    "\n",
    "def plotear_coeficientes():\n",
    "    \n",
    "    # la función \"request.get_json\" de Flask para capturar la información que le envíemos a la API\n",
    "    \n",
    "    \n",
    "    # Levantamos el modelo que tenemos grabado en disco con el llamado anterior\n",
    "       \n",
    "    \n",
    "    # Generamos la figura y la guardamos\n",
    "    \n",
    "    \n",
    "    # devolvemos un json con los coeficientes. Dado que las API devuelven la información en formato\n",
    "    # json, usamos el método de los dataframes \".to_json()\" para poder retornar los datos de los\n",
    "    # coeficientes.\n",
    "    return "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **TERCERA FUNCIÓN/ENDOPOINT:** predicciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dado que en este endopint no vamos a guardar nada en el servidor, sino recibir información, usamos \n",
    "# el método GET. \n",
    "\n",
    "def predecir_puntaje():\n",
    "    \n",
    "    # Usamos request.args para tomar las query que le pasamos a la URL\n",
    "    \n",
    "    \n",
    "    # Levantamos el modelo y los estimadores que ya tenemos entrenado\n",
    "        \n",
    "    # realizamos la prediccion\n",
    "    \n",
    "    \n",
    "    return {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Disponibilizamos nuestra API**\n",
    "<br>  \n",
    "\n",
    "<img src=\"img/forrest.jpg\" alt=\"Drawing\" style=\"width: 400px;\"/>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ahora ejecutamos esta línea de código que pone a disposición los tres endpoints que armamos arriba. \n",
    "# Es hora de ir a la otra notebook en la que simulamos ser un cliente y hacer los llamadados para cada\n",
    "# uno de estos tres endopoints...\n",
    "app.run(host='0.0.0.0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
