{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial setup\n",
    "%run \"../../../common/0_notebooks_base_setup.py\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<img src='../../../common/logo_DH.png' align='left' width=35%/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LAB: Generando nuestra propia API\n",
    "# Ahora somos el **CLIENTE**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introducción e instrucciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si todo salió bien, en este preciso momento tienen otra notebook abierta, simulando ser un **SERVIDOR**, en la cual definieron tres funciones asociadas cada una a un endpoint de nuestra API. \n",
    "La idea de esta notebook es hacer los distintos llamados a esos endpoints para que la magia de nuestra API suceda. Si todavía NO construyeron los endpoints, entonces vuelvan a la notebook **Clase_PIckle_shelve_flask_API** y sigan las instrucciones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importamos las librerías que vamos a utilizar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Algunas de las de siempre\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Las que vamos a necesitar para hacer los llamados y para lidiar con los datos en formato json\n",
    "import requests\n",
    "from flask import  Flask, request, jsonify, render_template\n",
    "import json\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **PRIMER ENDPOINT:** entrenar el modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para este primer endpoint, necesitamos cargar la base con los datos de los jugadores argentinos. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../Data/fifa_18_jugadores_argentinos_dos.csv',index_col='Unnamed: 0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usando la librería **request**, usamos el método **post** para enviar el input del primer llamado (en la notebook que simula ser el servidor está el detalle de lo que tenemos que pasarle a este **endpoint**). Tengan en cuenta que el dataframe lo tienen que pasar a un formato json con el métod de pandas <a class=\"reference internal\" href=https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.to_json.html><b><code>.to_json()</code></b></a>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos los datos que vamos a pasar en el request\n",
    "base=df.to_json() #dataframe en formato json\n",
    "lista_predictores=df.drop(columns=['ID','full_name','club','puntaje_global']).columns.values #features para entrenar el modelo\n",
    "variable_target='puntaje_global' #variable a predecir\n",
    "directory='modelos' #dirección donde vamos a guardar el modelo  \n",
    "name='predictor_jugadores' #nombre modelo\n",
    "alphas=list(np.linspace(0.001, 10, 10)) #alphas que vamos a usar en el cross-validation con ElasticNet\n",
    "url = 'http://localhost:5009/entrenar_modelo' #definimos la URL para hacer el llamado local con el endpoint correspondiente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hacemos el pedido y vemos los resultados.\n",
    "# Si todo salió bien en la carpeta \"modelos\" se tiene que haber generado un .pkl con el modelo entrenado\n",
    "modelo = requests.post(url,\n",
    "                       json = {'base' : base,\n",
    "                               'lista_predictores':list(lista_predictores),\n",
    "                               'target':variable_target,\n",
    "                               'alphas':alphas,\n",
    "                               'directory':directory,\n",
    "                               'name':name})\n",
    "print(modelo.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **SEGUNDA FUNCIÓN/ENDOPOINT:** coeficientes del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Definimos los datos que vamos a pasar en el pedido\n",
    "dir_modelo='modelos' #dirección donde se encuentra el modelo entrenado\n",
    "nombre_modelo='predictor_jugadores' #nombre del modelo entrenado\n",
    "palette='hot' #paleta de colores para usar en el gráfico de barras\n",
    "size=(25,8) #tamaño de la figura\n",
    "predictores=list(lista_predictores) #lista con los features en el mismo orden en el que fueron pasados en el modelo\n",
    "url = 'http://localhost:5009/plot_coeficientes' #definimos la URL para hacer el llamado local con el endpoint correspondiente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hacemos el pedido e imprimimos el output\n",
    "coef = requests.post(url,\n",
    "                     json = {'direccion' : dir_modelo,\n",
    "                             'nombre_modelo':nombre_modelo,\n",
    "                             'paleta_colores':palette,\n",
    "                             'tamano':size,\n",
    "                             'predictores':predictores})\n",
    "print(coef.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **TERCERA FUNCIÓN/ENDOPOINT:** predicciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Definimos las variables que vamos a utilizar para el pedido\n",
    "direccion_modelo='modelos' #dirección donde se encuentra el modelo grabado\n",
    "nombre_modelo='predictor_jugadores' #nombre del modelo grabado\n",
    "nombre_escalador='predictor_jugadores_scaler' #nombre del escalador que entrenamos cuando corrimos el modelo\n",
    "features=df.drop(columns=['ID','full_name','club','puntaje_global']).iloc[3].to_json() #elegimos features de un jugador \n",
    "#cualquiera de la base para chequear que funcione bien el llamado\n",
    "url = 'http://localhost:5009/prediccion' #definimos la URL para hacer el llamado local con el endpoint correspondiente\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hacemos el llamado\n",
    "pred = requests.get(url, \n",
    "                    params = {'direccion':direccion_modelo,\n",
    "                              'nombre_modelo':nombre_modelo,\n",
    "                              'nombre_scalador':nombre_escalador,\n",
    "                              'features':[features]})\n",
    "print(pred.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ¡Ahí tenemos nuestra predicción! ¡Congrats!\n",
    "<img src=\"img/we_did_it.jpg\" alt=\"Drawing\" style=\"width: 300px;\"/>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
