{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial setup\n",
    "%run \"../../../common/0_notebooks_base_setup.py\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[<img src=\"https://www.digitalhouse.com/ar/logo-DH.png\" width=\"400\" height=\"200\" align='right'>](http://digitalhouse.com.ar/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XTomJkhvRWHf"
   },
   "source": [
    "# Regularización (Integrador)\n",
    "\n",
    "En este lab vamos a practicar regularización. El [dataset](http://data.princeton.edu/wws509/datasets/#salary) consiste en datos de salarios de 52 profesores en una pequeña universidad, categorizados por género, ranking, título más alto, y años de servicio. (Si no está en el link o el link está caído, podés encontrar el dataset en la carpeta Data del Campus Virtual).\n",
    "\n",
    "### Objetivos de aprendizaje\n",
    "\n",
    "- Practicar el trabajo con variables categóricas y la generación de variables dummy.\n",
    "- Utilizar regularización para generar modelos con mayor poder de generalización\n",
    "\n",
    "### Requerimientos\n",
    "\n",
    "El dataset contiene tres variables categóricas, cada una con dos o tres valores: \"sx\", \"dg\", \"rk\". Tu misión es la siguiente:.\n",
    "* Crear variables dummy para cada una de las variables categóricas.\n",
    "* Usando pandas `value_counts()` mirar la distribución de estas variables\n",
    "* Usando seaborn, hacer [violin plots](https://stanford.edu/~mwaskom/software/seaborn/generated/seaborn.violinplot.html) de los salarios usando estas variables.\n",
    "\n",
    "\n",
    "* Vamos a entrenar modelos lineales para predecir el salario de los profesores 'sl'\n",
    "* Usando pandas, seleccionar una muestra de datos (set de entrenamiento) y ajustar un modelo lineal a esa muestra.\n",
    "* Ajustar un modelo al dataset solamente con las variables cuantitativas y luego con el dataset completo.\n",
    "\n",
    "* Aplicar este modelo ajustado al set de testeo y comparar los ajustes.\n",
    "* Usar regularizaciónn (ej. RidgeRegression o Lasso), ajustando el modelo sobre el mismo set de entrenamiento y midiendo la bondad de ajuste sobre el set de testeo. Cómo se comparan los ajustes sobre el set de testo con y sin regularización?\n",
    "\n",
    "Ejercicio bonus:\n",
    "* Predecir años de servicio \"yr\" o años desde obtención del título \"yd\" a partir del salario y usando otras variables si lo desea. Ayuda regularizar?\n",
    "\n",
    "### Material auxiliar\n",
    "- [Modelos lineales de scikit-learn](http://scikit-learn.org/stable/modules/linear_model.html), incluyendo regularizacion\n",
    "- [Crear variables dummy con pandas](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.get_dummies.html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AqLgk68nRWHk"
   },
   "outputs": [],
   "source": [
    "# Importamos las librerías\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../Data/salary.dat', delim_whitespace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZnFcPkBqRWH2"
   },
   "outputs": [],
   "source": [
    "# Aplicar value_counts() a las series \"sx\", \"dg\", and \"rk\"\n",
    "\n",
    "categories = ['sx', 'rk', 'dg']\n",
    "\n",
    "for category in categories:\n",
    "    print(df[category].value_counts())\n",
    "    plt.bar(df[category].value_counts().index, df[category].value_counts().values, color='b',\\\n",
    "            alpha=0.5)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FiT-3pSFRWH9"
   },
   "outputs": [],
   "source": [
    "# Hacer unos violinplots a las series \"sx\", \"dg\", and \"rk\"\n",
    "\n",
    "for category in categories:\n",
    "    sns.violinplot(x=category, y='sl', data=df)\n",
    "    plt.show()\n",
    "\n",
    "# Repetir para \"dg\" y \"rk\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5Y186sjORWIC"
   },
   "outputs": [],
   "source": [
    "# Crear variables \"dummy\"\n",
    "\n",
    "for category in categories:\n",
    "    serie = df[category]\n",
    "    dummies = pd.get_dummies(serie, drop_first= True, prefix=category)\n",
    "    df = pd.concat([df, dummies], axis=1)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajustamos el modelo usando solamente las variables cuantitativas y MCO\n",
    "\n",
    "X = df[['yr', 'yd']]\n",
    "y = df['sl']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.35, random_state=10)\n",
    "\n",
    "lm = linear_model.LinearRegression()\n",
    "\n",
    "model_1 = lm.fit(X_train, y_train)\n",
    "\n",
    "print('Score model_1:', model_1.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajustamos el modelo usando solamente las variables cuantitativas aplicando regularización\n",
    "#¿Hace falta normalizar los features antes aplicar regularización en este caso? ¿Qué unidades tienen los features?\n",
    "\n",
    "lm_ridge = linear_model.RidgeCV(alphas=[0.1, 1, 10], normalize=True) \n",
    "# Definimos el rango de de búsqueda del hiperparametro explicitamente\n",
    "\n",
    "model_2 = lm_ridge.fit(X_train, y_train)\n",
    "\n",
    "print('Score model_2:', model_2.score(X_test, y_test))\n",
    "\n",
    "# ¿Mejoraron los resultados?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ahora entrenamos el modelo con todas las variables con MCO:\n",
    "\n",
    "X_all = df.drop(['sx', 'rk', 'dg', 'sl'], axis=1) \n",
    "\n",
    "X_all_train, X_all_test, y_all_train, y_all_test = train_test_split(X_all, y, test_size=0.35, random_state=10)\n",
    "\n",
    "model_3 = lm.fit(X_all_train, y_all_train)\n",
    "\n",
    "print('Score model_3:', model_3.score(X_all_test, y_all_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ahora entrenamos el modelo con todas las variables con Ridge:\n",
    "\n",
    "lm_ridge = linear_model.RidgeCV(alphas=[0.00001, 0.00005, 0.0001, 0.0005, 0.001, 0.005, 0.01,\\\n",
    "                                        0.05, 0.1, 1, 5, 10],\\\n",
    "                                        normalize=True, cv=3) \n",
    "# Definimos el rango de de búsqueda del hiperparametro explicitamente\n",
    "\n",
    "model_4 = lm_ridge.fit(X_all_train, y_all_train)\n",
    "\n",
    "print('Score model_4:', model_4.score(X_all_test, y_all_test))\n",
    "\n",
    "# ¿Mejoraron los resultados?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_ridge.alpha_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ahora entrenamos el modelo con todas las variables con Lasso:\n",
    "\n",
    "lm_lasso = linear_model.LassoCV(alphas=[0.00001, 0.00005, 0.0001, 0.0005, 0.001, 0.005, 0.01,\\\n",
    "                                        0.05, 0.1, 1, 5, 10, 15, 25],\\\n",
    "                                        normalize=True, cv=3)\n",
    "\n",
    "model_5 = lm_lasso.fit(X_all_train, y_all_train)\n",
    "\n",
    "print('Score model_5:', model_5.score(X_all_test, y_all_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_lasso.alpha_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LPWYAA_pRWIi"
   },
   "source": [
    "# Resultados\n",
    "\n",
    "¿Cómo resultó la regularización?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iJyK3IlIRWIj"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "2.Starter_LAB_Regularización.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
