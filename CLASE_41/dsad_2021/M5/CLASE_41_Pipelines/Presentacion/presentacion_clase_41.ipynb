{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/paulati/Nuevo vol/paula/dh/2021/dsad_2021_paula/common\n",
      "default checking\n",
      "Running command `conda list`... ok\n",
      "jupyterlab=2.2.6 already installed\n",
      "pandas=1.1.5 already installed\n",
      "bokeh=2.2.3 already installed\n",
      "seaborn=0.11.0 already installed\n",
      "matplotlib=3.3.2 already installed\n",
      "ipywidgets=7.5.1 already installed\n",
      "pytest=6.2.1 already installed\n",
      "chardet=4.0.0 already installed\n",
      "psutil=5.7.2 already installed\n",
      "scipy=1.5.2 already installed\n",
      "statsmodels=0.12.1 already installed\n",
      "scikit-learn=0.23.2 already installed\n",
      "xlrd=2.0.1 already installed\n",
      "nltk=3.5 already installed\n",
      "unidecode=1.1.1 already installed\n",
      "pydotplus=2.0.2 already installed\n",
      "pandas-datareader=0.9.0 already installed\n",
      "flask=1.1.2 already installed\n"
     ]
    }
   ],
   "source": [
    "# initial setup\n",
    "%run \"../../../common/0_notebooks_base_setup.py\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<link rel=\"stylesheet\" href=\"../../../common/dhds.css\">\n",
    "<div class=\"Table\">\n",
    "    <div class=\"Row\">\n",
    "        <div class=\"Cell grey left\"> <img src=\"https://raw.githubusercontent.com/Digital-House-DATA/ds_blend_2021_img/master/M5/CLASE_41_Pipelines/Presentacion/img/M5_CLASE_41_portada.jpg\" align=\"center\" width=\"70%\"/></div>\n",
    "        <div class=\"Cell right\">\n",
    "            <div class=\"div-logo\"><img src=\"https://raw.githubusercontent.com/Digital-House-DATA/ds_blend_2021_img/master/common/logo_DH.png\" align=\"center\" width=70% /></div>\n",
    "            <div class=\"div-curso\">DATA SCIENCE</div>\n",
    "            <div class=\"div-modulo\">MÓDULO 5</div>\n",
    "            <div class=\"div-contenido\">Pipeline\n",
    "\n",
    "</div>\n",
    "        </div>\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Agenda\n",
    "\n",
    "---\n",
    "\n",
    "- ¿Qué son pipelines?\n",
    "    \n",
    "- Implementación\n",
    "\n",
    "- GridSearch + Pipelines\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div class=\"div-dhds-fondo-1\"> Pipeline\n",
    "<img src=\"https://raw.githubusercontent.com/Digital-House-DATA/ds_blend_2021_img/master/M3/CLASE_21_Regresion_Lineal_Simple/Presentacion/img/M3_CLASE_21_separador.png\" align=\"center\" />\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Introducción\n",
    "\n",
    "---\n",
    "\n",
    "**Pipeline** (tubería) es una *serie de pasos automatizados* para transformar nuestros datos con el objetivo de asegurar su validez y consistencia.\n",
    "\n",
    "**Cada paso se alimenta del paso previo**.\n",
    "\n",
    "Al ser reutilizables aseguran la *consistencia* en la operación.\n",
    "\n",
    "Al agrupar operaciones proveen un *mayor nivel de abstracción*.\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/Digital-House-DATA/ds_blend_2021_img/master/M5/CLASE_41_Pipelines/Presentacion/img/M5_CLASE_41_001_pipeline.jpg\" alt=\"pipeline\" width=50% height=40% align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Introducción\n",
    "\n",
    "---\n",
    "\n",
    "Sabemos que una parte importante del trabajo de un DataScientist es *la preparación de los datos* previo a la aplicación de los *algoritmos de machine learning*. \n",
    "\n",
    "Para ello realizamos *distintas operaciones*: data cleaning, data wrangling, cambios de escala, selección de features, etc. \n",
    "\n",
    "Las podemos ver como un **encadenamiento de procesos**, que también pueden incluir *la aplicación y evaluación de los modelos*.\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/Digital-House-DATA/ds_blend_2021_img/master/M5/CLASE_41_Pipelines/Presentacion/img/M5_CLASE_41_002_pipeline_ejemplo.png\" alt=\"pipeline_ejemplo\" width=80% height=60% />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Pipeline en Scikit-learn\n",
    "\n",
    "---\n",
    "\n",
    "<a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html\">Pipeline</a> es una clase de **scikit-learn** cuyo uso más común es facilitar el encadenamiento de pasos de preprocessing junto con un modelo.\n",
    "\n",
    "`pipeline` es en sí un estimador que tiene los métodos `fit`, `predict` y `score`, igual que otros modelos, por ejemplo `LinearRegression`.\n",
    "\n",
    "Todos los pasos encadenados en un `pipeline`, con excepción del último, tienen los métodos `fit` y `transform`, para generar una nueva representación del dato que se usa en el paso siguiente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Implementación de Pipeline\n",
    "\n",
    "---\n",
    "El esquema general para implementar `pipeline` es:\n",
    "\n",
    "**1-** Construir la **lista de los pasos** que se ejecutan en secuencia. \n",
    "  \n",
    "  Cada paso es una *tupla* que contiene un **nombre** (a elección) y la instancia de un **estimador**.  \n",
    "  \n",
    "  *Debemos previamente importar las librerías de los métodos que referenciamos*. En este ejemplo, un estimador para escalar los datos y otro para clasificar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "pasos = [('scaler', StandardScaler()), ('knn', KNeighborsClassifier())]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "---\n",
    "\n",
    "**2-** Instanciar `pipeline` con los pasos definidos previamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "pipe = Pipeline(pasos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Usemos el dataset de vinos para ilustrar el proceso. Lo dividimos en train y test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p2PHSRoPK8OK",
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score,plot_confusion_matrix,roc_auc_score, classification_report, confusion_matrix, precision_recall_curve, auc\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de filas:  178 Total de columnas:  13\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alcohol</th>\n",
       "      <th>malic_acid</th>\n",
       "      <th>ash</th>\n",
       "      <th>alcalinity_of_ash</th>\n",
       "      <th>magnesium</th>\n",
       "      <th>total_phenols</th>\n",
       "      <th>flavanoids</th>\n",
       "      <th>nonflavanoid_phenols</th>\n",
       "      <th>proanthocyanins</th>\n",
       "      <th>color_intensity</th>\n",
       "      <th>hue</th>\n",
       "      <th>od280/od315_of_diluted_wines</th>\n",
       "      <th>proline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   alcohol  malic_acid   ash  alcalinity_of_ash  magnesium  total_phenols  \\\n",
       "0    14.23        1.71  2.43               15.6      127.0           2.80   \n",
       "1    13.20        1.78  2.14               11.2      100.0           2.65   \n",
       "\n",
       "   flavanoids  nonflavanoid_phenols  proanthocyanins  color_intensity   hue  \\\n",
       "0        3.06                  0.28             2.29             5.64  1.04   \n",
       "1        2.76                  0.26             1.28             4.38  1.05   \n",
       "\n",
       "   od280/od315_of_diluted_wines  proline  \n",
       "0                          3.92   1065.0  \n",
       "1                          3.40   1050.0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_wine\n",
    "X,y = load_wine(as_frame=True, return_X_y=True)\n",
    "X_train, X_test, y_train, y_test=train_test_split(X,y,test_size=0.3, random_state=30, stratify=y)\n",
    "print('Total de filas: ',X.shape[0],'Total de columnas: ',X.shape[1])\n",
    "X.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "---\n",
    "\n",
    "**3-** Entrenamos la instancia de `pipeline` con los datos de entrenamiento, mediante el método `fit`.\n",
    "\n",
    "   - Primero ejecuta para estos datos el *paso 'scaler'*: aplica `.fit` para aprender la media y desvío de la variable, y luego `.transform` para modificar la escala.\n",
    "   \n",
    "   - Los datos re-escalados son entrenados (`.fit`) con el modelo, en el paso 'knn'. Recordemos que **el último paso no tiene `.transform`**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('scaler', StandardScaler()), ('knn', KNeighborsClassifier())])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**4-** Evaluamos el modelo generado:\n",
    "\n",
    "   - El método `predict` evalúa el modelo con los datos de test.\n",
    "   \n",
    "   - El método `score` devuelve *accuracy* del modelo. \n",
    "       \n",
    "        Para ello, escala los datos de test  *X_test* con el método `transform` del paso *'scaler'*, y se los pasa a *'knn'*, que aplica el método `score`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x144 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred = pipe.predict(X_test)\n",
    "\n",
    "conf_matrix = confusion_matrix(y_test, y_pred); \n",
    "plt.figure(figsize=(5, 2)); sns.heatmap(conf_matrix,  annot=True, fmt=\"d\");\n",
    "plt.title(\"Confusion matrix\"); plt.ylabel('True class'); plt.xlabel('Predicted class');plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Implementación de Pipeline\n",
    "\n",
    "---\n",
    "Resumimos lo anterior, asumiendo que **T1** y **T2** son dos pasos de preprocesamiento, y **Classifier** se refiere a un clasificador.\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/Digital-House-DATA/ds_blend_2021_img/master/M5/CLASE_41_Pipelines/Presentacion/img/M5_CLASE_41_003_pipeline_pasos.JPG\" alt=\"pipeline_pasos\" style=\"width: 600px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### make_pipeline\n",
    "\n",
    "---\n",
    "Si no queremos darle nombres específicos a los pasos, la clase `make_pipeline`, crea un Pipeline y nombra cada paso en forma automática."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Usando Pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "pasos = [('scaler', StandardScaler()), ('knn', KNeighborsClassifier())]\n",
    "pipe = Pipeline(pasos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Usando make_pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "makepipe = make_pipeline(StandardScaler(),KNeighborsClassifier())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Para ver el nombre que le puso a cada paso o etapa, podemos usar `.steps`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('standardscaler', StandardScaler()),\n",
       " ('kneighborsclassifier', KNeighborsClassifier())]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "makepipe.steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Atributos y parámetros\n",
    "\n",
    "---\n",
    "- Los **estimadores** se guardan como lista en el atributo `steps`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "pasos = [('scaler', StandardScaler()), ('knn', KNeighborsClassifier())]\n",
    "pipe = Pipeline(pasos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('scaler', StandardScaler())"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Accedemos al scaler\n",
    "pipe.steps[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('knn', KNeighborsClassifier())"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Accedemos al clasificador\n",
    "pipe.steps[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "La misma información queda guardada en el atributo `named_steps`pero como un diccionario: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler()"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.named_steps['scaler']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Los **parámetros** de los estimadores los podemos ver con el método `get_params`.\n",
    "\n",
    "  Tienen el formato **nombre_paso__nombre_parámetro**.\n",
    "  \n",
    "  Y se pueden modificar con el método `set_params`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'memory': None,\n",
       " 'steps': [('scaler', StandardScaler()), ('knn', KNeighborsClassifier())],\n",
       " 'verbose': False,\n",
       " 'scaler': StandardScaler(),\n",
       " 'knn': KNeighborsClassifier(),\n",
       " 'scaler__copy': True,\n",
       " 'scaler__with_mean': True,\n",
       " 'scaler__with_std': True,\n",
       " 'knn__algorithm': 'auto',\n",
       " 'knn__leaf_size': 30,\n",
       " 'knn__metric': 'minkowski',\n",
       " 'knn__metric_params': None,\n",
       " 'knn__n_jobs': None,\n",
       " 'knn__n_neighbors': 5,\n",
       " 'knn__p': 2,\n",
       " 'knn__weights': 'uniform'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                ('knn', KNeighborsClassifier(n_neighbors=4))])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.set_params(knn__n_neighbors=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div class=\"div-dhds-fondo-1\"> Pipeline + GridSearch\n",
    "<img src=\"https://raw.githubusercontent.com/Digital-House-DATA/ds_blend_2021_img/master/M3/CLASE_21_Regresion_Lineal_Simple/Presentacion/img/M3_CLASE_21_separador.png\" align=\"center\" />\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Dataset\n",
    "\n",
    "---\n",
    "Vamos a trabajar con un archivo de semillas de trigo.\n",
    "\n",
    "- Las features son propiedades geométricas de las semillas.\n",
    "\n",
    "- *type_wheat* indica el tipo de semilla: 0 - Kama, 1 - Rosa y 2 - Canadian.\n",
    "\n",
    "Para más detalles ver <a href=\"https://archive.ics.uci.edu/ml/datasets/seeds#\">aquí</a>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p2PHSRoPK8OK",
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score,plot_confusion_matrix,roc_auc_score, classification_report, confusion_matrix, precision_recall_curve, auc\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de filas:  210 Total de columnas:  8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>area</th>\n",
       "      <th>perimeter</th>\n",
       "      <th>compactness</th>\n",
       "      <th>length</th>\n",
       "      <th>width</th>\n",
       "      <th>coefficient</th>\n",
       "      <th>length_groove</th>\n",
       "      <th>type_wheat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>12.36</td>\n",
       "      <td>13.19</td>\n",
       "      <td>0.8923</td>\n",
       "      <td>5.076</td>\n",
       "      <td>3.042</td>\n",
       "      <td>3.220</td>\n",
       "      <td>4.605</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>14.52</td>\n",
       "      <td>14.60</td>\n",
       "      <td>0.8557</td>\n",
       "      <td>5.741</td>\n",
       "      <td>3.113</td>\n",
       "      <td>1.481</td>\n",
       "      <td>5.487</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>16.63</td>\n",
       "      <td>15.46</td>\n",
       "      <td>0.8747</td>\n",
       "      <td>6.053</td>\n",
       "      <td>3.465</td>\n",
       "      <td>2.040</td>\n",
       "      <td>5.877</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>11.23</td>\n",
       "      <td>12.63</td>\n",
       "      <td>0.8840</td>\n",
       "      <td>4.902</td>\n",
       "      <td>2.879</td>\n",
       "      <td>2.269</td>\n",
       "      <td>4.703</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     area  perimeter  compactness  length  width  coefficient  length_groove  \\\n",
       "62  12.36      13.19       0.8923   5.076  3.042        3.220          4.605   \n",
       "54  14.52      14.60       0.8557   5.741  3.113        1.481          5.487   \n",
       "8   16.63      15.46       0.8747   6.053  3.465        2.040          5.877   \n",
       "61  11.23      12.63       0.8840   4.902  2.879        2.269          4.703   \n",
       "\n",
       "    type_wheat  \n",
       "62           1  \n",
       "54           1  \n",
       "8            1  \n",
       "61           1  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../Data/seeds_dataset.csv')\n",
    "print('Total de filas: ',df.shape[0],'Total de columnas: ',df.shape[1])\n",
    "df.sample(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Preparamos los archivos de train y test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "X = df.drop(['type_wheat'], axis=1)\n",
    "y = df['type_wheat']\n",
    "\n",
    "X_train, X_test, y_train, y_test=train_test_split(X,y,test_size=0.3, random_state=30, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BlIfUosgK8OY",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Totales por Tipo de semilla: \n",
      "  3    70\n",
      "2    70\n",
      "1    70\n",
      "Name: type_wheat, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print('Totales por Tipo de semilla: \\n ',pd.value_counts(df['type_wheat'], sort = True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### GridSearch\n",
    "\n",
    "---\n",
    "Como vimos en una clase anterior, `GridSearch` busca *la mejor combinación de hiperparámetros* dentro de una **grilla (grid)** especificada previamente. La búsqueda es **exhaustiva para cada valor de la grilla**.\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/Digital-House-DATA/ds_blend_2021_img/master/M5/CLASE_41_Pipelines/Presentacion/img/M5_CLASE_41_004_gridsearch.JPG\" alt=\"gridsearch\" style=\"width: 250px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Para cada combinación de valores de los hiperparámetros: \n",
    "\n",
    "- los aplica sobre el *dataset de train* --> los *evalua con cross validation* --> *registra el score*.\n",
    "\n",
    "Al final de todas las búsquedas:\n",
    "\n",
    "- selecciona la combinación con **más alto score** --> aplica sobre **train** --> predice sobre **test**.\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/Digital-House-DATA/ds_blend_2021_img/master/M4/CLASE_30_Ev-Modelos_Grid-Search/Presentacion/img/M4_CLASE_30_grid_grid_random_2.png\" alt=\"Drawing\" style=\"width: 550px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "puQ9YKZCK8OH",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Pipeline + GridSearch\n",
    "\n",
    "---\n",
    "Podemos combinar los dos métodos:\n",
    "\n",
    "- Generamos nuevamente la lista de pasos que le vamos a pasar a `pipeline` y lo instanciamos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "pasos = [('scaler', StandardScaler()), ('knn', KNeighborsClassifier())]\n",
    "pipe_grid = Pipeline(pasos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Importamos `GridSearchCV` y una clase para definir los kfold del esquema de validación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold \n",
    "\n",
    "folds=StratifiedKFold(n_splits=5,shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- La grilla de hiperparámetros debe identificar **el paso del pipeline y el hiperparámetro** y los valores a evaluar.\n",
    "\n",
    "   Se indica con la sintaxis: *nombre_paso__nombre_hiperparámetro*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "param_grid = {'knn__n_neighbors':range(2,4,6),'knn__weights':['uniform','distance']}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Se combinan ambos métodos instanciando `GridSearchCV` con \n",
    "  - la instancia de `pipeline`.\n",
    "  - la grilla definida.\n",
    "  - el método de cross validation.\n",
    "\n",
    "y luego entrenamos el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=42, shuffle=True),\n",
       "             estimator=Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                                       ('knn', KNeighborsClassifier())]),\n",
       "             param_grid={'knn__n_neighbors': range(2, 4, 6),\n",
       "                         'knn__weights': ['uniform', 'distance']})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid = GridSearchCV(pipe_grid, param_grid, cv=folds)\n",
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "---\n",
    "Veamos el **score** del mejor modelo (`best_score_`), y los **pasos previos y su configuración** (`best_estimator_`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score:  0.9455172413793104\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                ('knn', KNeighborsClassifier(n_neighbors=2))])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Score: ',grid.best_score_)\n",
    "grid.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Y la performance con los datos de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9047619047619048"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(grid.best_estimator_.predict(X_test),y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "puQ9YKZCK8OH",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Pipeline + GridSearch + Preprocessing\n",
    "\n",
    "---\n",
    "Ademas de usar `GridSearch` para identificar la mejor configuración del modelo, se puede explorar cuál es la mejor configuración para los pasos previos.\n",
    "\n",
    "Por ejemplo, evaluar si nos conviene usar para escalar `StandardScaler` o `MinMaxScaler`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "puQ9YKZCK8OH",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Como antes, generamos nuevamente la lista de pasos que le vamos a pasar a `pipeline` y lo instanciamos. \n",
    "\n",
    "   **Solo** definimos como paso el uso de `StandardScaler`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "pasos = [('scaler', StandardScaler()), ('knn', KNeighborsClassifier())]\n",
    "pipe_grid_2 = Pipeline(pasos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Similarmente, importamos `GridSearchCV` y una clase para definir los kfold del esquema de validación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold \n",
    "folds=StratifiedKFold(n_splits=5,shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- La grilla de hiperparámetros ahora *incluye al paso 'scaler'* y sus valores a evaluar.\n",
    "\n",
    "   - Nota: No se debe olvidar de importar los métodos a evaluar.\n",
    "   - Nota 2: **None** significa no escalar. Lo agregamos como otra opción a evaluar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "param_grid_2 = [{'scaler':[StandardScaler(), MinMaxScaler(),None], \n",
    "                   'knn__n_neighbors':range(2,4,6), 'knn__weights':['uniform','distance']}]                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Combinamos `Pipeline` y `GridSearchCV`, y entrenamos el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=42, shuffle=True),\n",
       "             estimator=Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                                       ('knn', KNeighborsClassifier())]),\n",
       "             param_grid=[{'knn__n_neighbors': range(2, 4, 6),\n",
       "                          'knn__weights': ['uniform', 'distance'],\n",
       "                          'scaler': [StandardScaler(), MinMaxScaler(), None]}])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_2 = GridSearchCV(pipe_grid_2, param_grid_2, cv=folds)\n",
    "grid_2.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "---\n",
    "Veamos el **score** del mejor modelo (`best_score_`), y los **pasos previos y su configuración** (`best_estimator_`). \n",
    "\n",
    "En este caso, no mejoraron los valores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score:  0.9455172413793104\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                ('knn', KNeighborsClassifier(n_neighbors=2))])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Score: ',grid_2.best_score_)\n",
    "grid_2.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Y la performance con los datos de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9047619047619048"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(grid_2.best_estimator_.predict(X_test),y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "puQ9YKZCK8OH",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Custom Data Transformers\n",
    "\n",
    "---\n",
    "Veamos dos temas que luego integraremos a `Pipeline`.\n",
    "\n",
    "\n",
    "El package [`preprocessing`](https://scikit-learn.org/stable/modules/preprocessing.html) nos ofrece funciones y clases que transforman los datos para adecuarlos a nuestros modelos.\n",
    "\n",
    "Pero a veces no es suficiente y necesitamos crear nuevas funciones o **Custom Data Transformers**.\n",
    "\n",
    "Veamos dos maneras en que Scikit-learn nos permite crearlos, y usarlos **en forma estándar** como cualquier otra transformación."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "puQ9YKZCK8OH",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "---\n",
    "Recordemos que nosotros aplicamos las transformaciones mediante los métodos de la clase  `.fit`, `.transform` y `.fit_transform`.\n",
    "\n",
    "Por ejemplo, `StandardScaler`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Utilizamos sklearn para estandarizar la matriz de Features\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_scaler = pd.DataFrame(scaler.fit_transform(X_train))\n",
    "X_test_scaler = pd.DataFrame(scaler.transform(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "puQ9YKZCK8OH",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Una opción es usar la función `FunctionTransformer` de `preprocessing`.  Convierte una función Python **ya existente** en un transform.\n",
    "\n",
    "  Por ejemplo, definimos un transform para calcular la media. Observemos que lo usamos como cualquier otro. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "area             14.847524\n",
       "perimeter        14.559286\n",
       "compactness       0.870999\n",
       "length            5.628533\n",
       "width             3.258605\n",
       "coefficient       3.700201\n",
       "length_groove     5.408071\n",
       "type_wheat        2.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import FunctionTransformer\n",
    "transformer = FunctionTransformer(np.mean)\n",
    "\n",
    "df_mean = transformer.transform(df)\n",
    "df_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "puQ9YKZCK8OH",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Custom Data Transformers\n",
    "\n",
    "---\n",
    "Otra forma de crear *Custom Data Transformers* es **heredar** los métodos de las clases de `scikit-learn` para tenerlos disponibles en nuestras propias clases.\n",
    "\n",
    "Por un lado, [`BaseEstimator`](https://scikit-learn.org/stable/modules/generated/sklearn.base.BaseEstimator.html) permite heredar los métodos `get_params` y `set_params`.\n",
    "\n",
    "Por otro lado, [`TransformerMixin`](https://scikit-learn.org/stable/modules/generated/sklearn.base.TransformerMixin.html) permite obtener los métodos `.fit`, `.transform` y `.fit_transform`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "puQ9YKZCK8OH",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "---\n",
    "Supongamos que hacemos un transformer que multiplica la entrada por un valor determinado.\n",
    "\n",
    "Primero importamos las clases:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "puQ9YKZCK8OH",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Definimos nuestra propia clase.\n",
    "\n",
    "- Le pasamos las clases `BaseEstimator`y `TransformerMixin` para que herede los métodos de scikit-learn.\n",
    "\n",
    "-  `___init___` es el constructor. Donde definimos los parámetros que recibimos.\n",
    "\n",
    "- `fit` no es requerido. Solo transformamos.\n",
    "\n",
    "- `transform` indica lo que haremos con los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "class FeatureMultiplier(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self,factor):\n",
    "        self.factor = factor\n",
    "    \n",
    "    def fit(self,X,y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        return X * self.factor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "puQ9YKZCK8OH",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Ahora generamos una instancia de la clase:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "fm = FeatureMultiplier(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "puQ9YKZCK8OH",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Y transformamos un dato:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dato Original\n",
      "[[1 0 0]\n",
      " [0 2 0]\n",
      " [0 0 3]]\n",
      "Dato transformado\n",
      "[[2 0 0]\n",
      " [0 4 0]\n",
      " [0 0 6]]\n"
     ]
    }
   ],
   "source": [
    "test = np.diag((1,2,3))\n",
    "test_t = fm.transform(test)\n",
    "\n",
    "print('Dato Original'); print(test); print('Dato transformado'); print(test_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "puQ9YKZCK8OH",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Feature Union\n",
    "\n",
    "---\n",
    "[`FeatureUnion`](https://scikit-learn.org/stable/modules/compose.html#featureunion-composite-feature-spaces) combina varios transformadores, y devuelve los outputs concatenados.\n",
    "\n",
    "Es decir, aplica a los datos una serie de transformadores en forma paralela, y luego concatena la salida de ellos *en una única matriz*. \n",
    "\n",
    "Util para combinar *mecanismos de extracción de features* en un sólo transformador.\n",
    "\n",
    "En este ejemplo `FeatureUnion` recibe tres transform para distintos tipos de features, concatena las salidas, y las entrega como un unico dataset al modelo.\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/Digital-House-DATA/ds_blend_2021_img/master/M5/CLASE_41_Pipelines/Presentacion/img/M5_CLASE_41_005_features_union.jpg\" alt=\"features_union\" width=80% height=60% />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "puQ9YKZCK8OH",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Pipeline - Resultado final\n",
    "\n",
    "---\n",
    "Ahora vamos a unir todos los conceptos para armar un proceso completo con `Pipeline`.\n",
    "\n",
    "- Creamos dos `custom data transformers`. Uno selecciona un conjunto de features, el otro devuelve una feature discretizada.\n",
    "\n",
    "- Generamos dos conjuntos de features usando `FeatureUnion` y los transformers.\n",
    "\n",
    "- `GridSearch` ahora evalúa y selecciona una opción de cada grupo:\n",
    "   - Los dos conjuntos de features.\n",
    "   - Los métodos de preprocesamiento: StandardScaler(), MinMaxScaler(), None.\n",
    "   - Los hiperparámetros `n_neighbors` y `weights`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import FeatureUnion, Pipeline\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>area</th>\n",
       "      <th>perimeter</th>\n",
       "      <th>compactness</th>\n",
       "      <th>length</th>\n",
       "      <th>width</th>\n",
       "      <th>coefficient</th>\n",
       "      <th>length_groove</th>\n",
       "      <th>type_wheat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15.26</td>\n",
       "      <td>14.84</td>\n",
       "      <td>0.871</td>\n",
       "      <td>5.763</td>\n",
       "      <td>3.312</td>\n",
       "      <td>2.221</td>\n",
       "      <td>5.22</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    area  perimeter  compactness  length  width  coefficient  length_groove  \\\n",
       "0  15.26      14.84        0.871   5.763  3.312        2.221           5.22   \n",
       "\n",
       "   type_wheat  \n",
       "0           1  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "puQ9YKZCK8OH",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Creamos los dos custom data transformers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "class FeatureSelection(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self,selected_features):\n",
    "        self.selected_features=selected_features\n",
    "\n",
    "    def fit(self,X,y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        return X[self.selected_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "class FeatureDiscretize(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self,selected_features):\n",
    "        self.selected_features=selected_features\n",
    "    \n",
    "    def fit(self,X,y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        return pd.DataFrame(pd.qcut(X[self.selected_features], 10, labels=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "puQ9YKZCK8OH",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Pipeline - Resultado final\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "puQ9YKZCK8OH",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Creamos los dos conjuntos de features a evaluar usando `FeatureUnion` y los dos `Customer Transformers`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Primer FeatureUnion: selecciona 2 features y discretiza otro\n",
    "union_1=FeatureUnion([('select',FeatureSelection(selected_features=['area','perimeter'])),\n",
    "                    ('discret',FeatureDiscretize(selected_features='length_groove'))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Segundo FeatureUnion: selecciona 4 features y discretiza otro\n",
    "union_2=FeatureUnion([('select',FeatureSelection(selected_features=['area','perimeter','length','width'])),\n",
    "                    ('discret',FeatureDiscretize(selected_features='compactness'))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "puQ9YKZCK8OH",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Ahora generamos como siempre la lista de pasos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "pasos= [('feature_engineering',union_1),\n",
    "        ('preprocesamiento',StandardScaler()),\n",
    "        ('clasificador',KNeighborsClassifier())]\n",
    "\n",
    "pipe_grid_final=Pipeline(pasos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Definimos la grilla para el`GridSearch` y entrenamos el modelo en Train.\n",
    "\n",
    "  En la etapa **feature_engineering** tenemos para evaluar los dos conjuntos de features transformadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=42, shuffle=True),\n",
       "             estimator=Pipeline(steps=[('feature_engineering',\n",
       "                                        FeatureUnion(transformer_list=[('select',\n",
       "                                                                        FeatureSelection(selected_features=['area',\n",
       "                                                                                                            'perimeter'])),\n",
       "                                                                       ('discret',\n",
       "                                                                        FeatureDiscretize(selected_features='length_groove'))])),\n",
       "                                       ('preprocesamiento', StandardScaler()),\n",
       "                                       ('clasificador',\n",
       "                                        KNeighb...\n",
       "                                                                                  FeatureSelection(selected_features=['area',\n",
       "                                                                                                                      'perimeter'])),\n",
       "                                                                                 ('discret',\n",
       "                                                                                  FeatureDiscretize(selected_features='length_groove'))]),\n",
       "                                                  FeatureUnion(transformer_list=[('select',\n",
       "                                                                                  FeatureSelection(selected_features=['area',\n",
       "                                                                                                                      'perimeter',\n",
       "                                                                                                                      'length',\n",
       "                                                                                                                      'width'])),\n",
       "                                                                                 ('discret',\n",
       "                                                                                  FeatureDiscretize(selected_features='compactness'))])],\n",
       "                          'preprocesamiento': [StandardScaler(), MinMaxScaler(),\n",
       "                                               None]}])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid_final = [{'feature_engineering':[union_1,union_2],\n",
    "                   'preprocesamiento':[StandardScaler(), MinMaxScaler(), None],\n",
    "                   'clasificador__n_neighbors':range(2,4,6), 'clasificador__weights':['uniform','distance']}]\n",
    "\n",
    "folds=StratifiedKFold(n_splits=5,shuffle=True, random_state=42)\n",
    "\n",
    "grid_final=GridSearchCV(pipe_grid_final, param_grid_final, cv=folds)\n",
    "\n",
    "grid_final.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "---\n",
    "Veamos el **score** del mejor modelo (`best_score_`), y los **pasos previos y su configuración** (`best_estimator_`).\n",
    "\n",
    "El score bajó respecto a lo realizado anteriormente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score:  0.8841379310344827\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('feature_engineering',\n",
       "                 FeatureUnion(transformer_list=[('select',\n",
       "                                                 FeatureSelection(selected_features=['area',\n",
       "                                                                                     'perimeter'])),\n",
       "                                                ('discret',\n",
       "                                                 FeatureDiscretize(selected_features='length_groove'))])),\n",
       "                ('preprocesamiento', None),\n",
       "                ('clasificador',\n",
       "                 KNeighborsClassifier(n_neighbors=2, weights='distance'))])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Score: ',grid_final.best_score_)\n",
    "grid_final.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Y la performance con los datos de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9047619047619048"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(grid_final.best_estimator_.predict(X_test),y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div class=\"div-dhds-fondo-1\"> Conclusiones\n",
    "<img src=\"https://raw.githubusercontent.com/Digital-House-DATA/ds_blend_2021_img/master/M5/CLASE_34_CART/Presentacion/img/M5_CLASE_34_separador.png\" align=\"center\" />\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Conclusiones\n",
    "\n",
    "---\n",
    "Usar `pipeline` tiene algunas ventajas: \n",
    "\n",
    "- Facilita la creación de un flujo de trabajo coherente y fácil de entender.\n",
    "\n",
    "- Reproducibilidad.\n",
    "\n",
    "- Combinación con `GridSearch` para la selección de los hiperparámetros.\n",
    "\n",
    "- Combinación con `Custom Data Transformers` y `FeatureUnion` para persistir la transformación y selección de las features en el mismo proceso.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div class=\"div-dhds-fondo-1\"> Hands-on\n",
    "<img src=\"https://raw.githubusercontent.com/Digital-House-DATA/ds_blend_2021_img/master/M3/CLASE_21_Regresion_Lineal_Simple/Presentacion/img/M3_CLASE_21_separador.png\" align=\"center\" />\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Ejercicio\n",
    "\n",
    "----\n",
    "\n",
    "A partir del dataset de semillas de trigo, vamos a usar `Pipeline` para crear un flujo de trabajo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p2PHSRoPK8OK",
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score,plot_confusion_matrix,roc_auc_score, classification_report, confusion_matrix, precision_recall_curve, auc\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de filas:  210 Total de columnas:  8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>area</th>\n",
       "      <th>perimeter</th>\n",
       "      <th>compactness</th>\n",
       "      <th>length</th>\n",
       "      <th>width</th>\n",
       "      <th>coefficient</th>\n",
       "      <th>length_groove</th>\n",
       "      <th>type_wheat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>11.23</td>\n",
       "      <td>12.63</td>\n",
       "      <td>0.8840</td>\n",
       "      <td>4.902</td>\n",
       "      <td>2.879</td>\n",
       "      <td>2.269</td>\n",
       "      <td>4.703</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>16.16</td>\n",
       "      <td>15.33</td>\n",
       "      <td>0.8644</td>\n",
       "      <td>5.845</td>\n",
       "      <td>3.395</td>\n",
       "      <td>4.266</td>\n",
       "      <td>5.795</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      area  perimeter  compactness  length  width  coefficient  length_groove  \\\n",
       "61   11.23      12.63       0.8840   4.902  2.879        2.269          4.703   \n",
       "133  16.16      15.33       0.8644   5.845  3.395        4.266          5.795   \n",
       "\n",
       "     type_wheat  \n",
       "61            1  \n",
       "133           2  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../Data/seeds_dataset.csv')\n",
    "print('Total de filas: ',df.shape[0],'Total de columnas: ',df.shape[1])\n",
    "df.sample(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Preparamos los archivos de train y test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "X = df.drop(['type_wheat'], axis=1)\n",
    "y = df['type_wheat']\n",
    "\n",
    "X_train, X_test, y_train, y_test=train_test_split(X,y,test_size=0.3, random_state=30, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Vamos a usar nuevamente las dos `Custom Data Transformers`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "class FeatureSelection(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self,selected_features):\n",
    "        self.selected_features=selected_features\n",
    "\n",
    "    def fit(self,X,y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        return X[self.selected_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "class FeatureDiscretize(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self,selected_features):\n",
    "        self.selected_features=selected_features\n",
    "    \n",
    "    def fit(self,X,y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        return pd.DataFrame(pd.qcut(X[self.selected_features], 10, labels=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Ejercicio\n",
    "\n",
    "----\n",
    "\n",
    "Generamos un conjunto de features usando:\n",
    "- `FeatureSelection` para seleccionar 'area','length','width','coefficient'.\n",
    "- `FeatureDiscretize` para discretizar 'perimeter'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# union=FeatureUnion([('select',...),\n",
    "#                    ('discret',...)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "puQ9YKZCK8OH",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Generamos la lista de pasos y la instancia para `Pipeline`:\n",
    "  - 'feature_engineering' para el conjunto de features.\n",
    "  - 'preprocesamiento' para `StandardScaler()`.\n",
    "  - 'clasificador' para `KNeighborsClassifier()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# pasos= [('feature_engineering',...),\n",
    "#        ('preprocesamiento',...),\n",
    "#        ('clasificador',...)]\n",
    "\n",
    "# pipe_grid_handson=Pipeline(pasos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Definimos la grilla para el`GridSearch` y entrenamos el modelo en Train.\n",
    "\n",
    "  - No incluimos la etapa 'feature_engineering' para evaluar, pues tenemos un conjunto de features.\n",
    "  - Para la etapa 'preprocesamiento' comparamos `StandardScaler()` y `StandardScaler()`\n",
    "  - Para la etapa 'clasificador' evaluamos los hiperparámetros `n_neighbors` y `weights`, con los valores (2,4,6) y ('uniform','distance') respectivamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# param_grid_handson = [{'preprocesamiento':[...],\n",
    "#                   'clasificador__...), 'clasificador__...}]\n",
    "\n",
    "# folds=StratifiedKFold(n_splits=5,shuffle=True, random_state=42)\n",
    "\n",
    "# grid_handson=GridSearchCV(..., ..., cv=folds)\n",
    "\n",
    "# grid_handson.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "---\n",
    "Veamos el **score** del mejor modelo (`best_score_`), y los **pasos previos y su configuración** (`best_estimator_`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Y la performance con los datos de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# accuracy_score(grid_handson.best_estimator_.predict(X_test),y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Solución\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Ejercicio\n",
    "\n",
    "----\n",
    "\n",
    "A partir del dataset de semillas de trigo, vamos a usar `Pipeline` para crear un flujo de trabajo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p2PHSRoPK8OK",
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score,plot_confusion_matrix,roc_auc_score, classification_report, confusion_matrix, precision_recall_curve, auc\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de filas:  210 Total de columnas:  8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>area</th>\n",
       "      <th>perimeter</th>\n",
       "      <th>compactness</th>\n",
       "      <th>length</th>\n",
       "      <th>width</th>\n",
       "      <th>coefficient</th>\n",
       "      <th>length_groove</th>\n",
       "      <th>type_wheat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>18.59</td>\n",
       "      <td>16.05</td>\n",
       "      <td>0.9066</td>\n",
       "      <td>6.037</td>\n",
       "      <td>3.860</td>\n",
       "      <td>6.001</td>\n",
       "      <td>5.877</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14.29</td>\n",
       "      <td>14.09</td>\n",
       "      <td>0.9050</td>\n",
       "      <td>5.291</td>\n",
       "      <td>3.337</td>\n",
       "      <td>2.699</td>\n",
       "      <td>4.825</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     area  perimeter  compactness  length  width  coefficient  length_groove  \\\n",
       "93  18.59      16.05       0.9066   6.037  3.860        6.001          5.877   \n",
       "2   14.29      14.09       0.9050   5.291  3.337        2.699          4.825   \n",
       "\n",
       "    type_wheat  \n",
       "93           2  \n",
       "2            1  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../Data/seeds_dataset.csv')\n",
    "print('Total de filas: ',df.shape[0],'Total de columnas: ',df.shape[1])\n",
    "df.sample(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Preparamos los archivos de train y test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "X = df.drop(['type_wheat'], axis=1)\n",
    "y = df['type_wheat']\n",
    "\n",
    "X_train, X_test, y_train, y_test=train_test_split(X,y,test_size=0.3, random_state=30, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Vamos a usar nuevamente las dos `Custom Data Transformers`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "class FeatureSelection(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self,selected_features):\n",
    "        self.selected_features=selected_features\n",
    "\n",
    "    def fit(self,X,y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        return X[self.selected_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "class FeatureDiscretize(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self,selected_features):\n",
    "        self.selected_features=selected_features\n",
    "    \n",
    "    def fit(self,X,y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        return pd.DataFrame(pd.qcut(X[self.selected_features], 10, labels=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Ejercicio\n",
    "\n",
    "----\n",
    "\n",
    "Generamos un conjunto de features usando:\n",
    "- `FeatureSelection` para seleccionar 'area','length','width','coefficient'.\n",
    "- `FeatureDiscretize` para discretizar 'perimeter'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "union=FeatureUnion([('select',FeatureSelection(selected_features=['area','length','width','coefficient'])),\n",
    "                    ('discret',FeatureDiscretize(selected_features='perimeter'))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "puQ9YKZCK8OH",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Generamos la lista de pasos y la instancia para `Pipeline`:\n",
    "  - 'feature_engineering' para el conjunto de features.\n",
    "  - 'preprocesamiento' para `StandardScaler()`.\n",
    "  - 'clasificador' para `KNeighborsClassifier()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "pasos= [('feature_engineering',union),\n",
    "        ('preprocesamiento',StandardScaler()),\n",
    "        ('clasificador',KNeighborsClassifier())]\n",
    "\n",
    "pipe_grid_handson=Pipeline(pasos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Definimos la grilla para el`GridSearch` y entrenamos el modelo en Train.\n",
    "\n",
    "  - No incluimos la etapa 'feature_engineering' para evaluar, pues tenemos un conjunto de features.\n",
    "  - Para la etapa 'preprocesamiento' comparamos `StandardScaler()` y `StandardScaler()`\n",
    "  - Para la etapa 'clasificador' evaluamos los hiperparámetros `n_neighbors` y `weights`, con los valores (2,4,6) y ('uniform','distance') respectivamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=42, shuffle=True),\n",
       "             estimator=Pipeline(steps=[('feature_engineering',\n",
       "                                        FeatureUnion(transformer_list=[('select',\n",
       "                                                                        FeatureSelection(selected_features=['area',\n",
       "                                                                                                            'length',\n",
       "                                                                                                            'width',\n",
       "                                                                                                            'coefficient'])),\n",
       "                                                                       ('discret',\n",
       "                                                                        FeatureDiscretize(selected_features='perimeter'))])),\n",
       "                                       ('preprocesamiento', StandardScaler()),\n",
       "                                       ('clasificador',\n",
       "                                        KNeighborsClassifier())]),\n",
       "             param_grid=[{'clasificador__n_neighbors': range(2, 4, 6),\n",
       "                          'clasificador__weights': ['uniform', 'distance'],\n",
       "                          'preprocesamiento': [StandardScaler(),\n",
       "                                               MinMaxScaler()]}])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid_handson = [{'preprocesamiento':[StandardScaler(), MinMaxScaler()],\n",
    "                   'clasificador__n_neighbors':range(2,4,6), 'clasificador__weights':['uniform','distance']}]\n",
    "\n",
    "folds=StratifiedKFold(n_splits=5,shuffle=True, random_state=42)\n",
    "\n",
    "grid_handson=GridSearchCV(pipe_grid_handson, param_grid_handson, cv=folds)\n",
    "\n",
    "grid_handson.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "---\n",
    "Veamos el **score** del mejor modelo (`best_score_`), y los **pasos previos y su configuración** (`best_estimator_`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score:  0.8977011494252872\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('feature_engineering',\n",
       "                 FeatureUnion(transformer_list=[('select',\n",
       "                                                 FeatureSelection(selected_features=['area',\n",
       "                                                                                     'length',\n",
       "                                                                                     'width',\n",
       "                                                                                     'coefficient'])),\n",
       "                                                ('discret',\n",
       "                                                 FeatureDiscretize(selected_features='perimeter'))])),\n",
       "                ('preprocesamiento', MinMaxScaler()),\n",
       "                ('clasificador',\n",
       "                 KNeighborsClassifier(n_neighbors=2, weights='distance'))])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Score: ',grid_handson.best_score_)\n",
    "grid_handson.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Y la performance con los datos de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.873015873015873"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(grid_handson.best_estimator_.predict(X_test),y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div class=\"div-dhds-fondo-1\"> Referencias y Material Adicional\n",
    "<img src=\"https://raw.githubusercontent.com/Digital-House-DATA/ds_blend_2021_img/master/M3/CLASE_21_Regresion_Lineal_Simple/Presentacion/img/M3_CLASE_21_separador.png\" align=\"center\" />\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Referencias y Material Adicional\n",
    "\n",
    "---\n",
    "\n",
    "<a href=\"https://scikit-learn.org/stable/data_transforms.html\" target=\"_blank\">Data Transform - Scikit-learn</a>\n",
    "\n",
    "<a href=\"https://towardsdatascience.com/pipelines-custom-transformers-in-scikit-learn-ef792bbb3260\" target=\"_blank\">Pipelines & Custom Transformers in Scikit-learn</a>\n",
    "\n",
    "<a href=\"https://medium.com/analytics-vidhya/scikit-learn-pipelines-with-custom-transformer-a-step-by-step-guide-9b9b886fd2cc\" target=\"_blank\">Scikit-Learn Pipelines with Custom Transformer — A Step by Step Guide.</a>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
